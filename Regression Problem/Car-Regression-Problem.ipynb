{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problème de régression - GUIMONT Mathieu  CLEREMPUY Gabriel\n",
    "On dispose d'un fichier \"CarPrice_Assignment.csv\" qui contient 26 colonnes et 205 lignes, correspondant à des caractéristiques de voitures (https://www.kaggle.com/datasets/hellbuoy/car-price-prediction/code).\n",
    "\n",
    "\n",
    "On va chercher à estimer le prix de la voiture en fonction des autres paramètres, quantitatifs et qualitatifs.\n",
    "\n",
    "Paramètres quantitatifs: carlength, carwidth, carheight, curbweight, wheelbase, boreratio,stroke, compressionratio,horsepower,peakrpm, citympg,highwaympg\n",
    "\n",
    "Paramètres qualitatifs: symboling, CarName, fueltype, aspiration, doornumber, carbody, drivewheel, enginelocation, enginetype, cylindernumber, enginesize ,fuelsystem\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des librairies utiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "#Test de plusieurs modèles\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car_ID</th>\n",
       "      <th>symboling</th>\n",
       "      <th>CarName</th>\n",
       "      <th>fueltype</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>doornumber</th>\n",
       "      <th>carbody</th>\n",
       "      <th>drivewheel</th>\n",
       "      <th>enginelocation</th>\n",
       "      <th>wheelbase</th>\n",
       "      <th>...</th>\n",
       "      <th>enginesize</th>\n",
       "      <th>fuelsystem</th>\n",
       "      <th>boreratio</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compressionratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peakrpm</th>\n",
       "      <th>citympg</th>\n",
       "      <th>highwaympg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>alfa-romero giulia</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>13495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>alfa-romero stelvio</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>16500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>alfa-romero Quadrifoglio</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>94.5</td>\n",
       "      <td>...</td>\n",
       "      <td>152</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154</td>\n",
       "      <td>5000</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>16500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>audi 100 ls</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.8</td>\n",
       "      <td>...</td>\n",
       "      <td>109</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102</td>\n",
       "      <td>5500</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>13950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>audi 100ls</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>4wd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.4</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>17450.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   car_ID  symboling                   CarName fueltype aspiration doornumber  \\\n",
       "0       1          3        alfa-romero giulia      gas        std        two   \n",
       "1       2          3       alfa-romero stelvio      gas        std        two   \n",
       "2       3          1  alfa-romero Quadrifoglio      gas        std        two   \n",
       "3       4          2               audi 100 ls      gas        std       four   \n",
       "4       5          2                audi 100ls      gas        std       four   \n",
       "\n",
       "       carbody drivewheel enginelocation  wheelbase  ...  enginesize  \\\n",
       "0  convertible        rwd          front       88.6  ...         130   \n",
       "1  convertible        rwd          front       88.6  ...         130   \n",
       "2    hatchback        rwd          front       94.5  ...         152   \n",
       "3        sedan        fwd          front       99.8  ...         109   \n",
       "4        sedan        4wd          front       99.4  ...         136   \n",
       "\n",
       "   fuelsystem  boreratio  stroke compressionratio horsepower  peakrpm citympg  \\\n",
       "0        mpfi       3.47    2.68              9.0        111     5000      21   \n",
       "1        mpfi       3.47    2.68              9.0        111     5000      21   \n",
       "2        mpfi       2.68    3.47              9.0        154     5000      19   \n",
       "3        mpfi       3.19    3.40             10.0        102     5500      24   \n",
       "4        mpfi       3.19    3.40              8.0        115     5500      18   \n",
       "\n",
       "   highwaympg    price  \n",
       "0          27  13495.0  \n",
       "1          27  16500.0  \n",
       "2          26  16500.0  \n",
       "3          30  13950.0  \n",
       "4          22  17450.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"CarPrice_Assignment.csv\"\n",
    "data_full = pd.read_csv(filename, header=0)\n",
    "print(data_full.shape)\n",
    "data_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prétraitement des données\n",
    "Pour utiliser nos variables catégorielles dans nos modèles, nous allons devoir encoder nos variables.\n",
    "Le OneHotEncoder est l'encodeur le plus adapté à celà pour nos variables qui ne présentent pas de hiérarchie entre leurs différentes valeurs possibles (tel que 'petit', 'moyen', 'grand')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symboling_-2</th>\n",
       "      <th>symboling_-1</th>\n",
       "      <th>symboling_0</th>\n",
       "      <th>symboling_1</th>\n",
       "      <th>symboling_2</th>\n",
       "      <th>symboling_3</th>\n",
       "      <th>CarName_Nissan versa</th>\n",
       "      <th>CarName_alfa-romero Quadrifoglio</th>\n",
       "      <th>CarName_alfa-romero giulia</th>\n",
       "      <th>CarName_alfa-romero stelvio</th>\n",
       "      <th>...</th>\n",
       "      <th>carheight</th>\n",
       "      <th>curbweight</th>\n",
       "      <th>enginesize</th>\n",
       "      <th>boreratio</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compressionratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peakrpm</th>\n",
       "      <th>citympg</th>\n",
       "      <th>highwaympg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>48.8</td>\n",
       "      <td>2548</td>\n",
       "      <td>130</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>48.8</td>\n",
       "      <td>2548</td>\n",
       "      <td>130</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52.4</td>\n",
       "      <td>2823</td>\n",
       "      <td>152</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154</td>\n",
       "      <td>5000</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2337</td>\n",
       "      <td>109</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102</td>\n",
       "      <td>5500</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2824</td>\n",
       "      <td>136</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55.5</td>\n",
       "      <td>2952</td>\n",
       "      <td>141</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.15</td>\n",
       "      <td>9.5</td>\n",
       "      <td>114</td>\n",
       "      <td>5400</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55.5</td>\n",
       "      <td>3049</td>\n",
       "      <td>141</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.15</td>\n",
       "      <td>8.7</td>\n",
       "      <td>160</td>\n",
       "      <td>5300</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55.5</td>\n",
       "      <td>3012</td>\n",
       "      <td>173</td>\n",
       "      <td>3.58</td>\n",
       "      <td>2.87</td>\n",
       "      <td>8.8</td>\n",
       "      <td>134</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55.5</td>\n",
       "      <td>3217</td>\n",
       "      <td>145</td>\n",
       "      <td>3.01</td>\n",
       "      <td>3.40</td>\n",
       "      <td>23.0</td>\n",
       "      <td>106</td>\n",
       "      <td>4800</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55.5</td>\n",
       "      <td>3062</td>\n",
       "      <td>141</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.15</td>\n",
       "      <td>9.5</td>\n",
       "      <td>114</td>\n",
       "      <td>5400</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     symboling_-2  symboling_-1  symboling_0  symboling_1  symboling_2  \\\n",
       "0             0.0           0.0          0.0          0.0          0.0   \n",
       "1             0.0           0.0          0.0          0.0          0.0   \n",
       "2             0.0           0.0          0.0          1.0          0.0   \n",
       "3             0.0           0.0          0.0          0.0          1.0   \n",
       "4             0.0           0.0          0.0          0.0          1.0   \n",
       "..            ...           ...          ...          ...          ...   \n",
       "200           0.0           1.0          0.0          0.0          0.0   \n",
       "201           0.0           1.0          0.0          0.0          0.0   \n",
       "202           0.0           1.0          0.0          0.0          0.0   \n",
       "203           0.0           1.0          0.0          0.0          0.0   \n",
       "204           0.0           1.0          0.0          0.0          0.0   \n",
       "\n",
       "     symboling_3  CarName_Nissan versa  CarName_alfa-romero Quadrifoglio  \\\n",
       "0            1.0                   0.0                               0.0   \n",
       "1            1.0                   0.0                               0.0   \n",
       "2            0.0                   0.0                               1.0   \n",
       "3            0.0                   0.0                               0.0   \n",
       "4            0.0                   0.0                               0.0   \n",
       "..           ...                   ...                               ...   \n",
       "200          0.0                   0.0                               0.0   \n",
       "201          0.0                   0.0                               0.0   \n",
       "202          0.0                   0.0                               0.0   \n",
       "203          0.0                   0.0                               0.0   \n",
       "204          0.0                   0.0                               0.0   \n",
       "\n",
       "     CarName_alfa-romero giulia  CarName_alfa-romero stelvio  ...  carheight  \\\n",
       "0                           1.0                          0.0  ...       48.8   \n",
       "1                           0.0                          1.0  ...       48.8   \n",
       "2                           0.0                          0.0  ...       52.4   \n",
       "3                           0.0                          0.0  ...       54.3   \n",
       "4                           0.0                          0.0  ...       54.3   \n",
       "..                          ...                          ...  ...        ...   \n",
       "200                         0.0                          0.0  ...       55.5   \n",
       "201                         0.0                          0.0  ...       55.5   \n",
       "202                         0.0                          0.0  ...       55.5   \n",
       "203                         0.0                          0.0  ...       55.5   \n",
       "204                         0.0                          0.0  ...       55.5   \n",
       "\n",
       "     curbweight  enginesize  boreratio  stroke  compressionratio  horsepower  \\\n",
       "0          2548         130       3.47    2.68               9.0         111   \n",
       "1          2548         130       3.47    2.68               9.0         111   \n",
       "2          2823         152       2.68    3.47               9.0         154   \n",
       "3          2337         109       3.19    3.40              10.0         102   \n",
       "4          2824         136       3.19    3.40               8.0         115   \n",
       "..          ...         ...        ...     ...               ...         ...   \n",
       "200        2952         141       3.78    3.15               9.5         114   \n",
       "201        3049         141       3.78    3.15               8.7         160   \n",
       "202        3012         173       3.58    2.87               8.8         134   \n",
       "203        3217         145       3.01    3.40              23.0         106   \n",
       "204        3062         141       3.78    3.15               9.5         114   \n",
       "\n",
       "     peakrpm  citympg  highwaympg  \n",
       "0       5000       21          27  \n",
       "1       5000       21          27  \n",
       "2       5000       19          26  \n",
       "3       5500       24          30  \n",
       "4       5500       18          22  \n",
       "..       ...      ...         ...  \n",
       "200     5400       23          28  \n",
       "201     5300       19          25  \n",
       "202     5500       18          23  \n",
       "203     4800       26          27  \n",
       "204     5400       19          25  \n",
       "\n",
       "[205 rows x 204 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cat = data_full.iloc[:, [1,2,3,4,5,6,7,8,14,15,17]]  # Sélection des caractéristiques quantitatives (en supposant que la première et dernière colonnes sont catégorielles)\n",
    "X_quant=data_full.iloc[:, [9,10,11,12,13,16,18,19,20,21,22,23,24]]\n",
    "y = data_full.iloc[: , 25 ] #La colonne du prix\n",
    "\n",
    "quant_columns=[9,10,11,12,13,16,18,19,20,21,22,23,24]\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "X_cat_encoded = pd.DataFrame(encoder.fit_transform(X_cat).toarray(), columns=encoder.get_feature_names_out(X_cat.columns))\n",
    "X_processed = pd.concat([X_cat_encoded, pd.DataFrame(X_quant, columns=data_full.columns[quant_columns])], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.33, random_state=0)\n",
    "X_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Permet d'afficher les poids pour chaque variable après entraînement du modèle\n",
    "def affichage_poids(model):\n",
    "    # Obtention des poids\n",
    "    feature_weights = model.coef_\n",
    "\n",
    "    # Create a dictionary to pair feature names with their weights\n",
    "    feature_weights_dict = dict(zip(X_processed.columns.to_list(), feature_weights))\n",
    "    # Assuming you've already created the feature_weights_dict\n",
    "    feature_weights_df = pd.DataFrame(feature_weights_dict.items(), columns=['Variable', 'Poids'])\n",
    "\n",
    "    transposed_df = feature_weights_df.transpose()\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print('\\n', transposed_df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test de plusieurs modèles\n",
    "On commence par un modèle très simple qui va servir de point de comparaison par rapport aux autres modèles.\n",
    "Le modèle LinearRegression est un modèle simple qui va chercher à établir une relation linéaire entre les variables explicatives et la variable cible. Le modèle cherche à ajuster ces coefficients de manière à minimiser la somme des carrés des différences entre les valeurs prédites et les valeurs réelles des données d'entraînement. Cependant, il suppose une relation linéaire entre les variables explicatives et la variable cible, ce qui peut ne pas être adapté à des relations plus complexes ou non linéaires entre les variables.\n",
    "\n",
    "Pour l'optimisation des hyperparamètres des modèles, on utilisera à chaque fois optuna qui est une bibliothèque permettant de tester la performance d'un modèle en fonction de plusieurs sets d'hyperparamètres déterminés grâce à des algorithmes commme TPE (Tree-structured Parzen Estimator).\n",
    "\n",
    "On choisira la \"Mean Squared Error\" comme métrique pour mesurer la performance d'un modèle car on cherche à évaluer les erreurs individuelles de prédiction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 16:59:27,034] A new study created in memory with name: no-name-8b69e00e-9e90-491a-91d3-4e9ed6d31d9a\n",
      "[I 2024-01-08 16:59:27,109] Trial 0 finished with value: 473360180.5052456 and parameters: {'fit_intercept': False, 'positive': False}. Best is trial 0 with value: 473360180.5052456.\n",
      "[I 2024-01-08 16:59:27,187] Trial 1 finished with value: 453611394.76300454 and parameters: {'fit_intercept': True, 'positive': False}. Best is trial 1 with value: 453611394.76300454.\n",
      "[I 2024-01-08 16:59:27,235] Trial 2 finished with value: 300477196.5850369 and parameters: {'fit_intercept': True, 'positive': True}. Best is trial 2 with value: 300477196.5850369.\n",
      "[I 2024-01-08 16:59:27,341] Trial 3 finished with value: 453611394.76300454 and parameters: {'fit_intercept': True, 'positive': False}. Best is trial 2 with value: 300477196.5850369.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 16:59:27,440] Trial 4 finished with value: 453611394.76300454 and parameters: {'fit_intercept': True, 'positive': False}. Best is trial 2 with value: 300477196.5850369.\n",
      "[I 2024-01-08 16:59:27,495] Trial 5 finished with value: 300477196.5850369 and parameters: {'fit_intercept': True, 'positive': True}. Best is trial 2 with value: 300477196.5850369.\n",
      "[I 2024-01-08 16:59:27,516] Trial 6 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:27,546] Trial 7 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:27,583] Trial 8 finished with value: 473360180.5052456 and parameters: {'fit_intercept': False, 'positive': False}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:27,623] Trial 9 finished with value: 453611394.76300454 and parameters: {'fit_intercept': True, 'positive': False}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:27,649] Trial 10 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:27,668] Trial 11 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:27,692] Trial 12 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:27,716] Trial 13 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:27,738] Trial 14 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:27,756] Trial 15 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:27,781] Trial 16 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:27,807] Trial 17 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:27,825] Trial 18 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:27,855] Trial 19 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:27,902] Trial 20 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:27,934] Trial 21 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:27,954] Trial 22 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:27,980] Trial 23 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:28,003] Trial 24 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:28,024] Trial 25 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:28,049] Trial 26 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:28,070] Trial 27 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:28,091] Trial 28 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:28,126] Trial 29 finished with value: 473360180.5052456 and parameters: {'fit_intercept': False, 'positive': False}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:28,149] Trial 30 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:28,173] Trial 31 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:28,201] Trial 32 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:28,222] Trial 33 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:28,259] Trial 34 finished with value: 453611394.76300454 and parameters: {'fit_intercept': True, 'positive': False}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:28,282] Trial 35 finished with value: 300477196.5850369 and parameters: {'fit_intercept': True, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:28,307] Trial 36 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:28,341] Trial 37 finished with value: 453611394.76300454 and parameters: {'fit_intercept': True, 'positive': False}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:28,364] Trial 38 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:28,415] Trial 39 finished with value: 453611394.76300454 and parameters: {'fit_intercept': True, 'positive': False}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:28,435] Trial 40 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:28,457] Trial 41 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:28,485] Trial 42 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:28,504] Trial 43 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:28,529] Trial 44 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:28,566] Trial 45 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:28,600] Trial 46 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:28,643] Trial 47 finished with value: 453611394.76300454 and parameters: {'fit_intercept': True, 'positive': False}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:28,676] Trial 48 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n",
      "[I 2024-01-08 16:59:28,724] Trial 49 finished with value: 26156212.014953274 and parameters: {'fit_intercept': False, 'positive': True}. Best is trial 6 with value: 26156212.014953274.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Meilleurs hyperparamètres: {'fit_intercept': False, 'positive': True}\n",
      "MSE optimisé de LinearRegression: 26156212.014953274\n",
      "R2 correspondant: 0.5759401113614121\n",
      "\n",
      "                    0             1            2            3            4            5                     6                                 7                           8                            9                    10                  11                 12                 13                           14                15                16              17              18              19              20              21                     22                                23                             24                                25                               26                                       27                     28                     29                        30                             31                           32                           33                       34                          35                            36                                 37                  38                         39                         40                     41                    42                         43                       44                   45                          46                        47                           48                        49                     50                    51                           52                  53                 54                 55                 56                        57                 58                 59                 60                   61                        62                          63                        64                  65                     66                       67                      68                     69                         70                         71                            72                          73                            74                         75                      76                   77                   78                   79                   80                    81                    82                   83                   84                    85                   86                    87                    88                    89                   90                   91                        92                                 93                     94                        95                       96                                97                         98                                      99                        100                        101                     102                      103                    104                   105                    106               107                 108                109             110                  111                 112                113                114                115                    116                     117                    118                       119                                120                     121                          122                               123                              124                            125                    126                            127                             128                            129                      130                     131                     132                    133                     134                       135                                   136                          137                        138                           139                        140                               141                              142                        143                  144                      145                  146                147                148                  149                   150                151                152              153           154             155               156              157             158                  159              160                161            162            163             164             165             166                   167                  168              169               170           171             172              173              174               175                   176                  177                  178                 179                   180                    181                 182              183              184              185             186             187              188              189              190        191        192       193        194         195         196        197     198               199         200      201      202         203\n",
      "Variable  symboling_-2  symboling_-1  symboling_0  symboling_1  symboling_2  symboling_3  CarName_Nissan versa  CarName_alfa-romero Quadrifoglio  CarName_alfa-romero giulia  CarName_alfa-romero stelvio  CarName_audi 100 ls  CarName_audi 100ls  CarName_audi 4000  CarName_audi 5000  CarName_audi 5000s (diesel)  CarName_audi fox  CarName_bmw 320i  CarName_bmw x1  CarName_bmw x3  CarName_bmw x4  CarName_bmw x5  CarName_bmw z4  CarName_buick century  CarName_buick century luxus (sw)  CarName_buick century special  CarName_buick electra 225 custom  CarName_buick opel isuzu deluxe  CarName_buick regal sport coupe (turbo)  CarName_buick skyhawk  CarName_buick skylark  CarName_chevrolet impala  CarName_chevrolet monte carlo  CarName_chevrolet vega 2300  CarName_dodge challenger se  CarName_dodge colt (sw)  CarName_dodge colt hardtop  CarName_dodge coronet custom  CarName_dodge coronet custom (sw)  CarName_dodge d200  CarName_dodge dart custom  CarName_dodge monaco (sw)  CarName_dodge rampage  CarName_honda accord  CarName_honda accord cvcc  CarName_honda accord lx  CarName_honda civic  CarName_honda civic (auto)  CarName_honda civic 1300  CarName_honda civic 1500 gl  CarName_honda civic cvcc  CarName_honda prelude  CarName_isuzu D-Max   CarName_isuzu D-Max V-Cross  CarName_isuzu MU-X  CarName_jaguar xf  CarName_jaguar xj  CarName_jaguar xk  CarName_maxda glc deluxe  CarName_maxda rx3  CarName_mazda 626  CarName_mazda glc  CarName_mazda glc 4  CarName_mazda glc custom  CarName_mazda glc custom l  CarName_mazda glc deluxe  CarName_mazda rx-4  CarName_mazda rx-7 gs  CarName_mazda rx2 coupe  CarName_mercury cougar  CarName_mitsubishi g4  CarName_mitsubishi lancer  CarName_mitsubishi mirage  CarName_mitsubishi mirage g4  CarName_mitsubishi montero  CarName_mitsubishi outlander  CarName_mitsubishi pajero  CarName_nissan clipper  CarName_nissan dayz  CarName_nissan fuga  CarName_nissan gt-r  CarName_nissan juke  CarName_nissan kicks  CarName_nissan latio  CarName_nissan leaf  CarName_nissan note  CarName_nissan nv200  CarName_nissan otti  CarName_nissan rogue  CarName_nissan teana  CarName_nissan titan  CarName_peugeot 304  CarName_peugeot 504  CarName_peugeot 504 (sw)  CarName_peugeot 505s turbo diesel  CarName_peugeot 604sl  CarName_plymouth cricket  CarName_plymouth duster  CarName_plymouth fury gran sedan  CarName_plymouth fury iii  CarName_plymouth satellite custom (sw)  CarName_plymouth valiant  CarName_porcshce panamera  CarName_porsche boxter  CarName_porsche cayenne  CarName_porsche macan  CarName_renault 12tl  CarName_renault 5 gtl  CarName_saab 99e  CarName_saab 99gle  CarName_saab 99le  CarName_subaru  CarName_subaru baja  CarName_subaru brz  CarName_subaru dl  CarName_subaru r1  CarName_subaru r2  CarName_subaru trezia  CarName_subaru tribeca  CarName_toyota carina  CarName_toyota celica gt  CarName_toyota celica gt liftback  CarName_toyota corolla  CarName_toyota corolla 1200  CarName_toyota corolla 1600 (sw)  CarName_toyota corolla liftback  CarName_toyota corolla tercel  CarName_toyota corona  CarName_toyota corona hardtop  CarName_toyota corona liftback  CarName_toyota corona mark ii  CarName_toyota cressida  CarName_toyota mark ii  CarName_toyota starlet  CarName_toyota tercel  CarName_toyouta tercel  CarName_vokswagen rabbit  CarName_volkswagen 1131 deluxe sedan  CarName_volkswagen 411 (sw)  CarName_volkswagen dasher  CarName_volkswagen model 111  CarName_volkswagen rabbit  CarName_volkswagen rabbit custom  CarName_volkswagen super beetle  CarName_volkswagen type 3  CarName_volvo 144ea  CarName_volvo 145e (sw)  CarName_volvo 244dl  CarName_volvo 245  CarName_volvo 246  CarName_volvo 264gl  CarName_volvo diesel  CarName_vw dasher  CarName_vw rabbit  fueltype_diesel  fueltype_gas  aspiration_std  aspiration_turbo  doornumber_four  doornumber_two  carbody_convertible  carbody_hardtop  carbody_hatchback  carbody_sedan  carbody_wagon  drivewheel_4wd  drivewheel_fwd  drivewheel_rwd  enginelocation_front  enginelocation_rear  enginetype_dohc  enginetype_dohcv  enginetype_l  enginetype_ohc  enginetype_ohcf  enginetype_ohcv  enginetype_rotor  cylindernumber_eight  cylindernumber_five  cylindernumber_four  cylindernumber_six  cylindernumber_three  cylindernumber_twelve  cylindernumber_two  fuelsystem_1bbl  fuelsystem_2bbl  fuelsystem_4bbl  fuelsystem_idi  fuelsystem_mfi  fuelsystem_mpfi  fuelsystem_spdi  fuelsystem_spfi  wheelbase  carlength  carwidth  carheight  curbweight  enginesize  boreratio  stroke  compressionratio  horsepower  peakrpm  citympg  highwaympg\n",
      "Poids              0.0   2136.166837  1079.543739          0.0   745.990359  1857.224228                   0.0                       4161.338068                         0.0                       3005.0          5605.009158         5494.543739                0.0                0.0                    182.27411               0.0       8235.940775             0.0    16305.044983    15931.191612             0.0    15098.442094            12171.70101                      11187.077912                      6422.5556                       8053.324768                              0.0                                      0.0           14101.324768                    0.0                       0.0                            0.0                          0.0                          0.0                      0.0                 1101.199377                           0.0                                0.0                 0.0                 227.619539                        0.0             418.952521                   0.0                        0.0               441.871766          2761.582825                 2507.533545               1977.541838                    879.62491                1283.17347            1289.788694           3983.261989                          0.0                 0.0       19512.456953       16212.456953       15095.143588                941.952521          41.952521        3228.847735        8337.706247                  0.0                       0.0                         0.0               1804.199377         1777.761049             387.082446                      0.0                     0.0                    0.0                 289.962162                        0.0                           0.0                         0.0                           0.0                        0.0             2279.753855                  0.0          1121.210943                  0.0          2575.744214           1236.586963            1837.99107           1637.99107          2775.744214            842.614728                  0.0            834.179471                   0.0           2125.744214                  0.0          3041.402048               1771.680669                        4312.753144            3273.804477                       0.0                      0.0                               0.0                 747.452521                             1101.199377                227.619539                        0.0             2285.330835                   1500.0                    0.0                   0.0                    0.0       2902.930033                 0.0          3263.3427             0.0                  0.0          121.739336         802.920626        1307.453409                0.0              247.49248              2518.87538            2694.372698                764.529451                                0.0             1397.717804                   824.992167                               0.0                      1233.654217                      44.685086            1624.456941                    1106.658625                             0.0                     616.202364              6564.176835              2549.95396                     0.0                    0.0                     0.0               1743.025125                                   0.0                          0.0                        0.0                   1963.025125                        0.0                       5319.194085                      1302.747465                1043.550381          3737.946126              5382.916412          7760.042031        6375.086137        9686.055726         11010.388249           4403.142645                0.0         1804.02812      1197.399395           0.0             0.0       1036.944744              0.0             0.0          2214.669165              0.0                0.0     437.753144            0.0      272.285927             0.0             0.0                   0.0         15604.056587      1629.984503               0.0   2778.569789             0.0              0.0        992.98303       4309.654294          19108.835954           4054.78932                  0.0          533.599586                   0.0                    0.0                 0.0              0.0       378.882587              0.0             0.0             0.0              0.0              0.0              0.0        0.0        0.0       0.0        0.0         0.0         0.0        0.0     0.0               0.0   70.208307      0.0      0.0         0.0\n"
     ]
    }
   ],
   "source": [
    "# Fonction objectif pour Optuna utilisant la Mean Squared Error (MSE)\n",
    "def objective(trial):\n",
    "    fit_intercept = trial.suggest_categorical('fit_intercept', [True, False])\n",
    "    positive = trial.suggest_categorical('positive', [True, False])\n",
    "\n",
    "    model = LinearRegression(fit_intercept=fit_intercept, positive=positive)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    return mse\n",
    "\n",
    "# Création et exécution de l'étude Optuna\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Obtention des meilleurs paramètres et calcul du MSE et du R2 avec les paramètres optimisés\n",
    "best_params = study.best_params\n",
    "best_model = LinearRegression(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "mse_reglin= mean_squared_error(y_test, y_pred_best)\n",
    "r2_reglin = r2_score(y_test, y_pred_best)\n",
    "\n",
    "print('\\n')\n",
    "print(f\"Meilleurs hyperparamètres: {best_params}\")\n",
    "print(f\"MSE optimisé de LinearRegression: {mse_reglin}\")\n",
    "print(f\"R2 correspondant: {r2_reglin}\")\n",
    "affichage_poids(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso\n",
    "Lasso possède la capacité de pénaliser les coefficients des variables moins importantes en les conduisant vers zéro. Cela permet une sélection automatique des caractéristiques en éliminant celles qui ont peu d'impact sur la prédiction. Le modèle devient plus simple, celà peut aider à éviter l'overfiting. \n",
    "De plus, en présence de multicollinéarités, Lasso a tendance à choisir une variable parmi les variables fortement corrélées et à pénaliser les autres, ce qui peut améliorer la stabilité des prédictions.\n",
    "Dans notre cas, nous avons beaucoup de variables qui sont corrélées entre elles. Et il est fort probable que certaines de nos variables soient moins significatives que d'autres dans la prédiction du prix. Par conséquent la régularisation Lasso est pertinente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 17:00:23,757] A new study created in memory with name: no-name-a851bace-e21a-4611-baea-12591e0976d1\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.041e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:00:23,848] Trial 0 finished with value: 34336989.42841562 and parameters: {'alpha': 0.08652290187660243}. Best is trial 0 with value: 34336989.42841562.\n",
      "[I 2024-01-08 17:00:23,869] Trial 1 finished with value: 8715931.829242714 and parameters: {'alpha': 35.15082984826603}. Best is trial 1 with value: 8715931.829242714.\n",
      "[I 2024-01-08 17:00:23,893] Trial 2 finished with value: 12049921.303776145 and parameters: {'alpha': 264.0765336405729}. Best is trial 1 with value: 8715931.829242714.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.166e+06, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:00:23,977] Trial 3 finished with value: 67152676.93311477 and parameters: {'alpha': 0.0017141779899538191}. Best is trial 1 with value: 8715931.829242714.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.042e+06, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:00:24,058] Trial 4 finished with value: 68190264.35128862 and parameters: {'alpha': 0.00034953564019632905}. Best is trial 1 with value: 8715931.829242714.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.009e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:00:24,235] Trial 5 finished with value: 12991119.062743904 and parameters: {'alpha': 2.285274802696904}. Best is trial 1 with value: 8715931.829242714.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.434e+06, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:00:24,353] Trial 6 finished with value: 65046921.69795144 and parameters: {'alpha': 0.004791146674864534}. Best is trial 1 with value: 8715931.829242714.\n",
      "[I 2024-01-08 17:00:24,374] Trial 7 finished with value: 11392033.415510552 and parameters: {'alpha': 185.81516364476545}. Best is trial 1 with value: 8715931.829242714.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.166e+06, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:00:24,488] Trial 8 finished with value: 11512456.157857737 and parameters: {'alpha': 4.6782498886451025}. Best is trial 1 with value: 8715931.829242714.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.019e+06, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:00:24,555] Trial 9 finished with value: 68376898.52414072 and parameters: {'alpha': 0.00010720649044661984}. Best is trial 1 with value: 8715931.829242714.\n",
      "[I 2024-01-08 17:00:24,645] Trial 10 finished with value: 9713893.045473104 and parameters: {'alpha': 15.981779326634639}. Best is trial 1 with value: 8715931.829242714.\n",
      "[I 2024-01-08 17:00:24,687] Trial 11 finished with value: 9483262.095107818 and parameters: {'alpha': 19.16607708529393}. Best is trial 1 with value: 8715931.829242714.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.530e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:00:24,779] Trial 12 finished with value: 19846566.361832656 and parameters: {'alpha': 0.25288317973588}. Best is trial 1 with value: 8715931.829242714.\n",
      "[I 2024-01-08 17:00:24,815] Trial 13 finished with value: 9094243.30099544 and parameters: {'alpha': 25.560965209661333}. Best is trial 1 with value: 8715931.829242714.\n",
      "[I 2024-01-08 17:00:24,841] Trial 14 finished with value: 12134887.494593883 and parameters: {'alpha': 697.1875157818321}. Best is trial 1 with value: 8715931.829242714.\n",
      "[I 2024-01-08 17:00:24,903] Trial 15 finished with value: 8679680.722954841 and parameters: {'alpha': 48.88045019111172}. Best is trial 15 with value: 8679680.722954841.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.274e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:00:25,004] Trial 16 finished with value: 13573597.066438278 and parameters: {'alpha': 1.8890259444575537}. Best is trial 15 with value: 8679680.722954841.\n",
      "[I 2024-01-08 17:00:25,042] Trial 17 finished with value: 9896531.335234616 and parameters: {'alpha': 109.7169318799681}. Best is trial 15 with value: 8679680.722954841.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.259e+06, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:00:25,128] Trial 18 finished with value: 49263072.34983904 and parameters: {'alpha': 0.033769394796944116}. Best is trial 15 with value: 8679680.722954841.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.376e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:00:25,201] Trial 19 finished with value: 15055860.442725087 and parameters: {'alpha': 0.5518104799367877}. Best is trial 15 with value: 8679680.722954841.\n",
      "[I 2024-01-08 17:00:25,223] Trial 20 finished with value: 12062126.89471611 and parameters: {'alpha': 981.2430249902495}. Best is trial 15 with value: 8679680.722954841.\n",
      "[I 2024-01-08 17:00:25,272] Trial 21 finished with value: 9030866.545100383 and parameters: {'alpha': 26.932312932624512}. Best is trial 15 with value: 8679680.722954841.\n",
      "[I 2024-01-08 17:00:25,299] Trial 22 finished with value: 8676751.446898213 and parameters: {'alpha': 43.85679048716363}. Best is trial 22 with value: 8676751.446898213.\n",
      "[I 2024-01-08 17:00:25,342] Trial 23 finished with value: 8779534.050514348 and parameters: {'alpha': 55.44701561698282}. Best is trial 22 with value: 8676751.446898213.\n",
      "[I 2024-01-08 17:00:25,425] Trial 24 finished with value: 10758164.371810565 and parameters: {'alpha': 6.960577439800567}. Best is trial 22 with value: 8676751.446898213.\n",
      "[I 2024-01-08 17:00:25,455] Trial 25 finished with value: 9809912.867943447 and parameters: {'alpha': 106.2074456036671}. Best is trial 22 with value: 8676751.446898213.\n",
      "[I 2024-01-08 17:00:25,487] Trial 26 finished with value: 12153476.360882431 and parameters: {'alpha': 292.3506441630942}. Best is trial 22 with value: 8676751.446898213.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.501e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:00:25,580] Trial 27 finished with value: 14790477.472338047 and parameters: {'alpha': 0.9532367090403303}. Best is trial 22 with value: 8676751.446898213.\n",
      "[I 2024-01-08 17:00:25,668] Trial 28 finished with value: 10801510.051111707 and parameters: {'alpha': 6.593250540732739}. Best is trial 22 with value: 8676751.446898213.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.293e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:00:25,739] Trial 29 finished with value: 24051809.60661723 and parameters: {'alpha': 0.1711676061957257}. Best is trial 22 with value: 8676751.446898213.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.834e+06, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:00:25,809] Trial 30 finished with value: 53491087.750512674 and parameters: {'alpha': 0.025213194266850803}. Best is trial 22 with value: 8676751.446898213.\n",
      "[I 2024-01-08 17:00:25,841] Trial 31 finished with value: 9076077.166079843 and parameters: {'alpha': 64.8831313701089}. Best is trial 22 with value: 8676751.446898213.\n",
      "[I 2024-01-08 17:00:25,873] Trial 32 finished with value: 8678171.286372831 and parameters: {'alpha': 43.96507572433194}. Best is trial 22 with value: 8676751.446898213.\n",
      "[I 2024-01-08 17:00:25,908] Trial 33 finished with value: 12189807.625987327 and parameters: {'alpha': 359.0059061374309}. Best is trial 22 with value: 8676751.446898213.\n",
      "[I 2024-01-08 17:00:25,980] Trial 34 finished with value: 10405311.998586625 and parameters: {'alpha': 11.007033847755674}. Best is trial 22 with value: 8676751.446898213.\n",
      "[I 2024-01-08 17:00:26,005] Trial 35 finished with value: 8679708.452745125 and parameters: {'alpha': 48.9618439836524}. Best is trial 22 with value: 8676751.446898213.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.398e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:00:26,107] Trial 36 finished with value: 12425709.271084843 and parameters: {'alpha': 2.9710453587054437}. Best is trial 22 with value: 8676751.446898213.\n",
      "[I 2024-01-08 17:00:26,141] Trial 37 finished with value: 9482191.604808675 and parameters: {'alpha': 90.73961428482201}. Best is trial 22 with value: 8676751.446898213.\n",
      "[I 2024-01-08 17:00:26,171] Trial 38 finished with value: 8684592.757752268 and parameters: {'alpha': 46.30836983067929}. Best is trial 22 with value: 8676751.446898213.\n",
      "[I 2024-01-08 17:00:26,193] Trial 39 finished with value: 12204007.551193416 and parameters: {'alpha': 376.7699799702244}. Best is trial 22 with value: 8676751.446898213.\n",
      "[I 2024-01-08 17:00:26,240] Trial 40 finished with value: 11380220.718932677 and parameters: {'alpha': 184.3044995672126}. Best is trial 22 with value: 8676751.446898213.\n",
      "[I 2024-01-08 17:00:26,272] Trial 41 finished with value: 8665566.051753659 and parameters: {'alpha': 42.9024092939795}. Best is trial 41 with value: 8665566.051753659.\n",
      "[I 2024-01-08 17:00:26,309] Trial 42 finished with value: 8650851.630002161 and parameters: {'alpha': 40.27474235056541}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:26,360] Trial 43 finished with value: 9485246.089696564 and parameters: {'alpha': 19.12757345819165}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:26,442] Trial 44 finished with value: 10611759.396424206 and parameters: {'alpha': 8.7611118921493}. Best is trial 42 with value: 8650851.630002161.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.962e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:00:26,514] Trial 45 finished with value: 14096123.725142602 and parameters: {'alpha': 1.5354668353941494}. Best is trial 42 with value: 8650851.630002161.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.678e+06, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:00:26,622] Trial 46 finished with value: 11939005.780193254 and parameters: {'alpha': 3.8695215467987065}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:26,693] Trial 47 finished with value: 8696113.999775328 and parameters: {'alpha': 36.154644252702276}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:26,771] Trial 48 finished with value: 10996501.623768702 and parameters: {'alpha': 161.25924400816305}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:26,875] Trial 49 finished with value: 10038605.344550222 and parameters: {'alpha': 13.575957798685582}. Best is trial 42 with value: 8650851.630002161.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.437e+06, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:00:26,989] Trial 50 finished with value: 65024750.065849006 and parameters: {'alpha': 0.004829546426687481}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:27,017] Trial 51 finished with value: 12205870.865711475 and parameters: {'alpha': 494.33613891671763}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:27,063] Trial 52 finished with value: 9039728.82624793 and parameters: {'alpha': 63.91418278129613}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:27,101] Trial 53 finished with value: 8969095.921645865 and parameters: {'alpha': 28.352611133194063}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:27,174] Trial 54 finished with value: 10708638.827708587 and parameters: {'alpha': 147.83071192230594}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:27,205] Trial 55 finished with value: 8663915.395663984 and parameters: {'alpha': 38.60199538651952}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:27,311] Trial 56 finished with value: 9803598.184256516 and parameters: {'alpha': 15.147839468683367}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:27,478] Trial 57 finished with value: 11079569.646403594 and parameters: {'alpha': 5.589897027483881}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:27,529] Trial 58 finished with value: 9479640.137992976 and parameters: {'alpha': 90.57818586266036}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:27,626] Trial 59 finished with value: 11740908.424908444 and parameters: {'alpha': 230.6892616486121}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:27,714] Trial 60 finished with value: 9019867.943486203 and parameters: {'alpha': 27.17659713144594}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:27,790] Trial 61 finished with value: 8689951.245634807 and parameters: {'alpha': 45.22650002328662}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:27,854] Trial 62 finished with value: 9241868.12087442 and parameters: {'alpha': 71.93267522330632}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:27,914] Trial 63 finished with value: 9406369.892778646 and parameters: {'alpha': 20.569532686808298}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:27,946] Trial 64 finished with value: 12160031.110182438 and parameters: {'alpha': 650.9766525547909}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:28,024] Trial 65 finished with value: 10409843.94307265 and parameters: {'alpha': 10.949117271450756}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:28,051] Trial 66 finished with value: 8660331.301977567 and parameters: {'alpha': 42.36659476265385}. Best is trial 42 with value: 8650851.630002161.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.693e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:00:28,136] Trial 67 finished with value: 14277898.082192905 and parameters: {'alpha': 1.4112441150006136}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:28,225] Trial 68 finished with value: 8714629.73819661 and parameters: {'alpha': 35.214575411909294}. Best is trial 42 with value: 8650851.630002161.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.686e+06, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:00:28,419] Trial 69 finished with value: 11939313.550198933 and parameters: {'alpha': 3.8688894305843684}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:28,442] Trial 70 finished with value: 11949288.91324865 and parameters: {'alpha': 253.73854131548845}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:28,487] Trial 71 finished with value: 10594372.05051321 and parameters: {'alpha': 141.8398161831216}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:28,530] Trial 72 finished with value: 8679645.301876375 and parameters: {'alpha': 48.82136828625098}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:28,574] Trial 73 finished with value: 9741782.544407804 and parameters: {'alpha': 103.32938696601919}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:28,664] Trial 74 finished with value: 9301014.15857457 and parameters: {'alpha': 22.19227786283888}. Best is trial 42 with value: 8650851.630002161.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.069e+06, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:00:28,824] Trial 75 finished with value: 67964189.12840474 and parameters: {'alpha': 0.0006442559650129435}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:28,905] Trial 76 finished with value: 10616234.358075187 and parameters: {'alpha': 8.64696006849088}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:28,948] Trial 77 finished with value: 8769848.52213572 and parameters: {'alpha': 55.013430427753796}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:29,030] Trial 78 finished with value: 9829957.29704567 and parameters: {'alpha': 14.948601915782469}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:29,054] Trial 79 finished with value: 12063907.30987523 and parameters: {'alpha': 972.8905121330785}. Best is trial 42 with value: 8650851.630002161.\n",
      "[I 2024-01-08 17:00:29,089] Trial 80 finished with value: 8648944.368511384 and parameters: {'alpha': 41.18902393169587}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:29,126] Trial 81 finished with value: 8684336.553331941 and parameters: {'alpha': 36.867379415691325}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:29,172] Trial 82 finished with value: 9593706.29981701 and parameters: {'alpha': 96.64819459709143}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:29,207] Trial 83 finished with value: 8764309.458525192 and parameters: {'alpha': 54.761085604480726}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:29,248] Trial 84 finished with value: 8942353.382761683 and parameters: {'alpha': 28.895259553494842}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:29,288] Trial 85 finished with value: 10495929.722683635 and parameters: {'alpha': 136.25358867663846}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:29,362] Trial 86 finished with value: 10517142.75211586 and parameters: {'alpha': 9.907131856368519}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:29,405] Trial 87 finished with value: 9250869.264528826 and parameters: {'alpha': 72.84438288487686}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:29,429] Trial 88 finished with value: 12199180.363628034 and parameters: {'alpha': 369.76469379293286}. Best is trial 80 with value: 8648944.368511384.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.161e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:00:29,512] Trial 89 finished with value: 15297447.03996335 and parameters: {'alpha': 0.4769839698614336}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:29,559] Trial 90 finished with value: 9526317.075588636 and parameters: {'alpha': 18.36932141145049}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:29,601] Trial 91 finished with value: 11503988.329519685 and parameters: {'alpha': 198.91776291467042}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:29,654] Trial 92 finished with value: 8656612.817885583 and parameters: {'alpha': 41.998584508529774}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:29,689] Trial 93 finished with value: 8669448.390731417 and parameters: {'alpha': 43.25717951589655}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:29,730] Trial 94 finished with value: 8651392.469762705 and parameters: {'alpha': 40.177230473594506}. Best is trial 80 with value: 8648944.368511384.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.660e+06, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:00:29,821] Trial 95 finished with value: 46292722.66216593 and parameters: {'alpha': 0.04269376342791007}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:29,871] Trial 96 finished with value: 8920048.23274212 and parameters: {'alpha': 29.374260568028962}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:29,919] Trial 97 finished with value: 9295284.2863325 and parameters: {'alpha': 76.99716184298104}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:30,010] Trial 98 finished with value: 10692478.202006318 and parameters: {'alpha': 7.529275202055883}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:30,055] Trial 99 finished with value: 8665272.363978008 and parameters: {'alpha': 38.471438030017566}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:30,128] Trial 100 finished with value: 9964435.63968088 and parameters: {'alpha': 14.008129251484206}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:30,181] Trial 101 finished with value: 8660079.473437296 and parameters: {'alpha': 38.99991269642143}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:30,223] Trial 102 finished with value: 8687956.809186101 and parameters: {'alpha': 36.63388424413061}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:30,274] Trial 103 finished with value: 9208619.83860983 and parameters: {'alpha': 23.612555530432765}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:30,339] Trial 104 finished with value: 10077640.898601957 and parameters: {'alpha': 117.26789813320639}. Best is trial 80 with value: 8648944.368511384.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.546e+06, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:00:30,467] Trial 105 finished with value: 11210885.47893376 and parameters: {'alpha': 5.211884809448847}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:30,503] Trial 106 finished with value: 9223691.220244333 and parameters: {'alpha': 70.0013127554392}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:30,543] Trial 107 finished with value: 8669006.452759767 and parameters: {'alpha': 38.10635181291144}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:30,610] Trial 108 finished with value: 9413112.263568556 and parameters: {'alpha': 20.46403367346913}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:30,691] Trial 109 finished with value: 10363081.766554084 and parameters: {'alpha': 11.563032337145321}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:30,720] Trial 110 finished with value: 8652335.976355657 and parameters: {'alpha': 40.017726230944504}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:30,754] Trial 111 finished with value: 8666357.371840782 and parameters: {'alpha': 38.37008178824122}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:30,824] Trial 112 finished with value: 9071169.603680804 and parameters: {'alpha': 26.038404055227293}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:30,914] Trial 113 finished with value: 9635130.118061813 and parameters: {'alpha': 16.79568396495149}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:30,996] Trial 114 finished with value: 9495256.79309529 and parameters: {'alpha': 91.55799877511429}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:31,037] Trial 115 finished with value: 8799075.442661136 and parameters: {'alpha': 56.29439333215366}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:31,077] Trial 116 finished with value: 8700762.196533691 and parameters: {'alpha': 35.904404933091705}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:31,113] Trial 117 finished with value: 11353907.44192708 and parameters: {'alpha': 180.82973190458196}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:31,158] Trial 118 finished with value: 9150010.236933462 and parameters: {'alpha': 66.77435080544099}. Best is trial 80 with value: 8648944.368511384.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.022e+06, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:00:31,249] Trial 119 finished with value: 68355762.79735088 and parameters: {'alpha': 0.00013460773650871919}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:31,280] Trial 120 finished with value: 10218914.806340799 and parameters: {'alpha': 123.23921341422714}. Best is trial 80 with value: 8648944.368511384.\n",
      "[I 2024-01-08 17:00:31,322] Trial 121 finished with value: 8648805.4638422 and parameters: {'alpha': 40.700753668423864}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:31,392] Trial 122 finished with value: 8971211.904331394 and parameters: {'alpha': 28.310986267383498}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:31,424] Trial 123 finished with value: 8749125.382672809 and parameters: {'alpha': 33.817779151064585}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:31,522] Trial 124 finished with value: 8685791.076546941 and parameters: {'alpha': 50.16003670397616}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:31,583] Trial 125 finished with value: 9497749.260044567 and parameters: {'alpha': 18.88919319566041}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:31,635] Trial 126 finished with value: 9384485.740729382 and parameters: {'alpha': 84.1185774431624}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:31,711] Trial 127 finished with value: 9759856.71350187 and parameters: {'alpha': 15.51243213326415}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:31,744] Trial 128 finished with value: 8652957.127175767 and parameters: {'alpha': 39.91891390742455}. Best is trial 121 with value: 8648805.4638422.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.755e+06, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:00:31,839] Trial 129 finished with value: 62849206.14927217 and parameters: {'alpha': 0.00875038376110252}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:31,907] Trial 130 finished with value: 10376447.515830569 and parameters: {'alpha': 11.388901541396928}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:31,936] Trial 131 finished with value: 8684943.840197131 and parameters: {'alpha': 44.45291215298571}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:31,988] Trial 132 finished with value: 9163607.002809212 and parameters: {'alpha': 24.284299295142684}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:32,034] Trial 133 finished with value: 8944856.855205728 and parameters: {'alpha': 61.36796923250504}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:32,076] Trial 134 finished with value: 8658529.437251855 and parameters: {'alpha': 39.17581633503462}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:32,140] Trial 135 finished with value: 9533803.194753964 and parameters: {'alpha': 93.74733576885345}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:32,191] Trial 136 finished with value: 8840012.44433548 and parameters: {'alpha': 31.36928874748529}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:32,248] Trial 137 finished with value: 8793451.09372277 and parameters: {'alpha': 56.05409336585397}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:32,297] Trial 138 finished with value: 9372627.191358795 and parameters: {'alpha': 21.108111877156134}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:32,333] Trial 139 finished with value: 10452665.882769981 and parameters: {'alpha': 133.65907108836382}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:32,374] Trial 140 finished with value: 8683886.009358559 and parameters: {'alpha': 44.37959084331699}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:32,410] Trial 141 finished with value: 8687145.019245893 and parameters: {'alpha': 36.68496840083312}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:32,460] Trial 142 finished with value: 9232122.178997671 and parameters: {'alpha': 70.91314578302637}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:32,503] Trial 143 finished with value: 8943241.602224167 and parameters: {'alpha': 28.876712025983768}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:32,542] Trial 144 finished with value: 8678104.885326117 and parameters: {'alpha': 43.96006043595449}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:32,619] Trial 145 finished with value: 9773315.487787303 and parameters: {'alpha': 15.38396482099538}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:32,648] Trial 146 finished with value: 9860790.079954924 and parameters: {'alpha': 108.28782059752969}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:32,694] Trial 147 finished with value: 9349822.772058975 and parameters: {'alpha': 21.48251100068559}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:32,731] Trial 148 finished with value: 8871215.223482404 and parameters: {'alpha': 59.10183115645347}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:32,839] Trial 149 finished with value: 10736567.904039389 and parameters: {'alpha': 7.166266613528595}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:32,868] Trial 150 finished with value: 8701000.898876106 and parameters: {'alpha': 35.891929820413516}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:32,902] Trial 151 finished with value: 8678379.688330092 and parameters: {'alpha': 43.98078424882681}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:32,943] Trial 152 finished with value: 9326576.305075962 and parameters: {'alpha': 79.64900390949968}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:33,010] Trial 153 finished with value: 9062994.98651573 and parameters: {'alpha': 26.213464882997684}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:33,044] Trial 154 finished with value: 8658426.524766134 and parameters: {'alpha': 42.168248297463684}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:33,094] Trial 155 finished with value: 8923946.977289498 and parameters: {'alpha': 60.79979176020697}. Best is trial 121 with value: 8648805.4638422.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.385e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:00:33,190] Trial 156 finished with value: 22161870.04764657 and parameters: {'alpha': 0.20212957144677504}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:33,222] Trial 157 finished with value: 8718395.425047187 and parameters: {'alpha': 35.03230467844655}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:33,293] Trial 158 finished with value: 10036378.696515411 and parameters: {'alpha': 13.588279275488244}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:33,327] Trial 159 finished with value: 9062685.745052364 and parameters: {'alpha': 26.22015244440145}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:33,361] Trial 160 finished with value: 11016019.2493748 and parameters: {'alpha': 162.10130560523768}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:33,405] Trial 161 finished with value: 8674857.629608044 and parameters: {'alpha': 43.708637979909355}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:33,445] Trial 162 finished with value: 9319209.233241394 and parameters: {'alpha': 79.04173888204646}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:33,495] Trial 163 finished with value: 9408024.717521954 and parameters: {'alpha': 20.543574072398847}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:33,527] Trial 164 finished with value: 8679811.045345379 and parameters: {'alpha': 48.30418685999507}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:33,559] Trial 165 finished with value: 8702774.839223819 and parameters: {'alpha': 35.80028065894067}. Best is trial 121 with value: 8648805.4638422.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.082e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:00:33,658] Trial 166 finished with value: 31681726.864985697 and parameters: {'alpha': 0.09912597762914659}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:33,691] Trial 167 finished with value: 9734800.410059378 and parameters: {'alpha': 103.02808612446077}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:33,738] Trial 168 finished with value: 8767400.908552451 and parameters: {'alpha': 54.90232799213587}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:33,819] Trial 169 finished with value: 9538773.046324885 and parameters: {'alpha': 18.15225502036834}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:33,922] Trial 170 finished with value: 9030209.345053978 and parameters: {'alpha': 26.94673499414631}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:33,956] Trial 171 finished with value: 8685924.093759587 and parameters: {'alpha': 44.52000333873909}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:34,005] Trial 172 finished with value: 9152043.241532728 and parameters: {'alpha': 66.82496699730544}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:34,038] Trial 173 finished with value: 8659610.83223471 and parameters: {'alpha': 39.05204479176345}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:34,089] Trial 174 finished with value: 8764630.506273348 and parameters: {'alpha': 33.32988044099512}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:34,125] Trial 175 finished with value: 9288746.304559791 and parameters: {'alpha': 76.41730629477092}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:34,171] Trial 176 finished with value: 9296965.798236122 and parameters: {'alpha': 22.250677384715306}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:34,207] Trial 177 finished with value: 8650225.91292353 and parameters: {'alpha': 40.394263216219}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:34,257] Trial 178 finished with value: 8835320.08803797 and parameters: {'alpha': 31.488965830715046}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:34,327] Trial 179 finished with value: 10337406.495336534 and parameters: {'alpha': 11.917326886029352}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:34,360] Trial 180 finished with value: 8686350.464366753 and parameters: {'alpha': 50.2195456505527}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:34,396] Trial 181 finished with value: 8655983.218527993 and parameters: {'alpha': 39.48981506944149}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:34,435] Trial 182 finished with value: 8740798.754556343 and parameters: {'alpha': 34.08749626533832}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:34,496] Trial 183 finished with value: 8885261.20458038 and parameters: {'alpha': 59.577562943173746}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:34,588] Trial 184 finished with value: 9655647.055684237 and parameters: {'alpha': 99.52090286407478}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:34,664] Trial 185 finished with value: 9229442.602880832 and parameters: {'alpha': 23.29697247646487}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:34,737] Trial 186 finished with value: 8654284.188832598 and parameters: {'alpha': 39.72174077383396}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:34,814] Trial 187 finished with value: 9650024.759590104 and parameters: {'alpha': 16.640411720022904}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:34,846] Trial 188 finished with value: 8682269.518868865 and parameters: {'alpha': 46.97004046188465}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:34,896] Trial 189 finished with value: 9044173.609366223 and parameters: {'alpha': 26.62972157765397}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:34,938] Trial 190 finished with value: 9270166.262946771 and parameters: {'alpha': 74.71346009661599}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:34,964] Trial 191 finished with value: 8676961.209767725 and parameters: {'alpha': 37.399017998732326}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:35,010] Trial 192 finished with value: 8775589.931712646 and parameters: {'alpha': 55.27159828975885}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:35,043] Trial 193 finished with value: 8653827.40341197 and parameters: {'alpha': 39.787962173996135}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:35,087] Trial 194 finished with value: 8984055.850403925 and parameters: {'alpha': 28.02012634038537}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:35,128] Trial 195 finished with value: 8657085.726400167 and parameters: {'alpha': 39.34954573757121}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:35,164] Trial 196 finished with value: 8954684.028871253 and parameters: {'alpha': 61.63163790098499}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:35,212] Trial 197 finished with value: 9351254.680603422 and parameters: {'alpha': 21.458744198842414}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:35,243] Trial 198 finished with value: 8666158.380600987 and parameters: {'alpha': 42.95852775287261}. Best is trial 121 with value: 8648805.4638422.\n",
      "[I 2024-01-08 17:00:35,288] Trial 199 finished with value: 8886095.703084432 and parameters: {'alpha': 30.160148729390546}. Best is trial 121 with value: 8648805.4638422.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Best Alpha (Lasso) from Optuna: 40.700753668423864\n",
      "Mean Squared Error with Lasso (using best alpha): 8648805.4638422\n",
      "r2 with Lasso (using best alpha): 0.8597804804550064\n",
      "\n",
      "                    0             1            2            3            4            5                     6                                 7                           8                            9                    10                  11                 12                 13                           14                15                16              17              18              19              20              21                     22                                23                             24                                25                               26                                       27                     28                     29                        30                             31                           32                           33                       34                          35                            36                                 37                  38                         39                         40                     41                    42                         43                       44                   45                          46                        47                           48                        49                     50                    51                           52                  53                 54                 55                 56                        57                 58                 59                 60                   61                        62                          63                        64                  65                     66                       67                      68                     69                         70                         71                            72                          73                            74                         75                      76                   77                   78                   79                   80                    81                    82                   83                   84                    85                   86                    87                    88                    89                   90                   91                        92                                 93                     94                        95                       96                                97                         98                                      99                        100                        101                     102                      103                    104                   105                    106               107                 108                109             110                  111                 112                113                114                115                    116                     117                    118                       119                                120                     121                          122                               123                              124                            125                    126                            127                             128                            129                      130                     131                     132                    133                     134                       135                                   136                          137                        138                           139                        140                               141                              142                        143                  144                      145                  146                147                148                  149                   150                151                152              153           154             155               156              157             158                  159              160                161            162            163             164             165             166                   167                  168              169               170           171             172              173              174               175                   176                  177                  178                 179                   180                    181                 182              183              184              185             186             187              188              189              190         191         192         193        194         195         196        197          198               199         200      201         202         203\n",
      "Variable  symboling_-2  symboling_-1  symboling_0  symboling_1  symboling_2  symboling_3  CarName_Nissan versa  CarName_alfa-romero Quadrifoglio  CarName_alfa-romero giulia  CarName_alfa-romero stelvio  CarName_audi 100 ls  CarName_audi 100ls  CarName_audi 4000  CarName_audi 5000  CarName_audi 5000s (diesel)  CarName_audi fox  CarName_bmw 320i  CarName_bmw x1  CarName_bmw x3  CarName_bmw x4  CarName_bmw x5  CarName_bmw z4  CarName_buick century  CarName_buick century luxus (sw)  CarName_buick century special  CarName_buick electra 225 custom  CarName_buick opel isuzu deluxe  CarName_buick regal sport coupe (turbo)  CarName_buick skyhawk  CarName_buick skylark  CarName_chevrolet impala  CarName_chevrolet monte carlo  CarName_chevrolet vega 2300  CarName_dodge challenger se  CarName_dodge colt (sw)  CarName_dodge colt hardtop  CarName_dodge coronet custom  CarName_dodge coronet custom (sw)  CarName_dodge d200  CarName_dodge dart custom  CarName_dodge monaco (sw)  CarName_dodge rampage  CarName_honda accord  CarName_honda accord cvcc  CarName_honda accord lx  CarName_honda civic  CarName_honda civic (auto)  CarName_honda civic 1300  CarName_honda civic 1500 gl  CarName_honda civic cvcc  CarName_honda prelude  CarName_isuzu D-Max   CarName_isuzu D-Max V-Cross  CarName_isuzu MU-X  CarName_jaguar xf  CarName_jaguar xj  CarName_jaguar xk  CarName_maxda glc deluxe  CarName_maxda rx3  CarName_mazda 626  CarName_mazda glc  CarName_mazda glc 4  CarName_mazda glc custom  CarName_mazda glc custom l  CarName_mazda glc deluxe  CarName_mazda rx-4  CarName_mazda rx-7 gs  CarName_mazda rx2 coupe  CarName_mercury cougar  CarName_mitsubishi g4  CarName_mitsubishi lancer  CarName_mitsubishi mirage  CarName_mitsubishi mirage g4  CarName_mitsubishi montero  CarName_mitsubishi outlander  CarName_mitsubishi pajero  CarName_nissan clipper  CarName_nissan dayz  CarName_nissan fuga  CarName_nissan gt-r  CarName_nissan juke  CarName_nissan kicks  CarName_nissan latio  CarName_nissan leaf  CarName_nissan note  CarName_nissan nv200  CarName_nissan otti  CarName_nissan rogue  CarName_nissan teana  CarName_nissan titan  CarName_peugeot 304  CarName_peugeot 504  CarName_peugeot 504 (sw)  CarName_peugeot 505s turbo diesel  CarName_peugeot 604sl  CarName_plymouth cricket  CarName_plymouth duster  CarName_plymouth fury gran sedan  CarName_plymouth fury iii  CarName_plymouth satellite custom (sw)  CarName_plymouth valiant  CarName_porcshce panamera  CarName_porsche boxter  CarName_porsche cayenne  CarName_porsche macan  CarName_renault 12tl  CarName_renault 5 gtl  CarName_saab 99e  CarName_saab 99gle  CarName_saab 99le  CarName_subaru  CarName_subaru baja  CarName_subaru brz  CarName_subaru dl  CarName_subaru r1  CarName_subaru r2  CarName_subaru trezia  CarName_subaru tribeca  CarName_toyota carina  CarName_toyota celica gt  CarName_toyota celica gt liftback  CarName_toyota corolla  CarName_toyota corolla 1200  CarName_toyota corolla 1600 (sw)  CarName_toyota corolla liftback  CarName_toyota corolla tercel  CarName_toyota corona  CarName_toyota corona hardtop  CarName_toyota corona liftback  CarName_toyota corona mark ii  CarName_toyota cressida  CarName_toyota mark ii  CarName_toyota starlet  CarName_toyota tercel  CarName_toyouta tercel  CarName_vokswagen rabbit  CarName_volkswagen 1131 deluxe sedan  CarName_volkswagen 411 (sw)  CarName_volkswagen dasher  CarName_volkswagen model 111  CarName_volkswagen rabbit  CarName_volkswagen rabbit custom  CarName_volkswagen super beetle  CarName_volkswagen type 3  CarName_volvo 144ea  CarName_volvo 145e (sw)  CarName_volvo 244dl  CarName_volvo 245  CarName_volvo 246  CarName_volvo 264gl  CarName_volvo diesel  CarName_vw dasher  CarName_vw rabbit  fueltype_diesel  fueltype_gas  aspiration_std  aspiration_turbo  doornumber_four  doornumber_two  carbody_convertible  carbody_hardtop  carbody_hatchback  carbody_sedan  carbody_wagon  drivewheel_4wd  drivewheel_fwd  drivewheel_rwd  enginelocation_front  enginelocation_rear  enginetype_dohc  enginetype_dohcv  enginetype_l  enginetype_ohc  enginetype_ohcf  enginetype_ohcv  enginetype_rotor  cylindernumber_eight  cylindernumber_five  cylindernumber_four  cylindernumber_six  cylindernumber_three  cylindernumber_twelve  cylindernumber_two  fuelsystem_1bbl  fuelsystem_2bbl  fuelsystem_4bbl  fuelsystem_idi  fuelsystem_mfi  fuelsystem_mpfi  fuelsystem_spdi  fuelsystem_spfi   wheelbase   carlength    carwidth  carheight  curbweight  enginesize  boreratio       stroke  compressionratio  horsepower  peakrpm     citympg  highwaympg\n",
      "Poids             -0.0   -179.036893          0.0   128.979906         -0.0          0.0                   0.0                               0.0                        -0.0                          0.0                  0.0                -0.0                0.0                0.0                         -0.0               0.0         694.36843             0.0      802.534996             0.0             0.0             0.0                    0.0                               0.0                            0.0                              -0.0                              0.0                                      0.0                    0.0                    0.0                       0.0                            0.0                          0.0                          0.0                      0.0                        -0.0                          -0.0                               -0.0                -0.0                       -0.0                        0.0                    0.0                   0.0                        0.0                     -0.0                  0.0                        -0.0                      -0.0                         -0.0                      -0.0                   -0.0                  -0.0                          0.0                -0.0                0.0                0.0               -0.0                       0.0               -0.0                0.0                0.0                  0.0                       0.0                         0.0                       0.0                 0.0                    0.0                      0.0                     0.0                   -0.0                       -0.0                        0.0                          -0.0                        -0.0                          -0.0                        0.0                     0.0                  0.0                 -0.0                  0.0                  0.0                  -0.0                   0.0                  0.0                  0.0                  -0.0                 -0.0                  -0.0                   0.0                   0.0                 -0.0                 -0.0                      -0.0                                0.0                    0.0                       0.0                     -0.0                               0.0                        0.0                                     0.0                      -0.0                        0.0                     0.0                      0.0                    0.0                   0.0                    0.0               0.0                 0.0               -0.0            -0.0                  0.0                -0.0               -0.0                0.0                0.0                   -0.0                     0.0                    0.0                      -0.0                               -0.0                    -0.0                          0.0                               0.0                             -0.0                           -0.0                    0.0                            0.0                            -0.0                           -0.0                     -0.0                     0.0             -636.334308                    0.0                     0.0                      -0.0                                   0.0                          0.0                        0.0                          -0.0                       -0.0                               0.0                              0.0                       -0.0                 -0.0              -122.863124                 -0.0                0.0               -0.0                  0.0                   0.0                0.0                0.0              0.0          -0.0            -0.0               0.0         7.245277            -0.0          3233.973384             -0.0               -0.0     716.693989     -89.226865            -0.0            -0.0      1114.74163          -6534.456127                  0.0             -0.0               0.0   -854.754849     1134.303548              0.0      -3454.16592               0.0           3418.183377                 -0.0         -3052.767746                 0.0                   0.0                   -0.0                 0.0             -0.0        93.361983              0.0             0.0            -0.0              0.0       -386.77849             -0.0  157.441213 -116.942595  572.192939  96.528896    2.933109   75.393875       -0.0 -2057.118284        175.797963   31.057408   1.2699 -227.411857  139.686469\n"
     ]
    }
   ],
   "source": [
    "alpha_values = []\n",
    "mse_scores = []\n",
    "\n",
    "def objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-4, 1000, log=True)  # dans un espace logarithmique\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    y_pred = lasso.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # enregistrement de alpha et du mse correspondant\n",
    "    alpha_values.append(alpha)\n",
    "    mse_scores.append(mse)\n",
    "\n",
    "    return mse\n",
    "\n",
    "# Lancement de l'optimisation Optuna\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=200)\n",
    "\n",
    "# Récupération du meilleur alpha d'Optuna\n",
    "best_alpha = study.best_params['alpha']\n",
    "\n",
    "# TEntraînement du modèle avec le meilleur alpha\n",
    "best_lasso = Lasso(alpha=best_alpha)\n",
    "best_lasso.fit(X_train, y_train)\n",
    "y_pred = best_lasso.predict(X_test)\n",
    "\n",
    "# Calcul des métriques\n",
    "mse_lasso = mean_squared_error(y_test, y_pred)\n",
    "r2_lasso = r2_score(y_test, y_pred)\n",
    "\n",
    "print('\\n')\n",
    "print(f\"Best Alpha (Lasso) from Optuna: {best_alpha}\")\n",
    "print(f\"Mean Squared Error with Lasso (using best alpha): {mse_lasso}\")\n",
    "print(f\"r2 with Lasso (using best alpha): {r2_lasso}\")\n",
    "\n",
    "affichage_poids(best_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the R2 scores against alpha values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(alpha_values, mse_scores, marker='o')\n",
    "plt.plot(best_alpha, mse_lasso, marker='o', markersize=8, color='red')  # Point le plus optimisé (toujours montré en rouge)\n",
    "plt.title('MSE vs Alpha Values')\n",
    "plt.xlabel('Alpha Values')\n",
    "plt.ylabel('MSE Score')\n",
    "plt.xscale('log')  # Puisque alpha est dans un espace logarithmique\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge\n",
    "Ridge utilise une pénalité L2 dans sa fonction de coût, par opposition à la pénalité L1 utilisée par Lasso. Cette pénalité favorise des coefficients plus petits sans les annuler complètement, contrairement à Lasso. Ridge maintient donc chaque variable dans le modèle.\n",
    "Ridge utilise donc une autre approche de régularisation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 17:01:43,668] A new study created in memory with name: no-name-e9eaf8dd-fcfc-4a98-b2fd-4d2c689598c4\n",
      "[I 2024-01-08 17:01:43,715] Trial 0 finished with value: 9954550.425541172 and parameters: {'alpha': 4.665841772033686}. Best is trial 0 with value: 9954550.425541172.\n",
      "[I 2024-01-08 17:01:43,730] Trial 1 finished with value: 180084801.46980357 and parameters: {'alpha': 0.0001503211996554319}. Best is trial 0 with value: 9954550.425541172.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 17:01:43,747] Trial 2 finished with value: 11629621.72302855 and parameters: {'alpha': 214.10252892782609}. Best is trial 0 with value: 9954550.425541172.\n",
      "[I 2024-01-08 17:01:43,776] Trial 3 finished with value: 54870891.99234842 and parameters: {'alpha': 0.0006689664812140052}. Best is trial 0 with value: 9954550.425541172.\n",
      "[I 2024-01-08 17:01:43,791] Trial 4 finished with value: 11599437.064947523 and parameters: {'alpha': 175.87914812852296}. Best is trial 0 with value: 9954550.425541172.\n",
      "[I 2024-01-08 17:01:43,816] Trial 5 finished with value: 10228987.727501461 and parameters: {'alpha': 7.8401050921024575}. Best is trial 0 with value: 9954550.425541172.\n",
      "[I 2024-01-08 17:01:43,831] Trial 6 finished with value: 18812595.620158054 and parameters: {'alpha': 0.003680188263901513}. Best is trial 0 with value: 9954550.425541172.\n",
      "[I 2024-01-08 17:01:43,868] Trial 7 finished with value: 10733910.812267108 and parameters: {'alpha': 17.837567407157962}. Best is trial 0 with value: 9954550.425541172.\n",
      "[I 2024-01-08 17:01:43,898] Trial 8 finished with value: 134572302.21791154 and parameters: {'alpha': 0.0002359764816354642}. Best is trial 0 with value: 9954550.425541172.\n",
      "[I 2024-01-08 17:01:43,929] Trial 9 finished with value: 9752963.43005471 and parameters: {'alpha': 2.2613661526980535}. Best is trial 9 with value: 9752963.43005471.\n",
      "[I 2024-01-08 17:01:43,970] Trial 10 finished with value: 11569028.011922875 and parameters: {'alpha': 0.1287373682634357}. Best is trial 9 with value: 9752963.43005471.\n",
      "[I 2024-01-08 17:01:44,024] Trial 11 finished with value: 10393773.394047482 and parameters: {'alpha': 0.4026921320813349}. Best is trial 9 with value: 9752963.43005471.\n",
      "[I 2024-01-08 17:01:44,057] Trial 12 finished with value: 10283681.66614934 and parameters: {'alpha': 0.46516471789347513}. Best is trial 9 with value: 9752963.43005471.\n",
      "[I 2024-01-08 17:01:44,078] Trial 13 finished with value: 9767913.683740024 and parameters: {'alpha': 2.5494342820692}. Best is trial 9 with value: 9752963.43005471.\n",
      "[I 2024-01-08 17:01:44,097] Trial 14 finished with value: 14232673.422551816 and parameters: {'alpha': 0.022762567302430627}. Best is trial 9 with value: 9752963.43005471.\n",
      "[I 2024-01-08 17:01:44,116] Trial 15 finished with value: 9758509.555490172 and parameters: {'alpha': 2.382576151556017}. Best is trial 9 with value: 9752963.43005471.\n",
      "[I 2024-01-08 17:01:44,138] Trial 16 finished with value: 11166034.954868952 and parameters: {'alpha': 40.899565696638334}. Best is trial 9 with value: 9752963.43005471.\n",
      "[I 2024-01-08 17:01:44,163] Trial 17 finished with value: 12913640.321137711 and parameters: {'alpha': 0.049726286546092166}. Best is trial 9 with value: 9752963.43005471.\n",
      "[I 2024-01-08 17:01:44,181] Trial 18 finished with value: 9764459.836289927 and parameters: {'alpha': 1.4762594279542915}. Best is trial 9 with value: 9752963.43005471.\n",
      "[I 2024-01-08 17:01:44,200] Trial 19 finished with value: 15791292.243500575 and parameters: {'alpha': 0.010207466097495172}. Best is trial 9 with value: 9752963.43005471.\n",
      "[I 2024-01-08 17:01:44,218] Trial 20 finished with value: 11724416.302336201 and parameters: {'alpha': 596.7825770436004}. Best is trial 9 with value: 9752963.43005471.\n",
      "[I 2024-01-08 17:01:44,238] Trial 21 finished with value: 9750813.785692832 and parameters: {'alpha': 1.6671026261600814}. Best is trial 21 with value: 9750813.785692832.\n",
      "[I 2024-01-08 17:01:44,261] Trial 22 finished with value: 9895189.61037697 and parameters: {'alpha': 0.9188829881203302}. Best is trial 21 with value: 9750813.785692832.\n",
      "[I 2024-01-08 17:01:44,282] Trial 23 finished with value: 10824134.422962025 and parameters: {'alpha': 20.82982834313865}. Best is trial 21 with value: 9750813.785692832.\n",
      "[I 2024-01-08 17:01:44,302] Trial 24 finished with value: 11209501.046022216 and parameters: {'alpha': 0.1738757086385203}. Best is trial 21 with value: 9750813.785692832.\n",
      "[I 2024-01-08 17:01:44,323] Trial 25 finished with value: 11348084.675614173 and parameters: {'alpha': 65.04195959228828}. Best is trial 21 with value: 9750813.785692832.\n",
      "[I 2024-01-08 17:01:44,342] Trial 26 finished with value: 10118354.682910278 and parameters: {'alpha': 6.465191343892969}. Best is trial 21 with value: 9750813.785692832.\n",
      "[I 2024-01-08 17:01:44,363] Trial 27 finished with value: 9785656.98680712 and parameters: {'alpha': 1.3114115808161735}. Best is trial 21 with value: 9750813.785692832.\n",
      "[I 2024-01-08 17:01:44,384] Trial 28 finished with value: 12388763.626723783 and parameters: {'alpha': 0.07034840737008557}. Best is trial 21 with value: 9750813.785692832.\n",
      "[I 2024-01-08 17:01:44,402] Trial 29 finished with value: 10121502.598117232 and parameters: {'alpha': 6.502132840299045}. Best is trial 21 with value: 9750813.785692832.\n",
      "[I 2024-01-08 17:01:44,429] Trial 30 finished with value: 9775580.242435476 and parameters: {'alpha': 2.667466235914435}. Best is trial 21 with value: 9750813.785692832.\n",
      "[I 2024-01-08 17:01:44,447] Trial 31 finished with value: 9843728.1209022 and parameters: {'alpha': 1.0578573138209098}. Best is trial 21 with value: 9750813.785692832.\n",
      "[I 2024-01-08 17:01:44,466] Trial 32 finished with value: 10616910.873014683 and parameters: {'alpha': 0.3098921370874092}. Best is trial 21 with value: 9750813.785692832.\n",
      "[I 2024-01-08 17:01:44,485] Trial 33 finished with value: 9752445.948285632 and parameters: {'alpha': 2.2484437073546286}. Best is trial 21 with value: 9750813.785692832.\n",
      "[I 2024-01-08 17:01:44,506] Trial 34 finished with value: 10733613.26428263 and parameters: {'alpha': 17.82862099960179}. Best is trial 21 with value: 9750813.785692832.\n",
      "[I 2024-01-08 17:01:44,530] Trial 35 finished with value: 9774290.91420991 and parameters: {'alpha': 2.6483838247841724}. Best is trial 21 with value: 9750813.785692832.\n",
      "[I 2024-01-08 17:01:44,548] Trial 36 finished with value: 11581285.763845677 and parameters: {'alpha': 158.58680821425276}. Best is trial 21 with value: 9750813.785692832.\n",
      "[I 2024-01-08 17:01:44,569] Trial 37 finished with value: 10010454.764504949 and parameters: {'alpha': 5.258059216007943}. Best is trial 21 with value: 9750813.785692832.\n",
      "[I 2024-01-08 17:01:44,590] Trial 38 finished with value: 9994647.153513482 and parameters: {'alpha': 0.7394407597169865}. Best is trial 21 with value: 9750813.785692832.\n",
      "[I 2024-01-08 17:01:44,612] Trial 39 finished with value: 11293250.10016815 and parameters: {'alpha': 55.87531232946675}. Best is trial 21 with value: 9750813.785692832.\n",
      "[I 2024-01-08 17:01:44,632] Trial 40 finished with value: 10461219.232483795 and parameters: {'alpha': 11.44258517003138}. Best is trial 21 with value: 9750813.785692832.\n",
      "[I 2024-01-08 17:01:44,653] Trial 41 finished with value: 9758315.591385312 and parameters: {'alpha': 1.5458805786381196}. Best is trial 21 with value: 9750813.785692832.\n",
      "[I 2024-01-08 17:01:44,676] Trial 42 finished with value: 11053042.364995312 and parameters: {'alpha': 0.20013027616022847}. Best is trial 21 with value: 9750813.785692832.\n",
      "[I 2024-01-08 17:01:44,699] Trial 43 finished with value: 9758251.546301473 and parameters: {'alpha': 2.3774562207801004}. Best is trial 21 with value: 9750813.785692832.\n",
      "[I 2024-01-08 17:01:44,717] Trial 44 finished with value: 9901133.024382124 and parameters: {'alpha': 4.108097683919035}. Best is trial 21 with value: 9750813.785692832.\n",
      "[I 2024-01-08 17:01:44,736] Trial 45 finished with value: 10108938.760100849 and parameters: {'alpha': 0.6033908086826882}. Best is trial 21 with value: 9750813.785692832.\n",
      "[I 2024-01-08 17:01:44,761] Trial 46 finished with value: 11976674.620098218 and parameters: {'alpha': 0.0942370873975536}. Best is trial 21 with value: 9750813.785692832.\n",
      "[I 2024-01-08 17:01:44,816] Trial 47 finished with value: 10556983.527716236 and parameters: {'alpha': 0.33138983868211885}. Best is trial 21 with value: 9750813.785692832.\n",
      "[I 2024-01-08 17:01:44,867] Trial 48 finished with value: 29458096.77571501 and parameters: {'alpha': 0.0013849966713575333}. Best is trial 21 with value: 9750813.785692832.\n",
      "[I 2024-01-08 17:01:44,910] Trial 49 finished with value: 10439957.163224773 and parameters: {'alpha': 11.059795824783924}. Best is trial 21 with value: 9750813.785692832.\n",
      "[I 2024-01-08 17:01:44,969] Trial 50 finished with value: 9745781.998996919 and parameters: {'alpha': 1.8432786392984273}. Best is trial 50 with value: 9745781.998996919.\n",
      "[I 2024-01-08 17:01:45,018] Trial 51 finished with value: 9748990.151204955 and parameters: {'alpha': 1.7104459422605962}. Best is trial 50 with value: 9745781.998996919.\n",
      "[I 2024-01-08 17:01:45,065] Trial 52 finished with value: 9786088.771614732 and parameters: {'alpha': 2.8145962808906946}. Best is trial 50 with value: 9745781.998996919.\n",
      "[I 2024-01-08 17:01:45,112] Trial 53 finished with value: 10358109.840267528 and parameters: {'alpha': 0.4214023393529955}. Best is trial 50 with value: 9745781.998996919.\n",
      "[I 2024-01-08 17:01:45,150] Trial 54 finished with value: 10820920.467352353 and parameters: {'alpha': 20.712752830571016}. Best is trial 50 with value: 9745781.998996919.\n",
      "[I 2024-01-08 17:01:45,263] Trial 55 finished with value: 13714623.505648663 and parameters: {'alpha': 0.030540468791440612}. Best is trial 50 with value: 9745781.998996919.\n",
      "[I 2024-01-08 17:01:45,298] Trial 56 finished with value: 9755866.016929166 and parameters: {'alpha': 1.5793086353286445}. Best is trial 50 with value: 9745781.998996919.\n",
      "[I 2024-01-08 17:01:45,326] Trial 57 finished with value: 10007001.505652651 and parameters: {'alpha': 0.7220251755753183}. Best is trial 50 with value: 9745781.998996919.\n",
      "[I 2024-01-08 17:01:45,350] Trial 58 finished with value: 11033650.61433274 and parameters: {'alpha': 0.20375039958871063}. Best is trial 50 with value: 9745781.998996919.\n",
      "[I 2024-01-08 17:01:45,384] Trial 59 finished with value: 9759177.387708144 and parameters: {'alpha': 1.5350382836046212}. Best is trial 50 with value: 9745781.998996919.\n",
      "[I 2024-01-08 17:01:45,409] Trial 60 finished with value: 11060019.025118673 and parameters: {'alpha': 32.526612435414165}. Best is trial 50 with value: 9745781.998996919.\n",
      "[I 2024-01-08 17:01:45,438] Trial 61 finished with value: 9924050.416932698 and parameters: {'alpha': 4.347280491008928}. Best is trial 50 with value: 9745781.998996919.\n",
      "[I 2024-01-08 17:01:45,467] Trial 62 finished with value: 9746055.499490837 and parameters: {'alpha': 1.8232225366311934}. Best is trial 50 with value: 9745781.998996919.\n",
      "[I 2024-01-08 17:01:45,498] Trial 63 finished with value: 9824610.506649101 and parameters: {'alpha': 1.1247486712689907}. Best is trial 50 with value: 9745781.998996919.\n",
      "[I 2024-01-08 17:01:45,529] Trial 64 finished with value: 10365065.607405271 and parameters: {'alpha': 9.806308632975018}. Best is trial 50 with value: 9745781.998996919.\n",
      "[I 2024-01-08 17:01:45,562] Trial 65 finished with value: 9745388.479906136 and parameters: {'alpha': 1.9387803811500803}. Best is trial 65 with value: 9745388.479906136.\n",
      "[I 2024-01-08 17:01:45,584] Trial 66 finished with value: 9883562.51708288 and parameters: {'alpha': 3.923801189925046}. Best is trial 65 with value: 9745388.479906136.\n",
      "[I 2024-01-08 17:01:45,618] Trial 67 finished with value: 10131850.300716976 and parameters: {'alpha': 0.5814922487064399}. Best is trial 65 with value: 9745388.479906136.\n",
      "[I 2024-01-08 17:01:45,648] Trial 68 finished with value: 10242427.791028745 and parameters: {'alpha': 8.019269744288204}. Best is trial 65 with value: 9745388.479906136.\n",
      "[I 2024-01-08 17:01:45,678] Trial 69 finished with value: 10604079.752189152 and parameters: {'alpha': 0.31431884767143686}. Best is trial 65 with value: 9745388.479906136.\n",
      "[I 2024-01-08 17:01:45,704] Trial 70 finished with value: 9746991.593384411 and parameters: {'alpha': 2.069516849088686}. Best is trial 65 with value: 9745388.479906136.\n",
      "[I 2024-01-08 17:01:45,737] Trial 71 finished with value: 9745566.569100337 and parameters: {'alpha': 1.9706936417496086}. Best is trial 65 with value: 9745388.479906136.\n",
      "[I 2024-01-08 17:01:45,766] Trial 72 finished with value: 9880766.633049354 and parameters: {'alpha': 0.9532586768009533}. Best is trial 65 with value: 9745388.479906136.\n",
      "[I 2024-01-08 17:01:45,798] Trial 73 finished with value: 9746190.964337664 and parameters: {'alpha': 1.814829026820089}. Best is trial 65 with value: 9745388.479906136.\n",
      "[I 2024-01-08 17:01:45,819] Trial 74 finished with value: 10035292.15665967 and parameters: {'alpha': 5.52705052248401}. Best is trial 65 with value: 9745388.479906136.\n",
      "[I 2024-01-08 17:01:45,852] Trial 75 finished with value: 9832135.526750602 and parameters: {'alpha': 3.3691043601265602}. Best is trial 65 with value: 9745388.479906136.\n",
      "[I 2024-01-08 17:01:45,965] Trial 76 finished with value: 9746325.470464375 and parameters: {'alpha': 1.8071772665742005}. Best is trial 65 with value: 9745388.479906136.\n",
      "[I 2024-01-08 17:01:46,063] Trial 77 finished with value: 9895399.29043203 and parameters: {'alpha': 0.9184042881526575}. Best is trial 65 with value: 9745388.479906136.\n",
      "[I 2024-01-08 17:01:46,095] Trial 78 finished with value: 10529935.245199172 and parameters: {'alpha': 12.773574393553895}. Best is trial 65 with value: 9745388.479906136.\n",
      "[I 2024-01-08 17:01:46,161] Trial 79 finished with value: 9746967.59682788 and parameters: {'alpha': 1.7767230260556162}. Best is trial 65 with value: 9745388.479906136.\n",
      "[I 2024-01-08 17:01:46,181] Trial 80 finished with value: 10349943.107574234 and parameters: {'alpha': 0.4258784973065999}. Best is trial 65 with value: 9745388.479906136.\n",
      "[I 2024-01-08 17:01:46,215] Trial 81 finished with value: 9745434.68499428 and parameters: {'alpha': 1.9500583893573067}. Best is trial 65 with value: 9745388.479906136.\n",
      "[I 2024-01-08 17:01:46,244] Trial 82 finished with value: 9745363.961285017 and parameters: {'alpha': 1.9046853536569652}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:46,267] Trial 83 finished with value: 10087195.449300662 and parameters: {'alpha': 0.6255658296499848}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:46,304] Trial 84 finished with value: 9860267.927274782 and parameters: {'alpha': 3.676517438078555}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:46,329] Trial 85 finished with value: 10117597.364503507 and parameters: {'alpha': 6.456320857678905}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:46,359] Trial 86 finished with value: 11553193.64809176 and parameters: {'alpha': 0.13037950935539083}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:46,386] Trial 87 finished with value: 9806992.770639775 and parameters: {'alpha': 1.198266346499877}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:46,416] Trial 88 finished with value: 9746354.375288013 and parameters: {'alpha': 2.0351958771576006}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:46,442] Trial 89 finished with value: 10945039.33648976 and parameters: {'alpha': 0.22148586665172448}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:46,469] Trial 90 finished with value: 9806948.46073227 and parameters: {'alpha': 3.07806357702748}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:46,500] Trial 91 finished with value: 9750076.360514646 and parameters: {'alpha': 2.1833051083824664}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:46,531] Trial 92 finished with value: 166322694.8359945 and parameters: {'alpha': 0.00017179826480794955}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:46,561] Trial 93 finished with value: 9842239.372329751 and parameters: {'alpha': 1.062684815145014}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:46,585] Trial 94 finished with value: 10049265.244751086 and parameters: {'alpha': 5.680428854628433}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:46,620] Trial 95 finished with value: 9746167.730896916 and parameters: {'alpha': 1.8162148531630682}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:46,645] Trial 96 finished with value: 10206198.158938525 and parameters: {'alpha': 0.5190963157162312}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:46,679] Trial 97 finished with value: 10588294.528133605 and parameters: {'alpha': 14.032440156787311}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:46,703] Trial 98 finished with value: 9947640.768792273 and parameters: {'alpha': 0.8141398949056828}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:46,732] Trial 99 finished with value: 10269968.118068334 and parameters: {'alpha': 8.395840939393922}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:46,766] Trial 100 finished with value: 9787931.300761655 and parameters: {'alpha': 2.8391467774616532}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:46,794] Trial 101 finished with value: 9769570.209198458 and parameters: {'alpha': 1.4284787996517365}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:46,820] Trial 102 finished with value: 9745380.349317083 and parameters: {'alpha': 1.8978864557556585}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:46,850] Trial 103 finished with value: 9904318.70359318 and parameters: {'alpha': 4.14139597259415}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:46,878] Trial 104 finished with value: 9746586.460073344 and parameters: {'alpha': 2.0486288834666553}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:46,911] Trial 105 finished with value: 9796412.006638987 and parameters: {'alpha': 1.2501655117225678}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:46,935] Trial 106 finished with value: 11754013.702809975 and parameters: {'alpha': 959.7236526113725}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:46,968] Trial 107 finished with value: 9956436.641693616 and parameters: {'alpha': 0.7990133213819184}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,001] Trial 108 finished with value: 9774535.13651929 and parameters: {'alpha': 2.6520192235663873}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,027] Trial 109 finished with value: 9973802.81979648 and parameters: {'alpha': 4.868150985123783}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,053] Trial 110 finished with value: 10641664.349023422 and parameters: {'alpha': 0.3016059061280307}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,080] Trial 111 finished with value: 9745975.762779292 and parameters: {'alpha': 1.828566384648752}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,114] Trial 112 finished with value: 9745489.240050728 and parameters: {'alpha': 1.9597748109769073}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,144] Trial 113 finished with value: 9758843.21229262 and parameters: {'alpha': 1.539192397500454}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,177] Trial 114 finished with value: 9860540.136990048 and parameters: {'alpha': 3.6794358395251034}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,199] Trial 115 finished with value: 10035101.258358976 and parameters: {'alpha': 0.6852204231058459}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,230] Trial 116 finished with value: 9799433.61945555 and parameters: {'alpha': 1.2346143252169215}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,260] Trial 117 finished with value: 10202404.540300164 and parameters: {'alpha': 7.494104854214039}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,284] Trial 118 finished with value: 10191875.751772024 and parameters: {'alpha': 0.530204729611172}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,318] Trial 119 finished with value: 9790980.57124137 and parameters: {'alpha': 2.8791233244772485}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,352] Trial 120 finished with value: 9868292.90198891 and parameters: {'alpha': 0.9855523480781336}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,378] Trial 121 finished with value: 9748341.75759073 and parameters: {'alpha': 2.125893049064797}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,414] Trial 122 finished with value: 9746961.698958805 and parameters: {'alpha': 2.0680639048986813}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,450] Trial 123 finished with value: 9758183.382873898 and parameters: {'alpha': 1.5475822808427813}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,470] Trial 124 finished with value: 9953156.929884547 and parameters: {'alpha': 4.651246704905752}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,510] Trial 125 finished with value: 9747064.661225304 and parameters: {'alpha': 1.7727332119246937}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,534] Trial 126 finished with value: 9826894.641317768 and parameters: {'alpha': 3.3101422401350975}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,567] Trial 127 finished with value: 9886689.010388702 and parameters: {'alpha': 0.9387862830997522}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,598] Trial 128 finished with value: 10062426.688699039 and parameters: {'alpha': 5.826393773885761}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,632] Trial 129 finished with value: 9808998.440611681 and parameters: {'alpha': 1.1891686557212104}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,658] Trial 130 finished with value: 9754173.497123221 and parameters: {'alpha': 2.290241595237408}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,682] Trial 131 finished with value: 9747437.298672609 and parameters: {'alpha': 1.7584532584763535}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,711] Trial 132 finished with value: 9772811.84659802 and parameters: {'alpha': 2.6261475395071585}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,750] Trial 133 finished with value: 9988982.58385016 and parameters: {'alpha': 0.7477044734323214}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,770] Trial 134 finished with value: 9845604.637861636 and parameters: {'alpha': 3.5179079091450887}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,806] Trial 135 finished with value: 10435686.717874741 and parameters: {'alpha': 0.3823016281914613}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,849] Trial 136 finished with value: 9747824.797349012 and parameters: {'alpha': 2.1060398782001557}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,870] Trial 137 finished with value: 9957365.783127034 and parameters: {'alpha': 4.695346392087814}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,898] Trial 138 finished with value: 9792378.242526047 and parameters: {'alpha': 1.271974416947204}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:47,930] Trial 139 finished with value: 10181987.06348056 and parameters: {'alpha': 0.5381105275457708}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:48,031] Trial 140 finished with value: 10213708.820511477 and parameters: {'alpha': 7.639915477745062}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:48,062] Trial 141 finished with value: 9745732.751371795 and parameters: {'alpha': 1.9889283152890125}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:48,092] Trial 142 finished with value: 9745454.468892934 and parameters: {'alpha': 1.953869522235936}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:48,127] Trial 143 finished with value: 9764461.585761648 and parameters: {'alpha': 1.4762417591342007}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:48,165] Trial 144 finished with value: 9802457.377454147 and parameters: {'alpha': 3.0235991954212684}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:48,193] Trial 145 finished with value: 16762543.274726776 and parameters: {'alpha': 0.00670060354497288}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:48,219] Trial 146 finished with value: 9913062.374268135 and parameters: {'alpha': 0.8800058092351305}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:48,252] Trial 147 finished with value: 9746660.89604001 and parameters: {'alpha': 1.7902561305502056}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:48,279] Trial 148 finished with value: 9874645.24438853 and parameters: {'alpha': 3.8296535333693367}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:48,310] Trial 149 finished with value: 9820579.481121967 and parameters: {'alpha': 1.1404035107247492}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:48,337] Trial 150 finished with value: 9772566.95351285 and parameters: {'alpha': 2.6224281372338245}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:48,370] Trial 151 finished with value: 9746858.037380658 and parameters: {'alpha': 2.0629264989529705}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:48,404] Trial 152 finished with value: 9776474.36949424 and parameters: {'alpha': 1.3733367927519236}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:48,443] Trial 153 finished with value: 9749894.353461077 and parameters: {'alpha': 2.1777756433880984}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:48,481] Trial 154 finished with value: 9972006.541984154 and parameters: {'alpha': 0.7736077953953824}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:48,515] Trial 155 finished with value: 9841383.023519563 and parameters: {'alpha': 3.471641525389341}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:48,558] Trial 156 finished with value: 10019356.1132583 and parameters: {'alpha': 5.353960740568746}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:48,596] Trial 157 finished with value: 9846544.211293228 and parameters: {'alpha': 1.0488807631128174}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:48,628] Trial 158 finished with value: 9760645.837452788 and parameters: {'alpha': 1.5174764083590007}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:48,660] Trial 159 finished with value: 74621029.25964393 and parameters: {'alpha': 0.0004810800305783531}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:48,695] Trial 160 finished with value: 9775543.852777213 and parameters: {'alpha': 2.666931318348618}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:48,723] Trial 161 finished with value: 9746538.35319099 and parameters: {'alpha': 1.7961358789932116}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:48,750] Trial 162 finished with value: 9746293.377209112 and parameters: {'alpha': 1.808949392106034}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:48,782] Trial 163 finished with value: 9745551.983207462 and parameters: {'alpha': 1.8664152736115716}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:48,809] Trial 164 finished with value: 9826135.857042162 and parameters: {'alpha': 1.1189817623444291}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:48,845] Trial 165 finished with value: 9926310.452720184 and parameters: {'alpha': 4.370848020966034}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:48,876] Trial 166 finished with value: 10069993.886779306 and parameters: {'alpha': 0.644174361073353}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:48,907] Trial 167 finished with value: 9785164.451246284 and parameters: {'alpha': 2.8021593445015203}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:48,935] Trial 168 finished with value: 9750568.691616036 and parameters: {'alpha': 1.6723931920276536}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:48,965] Trial 169 finished with value: 9881269.663197778 and parameters: {'alpha': 0.9520090289967752}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:48,999] Trial 170 finished with value: 9758779.018862166 and parameters: {'alpha': 2.387882211867872}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:49,019] Trial 171 finished with value: 9757257.71946087 and parameters: {'alpha': 1.5598049520210895}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:49,059] Trial 172 finished with value: 9745564.592668254 and parameters: {'alpha': 1.8648655675629355}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:49,086] Trial 173 finished with value: 9849162.058468571 and parameters: {'alpha': 3.556666488605647}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:49,117] Trial 174 finished with value: 9792802.896398513 and parameters: {'alpha': 1.269618008391007}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:49,149] Trial 175 finished with value: 9749961.805785095 and parameters: {'alpha': 2.179835905362941}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:49,179] Trial 176 finished with value: 9786861.371912505 and parameters: {'alpha': 2.824928865362504}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:49,212] Trial 177 finished with value: 10053013.36906981 and parameters: {'alpha': 5.721844302673597}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:49,244] Trial 178 finished with value: 9946877.812634274 and parameters: {'alpha': 0.8154801375017376}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:49,273] Trial 179 finished with value: 9745460.094306357 and parameters: {'alpha': 1.8796943154539194}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:49,303] Trial 180 finished with value: 9758718.567265192 and parameters: {'alpha': 1.5407578409600873}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:49,334] Trial 181 finished with value: 9747370.64633315 and parameters: {'alpha': 2.086983977884111}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:49,368] Trial 182 finished with value: 9788895.625048703 and parameters: {'alpha': 1.2918828521084924}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:49,400] Trial 183 finished with value: 9843028.328318734 and parameters: {'alpha': 3.4897099526084117}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:49,433] Trial 184 finished with value: 9747209.37719691 and parameters: {'alpha': 1.7670050023575212}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:49,497] Trial 185 finished with value: 9773129.96946276 and parameters: {'alpha': 2.630962840055718}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:49,536] Trial 186 finished with value: 9852491.817903943 and parameters: {'alpha': 1.0305538128906855}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:49,585] Trial 187 finished with value: 9922033.308652591 and parameters: {'alpha': 4.326246666417483}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:49,628] Trial 188 finished with value: 9745427.73751065 and parameters: {'alpha': 1.9486151225981643}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:49,668] Trial 189 finished with value: 9786672.175072849 and parameters: {'alpha': 1.3051774358291828}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:49,702] Trial 190 finished with value: 10081788.785416305 and parameters: {'alpha': 0.6313085173938153}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:49,747] Trial 191 finished with value: 9749399.382963812 and parameters: {'alpha': 2.162229205220032}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:49,787] Trial 192 finished with value: 9745625.369329272 and parameters: {'alpha': 1.8579866555964937}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:49,843] Trial 193 finished with value: 9789492.536077425 and parameters: {'alpha': 2.8597121057765134}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:49,884] Trial 194 finished with value: 9764931.01583663 and parameters: {'alpha': 1.4715372208187585}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:49,917] Trial 195 finished with value: 9745953.669163331 and parameters: {'alpha': 1.8301097312887276}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:49,950] Trial 196 finished with value: 9892529.61489997 and parameters: {'alpha': 0.9250057989359763}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:49,980] Trial 197 finished with value: 9745472.393160153 and parameters: {'alpha': 1.877646249447061}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:50,093] Trial 198 finished with value: 9813526.258190857 and parameters: {'alpha': 3.1561820712493103}. Best is trial 82 with value: 9745363.961285017.\n",
      "[I 2024-01-08 17:01:50,128] Trial 199 finished with value: 9810961.938700523 and parameters: {'alpha': 1.1804631273966497}. Best is trial 82 with value: 9745363.961285017.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Meilleur Alpha pour Ridge (Optuna) : 1.9046853536569652\n",
      "Erreur quadratique moyenne avec Ridge (utilisant le meilleur alpha d'Optuna) : 9745363.961285017\n",
      "r2 avec Ridge (utilisant le meilleur alpha d'Optuna) : 0.8420024293348574\n",
      "\n",
      "                    0             1            2            3            4            5                     6                                 7                           8                            9                    10                  11                 12                 13                           14                15                16              17              18              19              20              21                     22                                23                             24                                25                               26                                       27                     28                     29                        30                             31                           32                           33                       34                          35                            36                                 37                  38                         39                         40                     41                    42                         43                       44                   45                          46                        47                           48                        49                     50                    51                           52                  53                 54                 55                 56                        57                 58                 59                 60                   61                        62                          63                        64                  65                     66                       67                      68                     69                         70                         71                            72                          73                            74                         75                      76                   77                   78                   79                   80                    81                    82                   83                   84                    85                   86                    87                    88                    89                   90                   91                        92                                 93                     94                        95                       96                                97                         98                                      99                        100                        101                     102                      103                    104                   105                    106               107                 108                109             110                  111                 112                113                114                115                    116                     117                    118                       119                                120                     121                          122                               123                              124                            125                    126                            127                             128                            129                      130                     131                     132                    133                     134                       135                                   136                          137                        138                           139                        140                               141                              142                        143                  144                      145                  146                147                148                  149                   150                151                152              153           154             155               156              157             158                  159              160                161            162            163             164             165             166                   167                  168              169               170           171             172              173              174               175                   176                  177                  178                 179                   180                    181                 182              183              184              185             186             187              188              189              190         191        192         193         194         195         196         197          198               199         200       201        202         203\n",
      "Variable  symboling_-2  symboling_-1  symboling_0  symboling_1  symboling_2  symboling_3  CarName_Nissan versa  CarName_alfa-romero Quadrifoglio  CarName_alfa-romero giulia  CarName_alfa-romero stelvio  CarName_audi 100 ls  CarName_audi 100ls  CarName_audi 4000  CarName_audi 5000  CarName_audi 5000s (diesel)  CarName_audi fox  CarName_bmw 320i  CarName_bmw x1  CarName_bmw x3  CarName_bmw x4  CarName_bmw x5  CarName_bmw z4  CarName_buick century  CarName_buick century luxus (sw)  CarName_buick century special  CarName_buick electra 225 custom  CarName_buick opel isuzu deluxe  CarName_buick regal sport coupe (turbo)  CarName_buick skyhawk  CarName_buick skylark  CarName_chevrolet impala  CarName_chevrolet monte carlo  CarName_chevrolet vega 2300  CarName_dodge challenger se  CarName_dodge colt (sw)  CarName_dodge colt hardtop  CarName_dodge coronet custom  CarName_dodge coronet custom (sw)  CarName_dodge d200  CarName_dodge dart custom  CarName_dodge monaco (sw)  CarName_dodge rampage  CarName_honda accord  CarName_honda accord cvcc  CarName_honda accord lx  CarName_honda civic  CarName_honda civic (auto)  CarName_honda civic 1300  CarName_honda civic 1500 gl  CarName_honda civic cvcc  CarName_honda prelude  CarName_isuzu D-Max   CarName_isuzu D-Max V-Cross  CarName_isuzu MU-X  CarName_jaguar xf  CarName_jaguar xj  CarName_jaguar xk  CarName_maxda glc deluxe  CarName_maxda rx3  CarName_mazda 626  CarName_mazda glc  CarName_mazda glc 4  CarName_mazda glc custom  CarName_mazda glc custom l  CarName_mazda glc deluxe  CarName_mazda rx-4  CarName_mazda rx-7 gs  CarName_mazda rx2 coupe  CarName_mercury cougar  CarName_mitsubishi g4  CarName_mitsubishi lancer  CarName_mitsubishi mirage  CarName_mitsubishi mirage g4  CarName_mitsubishi montero  CarName_mitsubishi outlander  CarName_mitsubishi pajero  CarName_nissan clipper  CarName_nissan dayz  CarName_nissan fuga  CarName_nissan gt-r  CarName_nissan juke  CarName_nissan kicks  CarName_nissan latio  CarName_nissan leaf  CarName_nissan note  CarName_nissan nv200  CarName_nissan otti  CarName_nissan rogue  CarName_nissan teana  CarName_nissan titan  CarName_peugeot 304  CarName_peugeot 504  CarName_peugeot 504 (sw)  CarName_peugeot 505s turbo diesel  CarName_peugeot 604sl  CarName_plymouth cricket  CarName_plymouth duster  CarName_plymouth fury gran sedan  CarName_plymouth fury iii  CarName_plymouth satellite custom (sw)  CarName_plymouth valiant  CarName_porcshce panamera  CarName_porsche boxter  CarName_porsche cayenne  CarName_porsche macan  CarName_renault 12tl  CarName_renault 5 gtl  CarName_saab 99e  CarName_saab 99gle  CarName_saab 99le  CarName_subaru  CarName_subaru baja  CarName_subaru brz  CarName_subaru dl  CarName_subaru r1  CarName_subaru r2  CarName_subaru trezia  CarName_subaru tribeca  CarName_toyota carina  CarName_toyota celica gt  CarName_toyota celica gt liftback  CarName_toyota corolla  CarName_toyota corolla 1200  CarName_toyota corolla 1600 (sw)  CarName_toyota corolla liftback  CarName_toyota corolla tercel  CarName_toyota corona  CarName_toyota corona hardtop  CarName_toyota corona liftback  CarName_toyota corona mark ii  CarName_toyota cressida  CarName_toyota mark ii  CarName_toyota starlet  CarName_toyota tercel  CarName_toyouta tercel  CarName_vokswagen rabbit  CarName_volkswagen 1131 deluxe sedan  CarName_volkswagen 411 (sw)  CarName_volkswagen dasher  CarName_volkswagen model 111  CarName_volkswagen rabbit  CarName_volkswagen rabbit custom  CarName_volkswagen super beetle  CarName_volkswagen type 3  CarName_volvo 144ea  CarName_volvo 145e (sw)  CarName_volvo 244dl  CarName_volvo 245  CarName_volvo 246  CarName_volvo 264gl  CarName_volvo diesel  CarName_vw dasher  CarName_vw rabbit  fueltype_diesel  fueltype_gas  aspiration_std  aspiration_turbo  doornumber_four  doornumber_two  carbody_convertible  carbody_hardtop  carbody_hatchback  carbody_sedan  carbody_wagon  drivewheel_4wd  drivewheel_fwd  drivewheel_rwd  enginelocation_front  enginelocation_rear  enginetype_dohc  enginetype_dohcv  enginetype_l  enginetype_ohc  enginetype_ohcf  enginetype_ohcv  enginetype_rotor  cylindernumber_eight  cylindernumber_five  cylindernumber_four  cylindernumber_six  cylindernumber_three  cylindernumber_twelve  cylindernumber_two  fuelsystem_1bbl  fuelsystem_2bbl  fuelsystem_4bbl  fuelsystem_idi  fuelsystem_mfi  fuelsystem_mpfi  fuelsystem_spdi  fuelsystem_spfi   wheelbase  carlength    carwidth   carheight  curbweight  enginesize   boreratio       stroke  compressionratio  horsepower   peakrpm    citympg  highwaympg\n",
      "Poids     -1190.246685   -560.239618   155.118699   701.095508    55.399342   838.872754                   0.0                        221.493313                 -104.882583                   929.652878           866.505344         -928.921599                0.0                0.0                  -172.221218               0.0       1785.263883             0.0     1634.786588      821.262446             0.0     1264.233216             642.525204                        376.280281                    1003.261059                       -533.520767                              0.0                                      0.0            1275.544897             915.892839                       0.0                            0.0                   105.618631                          0.0                      0.0                  -440.32086                   -384.225997                         -398.31926          -268.04917                -598.361332                        0.0             179.695073                   0.0                        0.0               -49.453863           716.973341                 -146.770215                198.729361                  -280.246622                -72.217463              -0.143236             82.812913                          0.0         -386.505701        1215.627134           79.53162        -930.985705                -16.771084          22.406533          84.132036          18.771745           411.489571                       0.0                         0.0                339.468344         -114.720064               553.4401                      0.0                     0.0              71.752333                 -65.791408                        0.0                    249.162796                -1287.056223                   -448.324417                        0.0              814.103357                  0.0         -1264.264733                  0.0           756.134651            -881.66035             94.924853           301.525783          1013.651305           -410.284841         -1650.280157           -196.173275                   0.0            805.830186         -1385.810735          -243.847144               -227.934076                         502.807727            -199.968738                214.514817              -896.502073                               0.0                -135.404315                              154.822927               -595.926924                 437.401107              914.537799               953.808158                    0.0                   0.0                    0.0       1030.513313                 0.0        -274.750515     -451.623976                  0.0         -171.546045        -253.874425         -61.600999                0.0             -34.244589              204.767585              -36.31154                -211.58109                        -403.107438             -592.157566                   221.298884                               0.0                     -1626.654401                    -101.551267             394.549964                      340.83155                    -1673.036761                     -14.471723              -131.451184             1104.686336            -1744.918848                    0.0                     0.0               -301.917844                                   0.0                          0.0                        0.0                   -480.768763               -1142.292553                       1100.923563                        71.149257                -622.848805         -1449.010251             -1526.004675          -102.248429          62.634864        -187.810255           689.466488            424.211159                0.0          636.24098        43.446251    -43.446251     -224.963982        224.963982       364.405319     -364.405319          2523.749748      -433.458164        -770.667811      -9.966912    -1309.65686      -701.02484     -513.643177     1214.668017          -2305.747064          2305.747064       -36.669105               0.0  -1554.752967     1657.119631      1537.624616     -2568.251847        964.929671           1919.153898          -482.605755         -1675.876633          205.384525                   0.0            -930.985705          964.929671      -360.302224       640.932162         553.4401       43.446251      -398.31926       419.843301      -981.853244        82.812913  155.385864 -177.55444  813.016266  234.194763    3.565003   85.046953 -707.118918 -1756.522504        192.382117   29.907634  1.717459 -268.61399  178.108944\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArwAAAIoCAYAAACLTTgWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABgM0lEQVR4nO3deVxWZf7/8fcNsogKiiiLK+7hLuZSYy7hPpatZplLjpWTNWXLxDSp2GJ7OmXZ4pKlaZY5XzNRMpdK3KMyy9QwSwF3EIhFOL8//HGPt9zADRy44fh6Ph48Zs451zn3dX+4g7cX17mOzTAMQwAAAIBFebi7AwAAAEBFIvACAADA0gi8AAAAsDQCLwAAACyNwAsAAABLI/ACAADA0gi8AAAAsDQCLwAAACyNwAsAAABLI/ACAFxis9k0Y8YMd3fDNM2bN9f48eNNu96mTZtks9m0adOmMp/78ccfm9YfAP9D4AVg98MPP+jmm29Ws2bN5Ovrq0aNGmngwIF67bXX3N21Uhs/frxsNpv8/f31559/Fjp+4MAB2Ww22Ww2vfTSSw7HDh8+rAkTJqhly5by9fVVSEiIrrnmGk2fPt2hXb9+/ezXuPSrXbt2Ffr+ivPAAw/IZrPp4MGDRbZ54oknZLPZ9P3331diz6q2gtB5+PBhp8dvvfVW2Ww2/fOf/6zcjgEotxru7gCAqmHr1q3q37+/mjZtqkmTJikkJES///67tm3bpjlz5uj+++93dxdLrUaNGsrMzNTq1at16623OhxbsmSJfH19lZWV5bD/4MGDuvLKK1WzZk3dddddat68uZKSkrRnzx49//zziomJcWjfuHFjzZo1q9BrBwQEmP+GXHTHHXfotdde09KlSzVt2jSnbT788EN17NhRnTp1quTeVU9paWlavXq1mjdvrg8//FDPPfecbDabu7sFwEUEXgCSpGeeeUYBAQHauXOn6tat63Ds+PHjldqXzMxM+fn5lfs6Pj4+uvrqq/Xhhx8WCrxLly7V8OHD9cknnzjsf/XVV5Wenq6EhAQ1a9bM4ZizOgQEBGjMmDHl7quZevbsqVatWunDDz90Gnjj4+OVmJio5557zg29Kz2zPg/l8cknnygvL08LFizQgAEDtGXLFvXt29etfQLgOqY0AJAkHTp0SO3bty8UdiWpYcOGhfZ98MEH6tGjh/z8/FSvXj1dc801Wr9+vUObN954Q+3bt5ePj4/CwsJ033336ezZsw5t+vXrpw4dOmj37t265ppr5Ofnp3/961+SpOzsbE2fPl2tWrWSj4+PmjRposcee0zZ2dkuv6/bb79da9eudXjdnTt36sCBA7r99tud1qFx48aFwm5RdSiLlJQU1ahRo9BosSTt379fNptNr7/+uiQpNzdXMTExat26tXx9fVW/fn395S9/UVxcXLGvcccdd+jnn3/Wnj17Ch1bunSpbDabRo8erZycHE2bNk2RkZEKCAhQrVq11KdPH23cuNGl93L06FHdddddCg4Olo+Pj9q3b68FCxY4tFm0aJHTqQLO5rwW93nYtWuXBg8erKCgINWsWVPh4eG66667SuyjYRh6+umn1bhxY/n5+al///768ccfXXp/BZYsWaKBAweqf//+uuKKK7RkyRKXzrv4/Vx11VX2fs+bN89p+/z8fD3zzDNq3LixfH19de211xaamvLVV1/plltuUdOmTe3/XTz00ENOp+4AuIDAC0CS1KxZM+3evVt79+4tsW1MTIzuvPNOeXl5aebMmYqJiVGTJk305Zdf2tvMmDFD9913n8LCwvTyyy/rpptu0ltvvaVBgwYpNzfX4XqnTp3S0KFD1aVLF82ePVv9+/dXfn6+rrvuOr300ksaMWKEXnvtNY0cOVKvvvqqRo0a5fL7uvHGG2Wz2bRy5Ur7vqVLl6pdu3bq1q2b0zr8/vvvDu+lOHl5eTp58mShr4yMjCLPCQ4OVt++ffXRRx8VOrZ8+XJ5enrqlltukXShjjExMerfv79ef/11PfHEE2ratKnTIHuxO+64w/5eL+3vRx99pD59+qhp06ZKS0vTu+++q379+un555/XjBkzdOLECQ0ePFgJCQnFvkZKSop69eqlL774QlOmTNGcOXPUqlUrTZw4UbNnzy723OI4+zwcP35cgwYN0uHDh/X444/rtdde0x133KFt27aVeL1p06bpySefVOfOnfXiiy+qRYsWGjRoULHfo4sdO3ZMGzdu1OjRoyVJo0eP1scff6ycnByXzj9z5oyGDRumyMhIvfDCC2rcuLEmT55c6B8GkvTcc8/p008/1SOPPKLo6Ght27bN/r0ssGLFCmVmZmry5Ml67bXXNHjwYL322msaO3asS/0BLksGABiGsX79esPT09Pw9PQ0evfubTz22GPGunXrjJycHId2Bw4cMDw8PIwbbrjByMvLcziWn59vGIZhHD9+3PD29jYGDRrk0Ob11183JBkLFiyw7+vbt68hyZg3b57Dtd5//33Dw8PD+Oqrrxz2z5s3z5BkfPPNN8W+n3Hjxhm1atUyDMMwbr75ZuPaa681DMMw8vLyjJCQECMmJsZITEw0JBkvvvii/by9e/caNWvWNCQZXbp0Mf7xj38Yq1atMjIyMgq9RkHfnX3dc889xfbvrbfeMiQZP/zwg8P+iIgIY8CAAfbtzp07G8OHDy/2WkW58sorjcaNGzt8D2JjYw1JxltvvWUYhmGcP3/eyM7OdjjvzJkzRnBwsHHXXXc57JdkTJ8+3b49ceJEIzQ01Dh58qRDu9tuu80ICAgwMjMzDcMwjIULFxqSjMTERId2GzduNCQZGzdutO8r6vPw6aefGpKMnTt3lqoGBZ/F4cOH2z+fhmEY//rXvwxJxrhx40q8xksvvWTUrFnTSEtLMwzDMH755RdDkvHpp5+6/H5efvll+77s7GyjS5cuRsOGDe3/fRWce8UVVzh8P+bMmVPoc1JQ14vNmjXLsNlsxm+//Vbi+wEuR4zwApAkDRw4UPHx8bruuuv03Xff6YUXXtDgwYPVqFEj/d///Z+93apVq5Sfn69p06bJw8PxR0jBTTxffPGFcnJy9OCDDzq0mTRpkvz9/bVmzRqH83x8fDRhwgSHfStWrNAVV1yhdu3aOYycDhgwQJJc/pO7dGFaw6ZNm5ScnKwvv/xSycnJTqczSFL79u2VkJCgMWPG6PDhw5ozZ45Gjhyp4OBgvfPOO4XaN2/eXHFxcYW+HnzwwWL7dOONN6pGjRpavny5fd/evXu1b98+hxHsunXr6scff9SBAwdcfr8FxowZoz/++ENbtmyx71u6dKm8vb3tI8ienp7y9vaWdOHP6adPn9b58+fVvXv3YkeRDcPQJ598ohEjRsgwDIfv0eDBg5WamlriKHRRnH0eCqbafPbZZ4X+QlCcgs/i/fff73CTWUnfn4stWbJEw4cPV506dSRJrVu3VmRkpMvTGmrUqKF77rnHvu3t7a177rlHx48f1+7dux3aTpgwwf79kKQ+ffpIkn799Vf7vpo1a9r/f0ZGhk6ePKmrrrpKhmHo22+/dfl9AZcTAm8JtmzZohEjRigsLEw2m02rVq0q9TXWrVunXr16qU6dOmrQoIFuuummIpe9Adzpyiuv1MqVK3XmzBnt2LFD0dHROnfunG6++Wbt27dP0oU5rh4eHoqIiCjyOr/99pskqW3btg77vb291aJFC/vxAo0aNXL4JS9dWDbsxx9/VIMGDRy+2rRpI6l0N9INGzZMderU0fLly7VkyRJdeeWVatWqVZHt27Rpo/fff18nT57U999/r2effVY1atTQ3XffrS+++MKhba1atRQVFVXoq6RlyYKCgnTttdc6TGtYvny5atSooRtvvNG+b+bMmTp79qzatGmjjh076tFHH3V5KbHbbrtNnp6e9mkNWVlZ+vTTTzV06FDVq1fP3u69995Tp06d7HOEGzRooDVr1ig1NbXIa584cUJnz57V22+/Xeh7VBBWy3qzo7PPQ9++fXXTTTcpJiZGQUFBuv7667Vw4cIS53MXfNZat27tsL9BgwYONSjKTz/9pG+//VZXX321Dh48aP/q16+fPvvsM6WlpZV4jbCwMNWqVcthX8Hn+NLfBU2bNnXYLujjmTNn7PuOHDmi8ePHKzAwULVr11aDBg3sN9AV9z0DLmcE3hJkZGSoc+fOmjt3bpnOT0xM1PXXX68BAwYoISFB69at08mTJx1+oQFVjbe3t6688ko9++yzevPNN5Wbm6sVK1ZU2OtdPGJVID8/Xx07dnQ6ehoXF6e///3vLl/fx8dHN954o9577z19+umnRY7uXsrT01MdO3ZUdHS0Pv30U0lyeVTPFbfddpt++eUX+1zZjz76SNdee62CgoLsba655hodOnRICxYsUIcOHfTuu++qW7duevfdd0u8fsOGDTVw4EB98sknys3N1erVq3Xu3DmHOaEffPCBxo8fr5YtW2r+/PmKjY1VXFycBgwYoPz8/CKvXXBszJgxRX6Prr76akkqcvmuvLw8p/udfR4KHsoQHx+vKVOm2G+Wi4yMVHp6eom1KKsPPvhAkvTQQw+pdevW9q+XX35ZWVlZhVb5KC9PT0+n+w3DkHShZgMHDtSaNWv0z3/+U6tWrVJcXJwWLVokScV+z4DLGcuSlWDo0KEaOnRokcezs7P1xBNP6MMPP9TZs2fVoUMHPf/88+rXr58kaffu3crLy9PTTz9t/9PuI488ouuvv165ubny8vKqjLcBlFn37t0lSUlJSZKkli1bKj8/X/v27VOXLl2cnlOwwsH+/fvVokUL+/6cnBwlJiYqKiqqxNdt2bKlvvvuO1177bWmrHd6++23a8GCBfLw8NBtt91W6vMvrYMZRo4cqXvuucc+reGXX35RdHR0oXaBgYGaMGGCJkyYoPT0dF1zzTWaMWOG/va3v5X4GnfccYdiY2O1du1aLV26VP7+/hoxYoT9+Mcff6wWLVpo5cqVDnW+9CEbl2rQoIHq1KmjvLy8Er+fBaOUl67QcelIvyt69eqlXr166ZlnntHSpUt1xx13aNmyZUXWouCzeODAAYfP4okTJxxGTZ0xDENLly5V//79nf4D66mnntKSJUsKTb+41LFjx5SRkeEwyvvLL79IujAlpjR++OEH/fLLL3rvvfccblIradUO4HLHCG85TZkyRfHx8Vq2bJm+//573XLLLRoyZIh9vl1kZKQ8PDy0cOFC5eXlKTU1Ve+//76ioqIIu6hSNm7caB9Futjnn38u6X/TE0aOHCkPDw/NnDmz0GhSwflRUVHy9vbWf/7zH4drzp8/X6mpqRo+fHiJ/bn11lt19OhRp/Nm//zzT5fvsC/Qv39/PfXUU3r99dcVEhJSZLuvvvrK6RzRS+tghrp162rw4MH66KOPtGzZMnl7e2vkyJEObU6dOuWwXbt2bbVq1crlpdlGjhwpPz8/vfHGG1q7dq1uvPFG+fr62o8XjChe/H3avn274uPji72up6enbrrpJn3yySdOV/Y4ceKE/f+3bNlSkhzmEufl5entt9926T1IF/6kf+nns+AfXMXVouBn7WuvveZwviurSHzzzTf2p+7dfPPNhb5GjRqljRs36tixY8Ve5/z583rrrbfs2zk5OXrrrbfUoEEDRUZGltiPizn7fhmGoTlz5pTqOsDlhhHecjhy5IgWLlyoI0eOKCwsTNKF0dvY2FgtXLhQzz77rMLDw7V+/Xrdeuutuueee5SXl6fevXvbf3kCVcX999+vzMxM3XDDDWrXrp1ycnK0detWLV++XM2bN7ePYrVq1UpPPPGEnnrqKfXp00c33nijfHx8tHPnToWFhWnWrFlq0KCBoqOjFRMToyFDhui6667T/v379cYbb+jKK6906UENd955pz766CPde++92rhxo66++mrl5eXp559/1kcffaR169bZR11d4eHhoX//+98ltnv++ee1e/du3XjjjfankO3Zs0eLFy9WYGBgoZudUlNT7X/2vpQr73PUqFEaM2aM3njjDQ0ePLjQOsgRERHq16+fIiMjFRgYqF27dunjjz/WlClTSry2dCEgjxw50j6P99Ilrv76179q5cqVuuGGGzR8+HAlJiZq3rx5ioiIKHGqwHPPPaeNGzeqZ8+emjRpkiIiInT69Gnt2bNHX3zxhU6fPi3pwo2AvXr1UnR0tE6fPq3AwEAtW7ZM58+fd+k9SBfmGb/xxhu64YYb1LJlS507d07vvPOO/P39NWzYsCLPa9CggR555BHNmjVLf/3rXzVs2DB9++23Wrt2rcPUEWeWLFkiT0/PIv+Bdt111+mJJ57QsmXLNHXq1CKvExYWpueff16HDx9WmzZttHz5ciUkJOjtt98u9cBHu3bt1LJlSz3yyCM6evSo/P399cknn5Q4Wg1c9tyyNkQ1pUuWofnss88MSUatWrUcvmrUqGHceuuthmEYRlJSktG6dWvj0UcfNfbs2WNs3rzZ6Nu3r3Httdc6LJEDuNvatWuNu+66y2jXrp1Ru3Ztw9vb22jVqpVx//33GykpKYXaL1iwwOjatavh4+Nj1KtXz+jbt68RFxfn0Ob111832rVrZ3h5eRnBwcHG5MmTjTNnzji06du3r9G+fXunfcrJyTGef/55o3379vbXiYyMNGJiYozU1NRi38/Fy5IVxdmyZN98841x3333GR06dDACAgIMLy8vo2nTpsb48eONQ4cOFeq7iliWzNUfr2lpafZl0D744INCx59++mmjR48eRt26dY2aNWsa7dq1M5555plCy8UVZ82aNYYkIzQ01OlScs8++6zRrFkzw8fHx+jatavx2WefGePGjTOaNWvm0FaXLEtmGIaRkpJi3HfffUaTJk0MLy8vIyQkxLj22muNt99+26HdoUOHjKioKMPHx8cIDg42/vWvfxlxcXFOl/Fy9nnYs2ePMXr0aKNp06aGj4+P0bBhQ+Ovf/2rsWvXrhLff15enhETE2OEhoYaNWvWNPr162fs3bvXaNasWZHLkuXk5Bj169c3+vTpU+y1w8PDja5duxqGUfSyZO3btzd27dpl9O7d2/D19TWaNWtmvP766w7XKTh3xYoVDvsLPqMLFy6079u3b58RFRVl1K5d2wgKCjImTZpkfPfdd4XaAfgfm2E4+RsmnLLZbPr000/tf3Jcvny57rjjDv3444+FbjSoXbu2QkJC9OSTTyo2NlY7d+60H/vjjz/UpEkTxcfHq1evXpX5FgAAlahfv346efKkSw90AVBxmNJQDl27dlVeXp6OHz9uXyvxUpmZmYXWKi0Ix9xNCwAAUPG4aa0E6enpSkhIsC8blJiYqISEBB05ckRt2rTRHXfcobFjx2rlypVKTEzUjh07NGvWLPvC+sOHD9fOnTs1c+ZMHThwQHv27NGECRPUrFkzde3a1Y3vDAAA4PJA4C3Brl271LVrV3s4nTp1qrp27app06ZJkhYuXKixY8fq4YcfVtu2bTVy5Ejt3LnTvnj4gAEDtHTpUq1atUpdu3bVkCFD5OPjo9jYWKdrTQIAAMBczOEFAACApTHCCwAAAEsj8AIAAMDSWKXBifz8fB07dkx16tQx5ZGmAAAAMJdhGDp37pzCwsIKrYh1KQKvE8eOHVOTJk3c3Q0AAACU4Pfff1fjxo2LbUPgdaJOnTqSLhTQ39/f5fNyc3O1fv16DRo0qNSPi8T/UEfzUEvzUEvzUEvzUEtzUEfzVGYt09LS1KRJE3tuKw6B14mCaQz+/v6lDrx+fn7y9/fnP5hyoI7moZbmoZbmoZbmoZbmoI7mcUctXZl+yk1rAAAAsDQCLwAAACyNwAsAAABLI/ACAADA0gi8AAAAsDQCLwAAACyNwAsAAABLI/ACAADA0gi8AAAAsDQCLwAAACyNwAsAAABLI/ACAADA0gi8AAAAsLQa7u7A5S4v39COxNM6fi5LDev4qkd4oDw9bO7uFgAAgGUQeN0odm+SYlbvU1Jqln1faICvpo+I0JAOoW7sGQAAgHUwpcFNYvcmafIHexzCriQlp2Zp8gd7FLs3yU09AwAAsBYCrxvk5RuKWb1PhpNjBftiVu9TXr6zFgAAACgNAq8b7Eg8XWhk92KGpKTULO1IPF15nQIAALAoAq8bHD9XdNgtSzsAAAAUjcDrBg3r+JraDgAAAEUj8LpBj/BAhQb4qqjFx2y6sFpDj/DAyuwWAACAJRF43cDTw6bpIyIkqVDoLdiePiKC9XgBAABMQOB1kyEdQvXmmG4KCXCcthAS4Ks3x3RjHV4AAACT8OAJNxrSIVQDI0J40hoAAEAFIvC6maeHTb1b1nd3NwAAACyLKQ0AAACwNLcG3i1btmjEiBEKCwuTzWbTqlWrim0/fvx42Wy2Ql/t27e3t5kxY0ah4+3atavgdwIAAICqyq2BNyMjQ507d9bcuXNdaj9nzhwlJSXZv37//XcFBgbqlltucWjXvn17h3Zff/11RXQfAAAA1YBb5/AOHTpUQ4cOdbl9QECAAgIC7NurVq3SmTNnNGHCBId2NWrUUEhIiGn9BAAAQPVVrefwzp8/X1FRUWrWrJnD/gMHDigsLEwtWrTQHXfcoSNHjriphwAAAHC3artKw7Fjx7R27VotXbrUYX/Pnj21aNEitW3bVklJSYqJiVGfPn20d+9e1alTx+m1srOzlZ2dbd9OS0uTJOXm5io3N9flPhW0Lc05KIw6modamodamodamodamoM6mqcya1ma17AZhmFUYF9cZrPZ9Omnn2rkyJEutZ81a5ZefvllHTt2TN7e3kW2O3v2rJo1a6ZXXnlFEydOdNpmxowZiomJKbR/6dKl8vPzc6k/AAAAqDyZmZm6/fbblZqaKn9//2LbVssRXsMwtGDBAt15553Fhl1Jqlu3rtq0aaODBw8W2SY6OlpTp061b6elpalJkyYaNGhQiQW8WG5uruLi4jRw4EB5eXm5fB4cUUfzUEvzUEvzUEvzUEtzUEfzVGYtC/4i74pqGXg3b96sgwcPFjlie7H09HQdOnRId955Z5FtfHx85OPjU2i/l5dXmb5ZZT0PjqijeaileaileaileailOaijeSqjlqW5vltvWktPT1dCQoISEhIkSYmJiUpISLDfZBYdHa2xY8cWOm/+/Pnq2bOnOnToUOjYI488os2bN+vw4cPaunWrbrjhBnl6emr06NEV+l4AAABQNbl1hHfXrl3q37+/fbtgWsG4ceO0aNEiJSUlFVphITU1VZ988onmzJnj9Jp//PGHRo8erVOnTqlBgwb6y1/+om3btqlBgwYV90YAAABQZbk18Pbr10/F3TO3aNGiQvsCAgKUmZlZ5DnLli0zo2sAAACwiGq9Di8AAABQEgIvAAAALI3ACwAAAEsj8AIAAMDSCLwAAACwNAIvAAAALI3ACwAAAEsj8AIAAMDSCLwAAACwNAIvAAAALM2tjxaGc3n5hnYkntbxc1lqWMdXPcID5elhc3e3AAAAqiUCbxUTuzdJMav3KSk1y74vNMBX00dEaEiHUDf2DAAAoHpiSkMVErs3SZM/2OMQdiUpOTVLkz/Yo9i9SW7qGQAAQPVF4K0i8vINxazeJ8PJsYJ9Mav3KS/fWQsAAAAUhcBbRexIPF1oZPdihqSk1CztSDxdeZ0CAACwAAJvFXH8XNFhtyztAAAAcAGBt4poWMfX1HYAAAC4gMBbRfQID1RogK+KWnzMpgurNfQID6zMbgEAAFR7BN4qwtPDpukjIiSpUOgt2J4+IoL1eAEAAEqJwFuFDOkQqjfHdFNIgOO0hZAAX705phvr8AIAAJQBD56oYoZ0CNXAiBCetAYAAGASAm8V5OlhU++W9d3dDQAAAEtgSgMAAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsza2Bd8uWLRoxYoTCwsJks9m0atWqYttv2rRJNput0FdycrJDu7lz56p58+by9fVVz549tWPHjgp8FwAAAKjK3Bp4MzIy1LlzZ82dO7dU5+3fv19JSUn2r4YNG9qPLV++XFOnTtX06dO1Z88ede7cWYMHD9bx48fN7j4AAACqgRrufPGhQ4dq6NChpT6vYcOGqlu3rtNjr7zyiiZNmqQJEyZIkubNm6c1a9ZowYIFevzxx8vTXQAAAFRDbg28ZdWlSxdlZ2erQ4cOmjFjhq6++mpJUk5Ojnbv3q3o6Gh7Ww8PD0VFRSk+Pr7I62VnZys7O9u+nZaWJknKzc1Vbm6uy/0qaFuac1AYdTQPtTQPtTQPtTQPtTQHdTRPZdayNK9RrQJvaGio5s2bp+7duys7O1vvvvuu+vXrp+3bt6tbt246efKk8vLyFBwc7HBecHCwfv755yKvO2vWLMXExBTav379evn5+ZW6n3FxcaU+B4VRR/NQS/NQS/NQS/NQS3NQR/NURi0zMzNdblutAm/btm3Vtm1b+/ZVV12lQ4cO6dVXX9X7779f5utGR0dr6tSp9u20tDQ1adJEgwYNkr+/v8vXyc3NVVxcnAYOHCgvL68y9+dyRx3NQy3NQy3NQy3NQy3NQR3NU5m1LPiLvCuqVeB1pkePHvr6668lSUFBQfL09FRKSopDm5SUFIWEhBR5DR8fH/n4+BTa7+XlVaZvVlnPgyPqaB5qaR5qaR5qaR5qaQ7qaJ7KqGVprl/t1+FNSEhQaGioJMnb21uRkZHasGGD/Xh+fr42bNig3r17u6uLAAAAcCO3jvCmp6fr4MGD9u3ExEQlJCQoMDBQTZs2VXR0tI4eParFixdLkmbPnq3w8HC1b99eWVlZevfdd/Xll19q/fr19mtMnTpV48aNU/fu3dWjRw/Nnj1bGRkZ9lUbAAAAcHlxa+DdtWuX+vfvb98umEc7btw4LVq0SElJSTpy5Ij9eE5Ojh5++GEdPXpUfn5+6tSpk7744guHa4waNUonTpzQtGnTlJycrC5duig2NrbQjWwAAAC4PLg18Pbr10+GYRR5fNGiRQ7bjz32mB577LESrztlyhRNmTKlvN0DAACABVT7ObwAAABAcQi8AAAAsDQCLwAAACyNwAsAAABLI/ACAADA0gi8AAAAsDQCLwAAACyNwAsAAABLI/ACAADA0gi8AAAAsDQCLwAAACyNwAsAAABLI/ACAADA0gi8AAAAsDQCLwAAACyNwAsAAABLI/ACAADA0gi8AAAAsDQCLwAAACyNwAsAAABLI/ACAADA0gi8AAAAsDQCLwAAACyNwAsAAABLI/ACAADA0gi8AAAAsLQa7u4Ayicv39COxNM6fi5LDev4qkd4oDw9bO7uFgAAQJVB4K3GYvcmKWb1PiWlZtn3hQb4avqICA3pEOrGngEAAFQdTGmopmL3JmnyB3scwq4kJadmafIHexS7N8lNPQMAAKhaCLzVUF6+oZjV+2Q4OVawL2b1PuXlO2sBAABweSHwVkM7Ek8XGtm9mCEpKTVLOxJPV16nAAAAqigCbzV0/FzRYbcs7QAAAKyMwFsNNazja2o7AAAAKyPwVkM9wgMVGuCrohYfs+nCag09wgMrs1sAAABVEoG3GvL0sGn6iAhJKhR6C7anj4hgPV4AAAAReKutIR1C9eaYbgoJcJy2EBLgqzfHdGMdXgAAgP+PB09UY0M6hGpgRAhPWgMAACgGgbea8/SwqXfL+u7uBgAAQJXFlAYAAABYGoEXAAAAlkbgBQAAgKUReAEAAGBpBF4AAABYGoEXAAAAlkbgBQAAgKUReAEAAGBpBF4AAABYGoEXAAAAlkbgBQAAgKUReAEAAGBpBF4AAABYmlsD75YtWzRixAiFhYXJZrNp1apVxbZfuXKlBg4cqAYNGsjf31+9e/fWunXrHNrMmDFDNpvN4atdu3YV+C4AAABQlbk18GZkZKhz586aO3euS+23bNmigQMH6vPPP9fu3bvVv39/jRgxQt9++61Du/bt2yspKcn+9fXXX1dE9wEAAFAN1HDniw8dOlRDhw51uf3s2bMdtp999ln997//1erVq9W1a1f7/ho1aigkJMSsbgIAAKAac2vgLa/8/HydO3dOgYGBDvsPHDigsLAw+fr6qnfv3po1a5aaNm1a5HWys7OVnZ1t305LS5Mk5ebmKjc31+X+FLQtzTkojDqah1qah1qah1qah1qagzqapzJrWZrXsBmGYVRgX1xms9n06aefauTIkS6f88ILL+i5557Tzz//rIYNG0qS1q5dq/T0dLVt21ZJSUmKiYnR0aNHtXfvXtWpU8fpdWbMmKGYmJhC+5cuXSo/P78yvR8AAABUnMzMTN1+++1KTU2Vv79/sW2rbeBdunSpJk2apP/+97+Kiooqst3Zs2fVrFkzvfLKK5o4caLTNs5GeJs0aaKTJ0+WWMCL5ebmKi4uTgMHDpSXl5fL58ERdTQPtTQPtTQPtTQPtTQHdTRPZdYyLS1NQUFBLgXeajmlYdmyZfrb3/6mFStWFBt2Jalu3bpq06aNDh48WGQbHx8f+fj4FNrv5eVVpm9WWc+DI+poHmppHmppHmppHmppDuponsqoZWmuX+3W4f3www81YcIEffjhhxo+fHiJ7dPT03Xo0CGFhoZWQu8AAABQ1bh1hDc9Pd1h5DUxMVEJCQkKDAxU06ZNFR0draNHj2rx4sWSLkxjGDdunObMmaOePXsqOTlZklSzZk0FBARIkh555BGNGDFCzZo107FjxzR9+nR5enpq9OjRlf8GAQAA4HZuHeHdtWuXunbtal9SbOrUqerataumTZsmSUpKStKRI0fs7d9++22dP39e9913n0JDQ+1f//jHP+xt/vjjD40ePVpt27bVrbfeqvr162vbtm1q0KBB5b45AAAAVAluHeHt16+firtnbtGiRQ7bmzZtKvGay5YtK2evAAAAYCXVbg4vAAAAUBoEXgAAAFgagRcAAACWRuAFAACApRF4AQAAYGkEXgAAAFgagRcAAACWRuAFAACApRF4AQAAYGkEXgAAAFgagRcAAACWRuAFAACApRF4AQAAYGkEXgAAAFgagRcAAACWRuAFAACApRF4AQAAYGkEXgAAAFgagRcAAACWRuAFAACApRF4AQAAYGkEXgAAAFgagRcAAACWRuAFAACApRF4AQAAYGkEXgAAAFgagRcAAACWRuAFAACApRF4AQAAYGkEXgAAAFgagRcAAACWRuAFAACApRF4AQAAYGkuB95hw4YpNTXVvv3cc8/p7Nmz9u1Tp04pIiLC1M4BAAAA5eVy4F23bp2ys7Pt288++6xOnz5t3z5//rz2799vbu8AAACAcnI58BqGUew2AAAAUBUxhxcAAACW5nLgtdlsstlshfYBAAAAVVkNVxsahqHx48fLx8dHkpSVlaV7771XtWrVkiSH+b0AAABAVeFy4B03bpzD9pgxYwq1GTt2bPl7BAAAAJjI5cC7cOHCiuwHAAAAUCHKfdPab7/9pn379ik/P9+M/gAAAACmcjnwLliwQK+88orDvrvvvlstWrRQx44d1aFDB/3++++mdxAAAAAoD5cD79tvv6169erZt2NjY7Vw4UItXrxYO3fuVN26dRUTE1MhnQQAAADKyuU5vAcOHFD37t3t2//97391/fXX64477pB04clrEyZMML+HAAAAQDm4PML7559/yt/f3769detWXXPNNfbtFi1aKDk52dzeAQAAAOXkcuBt1qyZdu/eLUk6efKkfvzxR1199dX248nJyQoICDC/hwAAAEA5lGod3vvuu08//vijvvzyS7Vr106RkZH241u3blWHDh0qpJMAAABAWbkceB977DFlZmZq5cqVCgkJ0YoVKxyOf/PNNxo9erTpHQQAAADKw+XA6+HhoZkzZ2rmzJlOj18agAEAAICqoNwPniiPLVu2aMSIEQoLC5PNZtOqVatKPGfTpk3q1q2bfHx81KpVKy1atKhQm7lz56p58+by9fVVz549tWPHDvM7DwAAgGrB5RHeFi1auNTu119/dfnFMzIy1LlzZ91111268cYbS2yfmJio4cOH695779WSJUu0YcMG/e1vf1NoaKgGDx4sSVq+fLmmTp2qefPmqWfPnpo9e7YGDx6s/fv3q2HDhi73DQAAANbgcuA9fPiwmjVrpttvv9204Dh06FANHTrU5fbz5s1TeHi4Xn75ZUnSFVdcoa+//lqvvvqqPfC+8sormjRpkn1N4Hnz5mnNmjVasGCBHn/8cVP6DQAAgOrD5cC7fPly++OFhw4dqrvuukvDhg2Th0flzYqIj49XVFSUw77BgwfrwQcflCTl5ORo9+7dio6Oth/38PBQVFSU4uPjK62fAAAAqDpcDry33HKLbrnlFh09elSLFi3SQw89pHvuuUd33nmnJk6cqNatW1dkPyVdWOs3ODjYYV9wcLDS0tL0559/6syZM8rLy3Pa5ueffy7yutnZ2crOzrZvp6WlSZJyc3OVm5vrcv8K2pbmHBRGHc1DLc1DLc1DLc1DLc1BHc1TmbUszWu4HHgLNGrUSE888YSeeOIJbd68WTNmzNCLL76okydPql69eqW9XJUwa9YsxcTEFNq/fv16+fn5lfp6cXFxZnTrskcdzUMtzUMtzUMtzUMtzUEdzVMZtczMzHS5bakDryRlZWXp448/1oIFC7R9+3bdcsstZQqGpRUSEqKUlBSHfSkpKfL391fNmjXl6ekpT09Pp21CQkKKvG50dLSmTp1q305LS1OTJk00aNAgh8cplyQ3N1dxcXEaOHCgvLy8XD4PjqijeaileaileaileailOaijeSqzlgV/kXdFqQLv9u3bNX/+fH300Udq0aKF7rrrLn3yySeVNrLbu3dvff755w774uLi1Lt3b0mSt7e3IiMjtWHDBo0cOVKSlJ+frw0bNmjKlClFXtfHx0c+Pj6F9nt5eZXpm1XW8+CIOpqHWpqHWpqHWpqHWpqDOpqnMmpZmuu7HHjbt2+v48eP6/bbb9fmzZvVuXPnMnXuYunp6Tp48KB9OzExUQkJCQoMDFTTpk0VHR2to0ePavHixZKke++9V6+//roee+wx3XXXXfryyy/10Ucfac2aNfZrTJ06VePGjVP37t3Vo0cPzZ49WxkZGfZVGwAAAHB5cTnw/vTTT6pVq5YWL16s999/v8h2p0+fdvnFd+3apf79+9u3C6YVjBs3TosWLVJSUpKOHDliPx4eHq41a9booYce0pw5c9S4cWO9++679iXJJGnUqFE6ceKEpk2bpuTkZHXp0kWxsbGFbmQDAADA5cHlwLtw4ULTX7xfv34yDKPI486eotavXz99++23xV53ypQpxU5hAAAAwOXD5cA7bty4iuwHAAAAUCEq76kRAAAAgBsQeAEAAGBpBF4AAABYGoEXAAAAllbmwJuTk6P9+/fr/PnzZvYHAAAAMFWpA29mZqYmTpwoPz8/tW/f3r5O7v3336/nnnvO9A4CAAAA5VHqwBsdHa3vvvtOmzZtkq+vr31/VFSUli9fbmrnAAAAgPJyeR3eAqtWrdLy5cvVq1cv2Ww2+/727dvr0KFDpnYOAAAAKK9Sj/CeOHFCDRs2LLQ/IyPDIQADAAAAVUGpA2/37t21Zs0a+3ZByH333XfVu3dv83oGAAAAmKDUUxqeffZZDR06VPv27dP58+c1Z84c7du3T1u3btXmzZsroo8AAABAmZV6hPcvf/mLvvvuO50/f14dO3bU+vXr1bBhQ8XHxysyMrIi+ggAAACUWalGeHNzc3XPPffoySef1DvvvFNRfQIAAABMU6oRXi8vL33yyScV1RcAAADAdKWe0jBy5EitWrWqAroCAAAAmK/UN621bt1aM2fO1DfffKPIyEjVqlXL4fgDDzxgWucAAACA8ip14J0/f77q1q2r3bt3a/fu3Q7HbDYbgRcAAABVSqkDb2JiYkX0AwAAAKgQpZ7DezHDMGQYhll9AQAAAExXpsC7ePFidezYUTVr1lTNmjXVqVMnvf/++2b3DQAAACi3Uk9peOWVV/Tkk09qypQpuvrqqyVJX3/9te69916dPHlSDz30kOmdBAAAAMqq1IH3tdde05tvvqmxY8fa91133XVq3769ZsyYQeAFAABAlVLqKQ1JSUm66qqrCu2/6qqrlJSUZEqnAAAAALOUOvC2atVKH330UaH9y5cvV+vWrU3pFAAAAGCWUk9piImJ0ahRo7Rlyxb7HN5vvvlGGzZscBqEAQAAAHcq9QjvTTfdpO3btysoKEirVq3SqlWrFBQUpB07duiGG26oiD4CAAAAZVbqEV5JioyM1AcffGB2XwAAAADTlXqE9/PPP9e6desK7V+3bp3Wrl1rSqcAAAAAs5Q68D7++OPKy8srtN8wDD3++OOmdAoAAAAwS6kD74EDBxQREVFof7t27XTw4EFTOgUAAACYpdSBNyAgQL/++muh/QcPHlStWrVM6RQAAABgllIH3uuvv14PPvigDh06ZN938OBBPfzww7ruuutM7RwAAABQXqUOvC+88IJq1aqldu3aKTw8XOHh4briiitUv359vfTSSxXRRwAAAKDMSr0sWUBAgLZu3aq4uDh99913qlmzpjp16qRrrrmmIvoHAAAAlEuZ1uG12WwaNGiQBg0aZHZ/AAAAAFO5PKUhPj5en332mcO+xYsXKzw8XA0bNtTdd9+t7Oxs0zsIAAAAlIfLgXfmzJn68ccf7ds//PCDJk6cqKioKD3++ONavXq1Zs2aVSGdBAAAAMrK5cCbkJCga6+91r69bNky9ezZU++8846mTp2q//znP/roo48qpJMAAABAWbkceM+cOaPg4GD79ubNmzV06FD79pVXXqnff//d3N4BAAAA5eRy4A0ODlZiYqIkKScnR3v27FGvXr3sx8+dOycvLy/zewgAAACUg8uBd9iwYXr88cf11VdfKTo6Wn5+furTp4/9+Pfff6+WLVtWSCcBAACAsnJ5WbKnnnpKN954o/r27avatWvrvffek7e3t/34ggULWKYMAAAAVY7LgTcoKEhbtmxRamqqateuLU9PT4fjK1asUO3atU3vIAAAAFAeZXrSmjOBgYHl7gwAAABgNpfn8AIAAADVEYEXAAAAlkbgBQAAgKUReAEAAGBpBF4AAABYGoEXAAAAllYlAu/cuXPVvHlz+fr6qmfPntqxY0eRbfv16yebzVboa/jw4fY248ePL3R8yJAhlfFWLCsv31D8oVP6b8JRxR86pbx8w91dAgAAcEmp1+E12/LlyzV16lTNmzdPPXv21OzZszV48GDt379fDRs2LNR+5cqVysnJsW+fOnVKnTt31i233OLQbsiQIVq4cKF928fHp+LehMXF7k1SzOp9SkrNsu8LDfDV9BERGtIh1I09AwAAKJnbR3hfeeUVTZo0SRMmTFBERITmzZsnPz8/LViwwGn7wMBAhYSE2L/i4uLk5+dXKPD6+Pg4tKtXr15lvB3Lid2bpMkf7HEIu5KUnJqlyR/sUezeJDf1DAAAwDVuHeHNycnR7t27FR0dbd/n4eGhqKgoxcfHu3SN+fPn67bbblOtWrUc9m/atEkNGzZUvXr1NGDAAD399NOqX7++02tkZ2crOzvbvp2WliZJys3NVW5ursvvp6Btac6pyvLyDc1a86O8PZ1PX7BJmrXmR/VrXV+eHjbTXtdqdXQnamkeamkeamkeamkO6mieyqxlaV7DZhiG2yZjHjt2TI0aNdLWrVvVu3dv+/7HHntMmzdv1vbt24s9f8eOHerZs6e2b9+uHj162PcvW7ZMfn5+Cg8P16FDh/Svf/1LtWvXVnx8vDw9PQtdZ8aMGYqJiSm0f+nSpfLz8yvHOwQAAEBFyMzM1O23367U1FT5+/sX29btc3jLY/78+erYsaND2JWk2267zf7/O3bsqE6dOqlly5batGmTrr322kLXiY6O1tSpU+3baWlpatKkiQYNGlRiAS+Wm5uruLg4DRw4UF5eXmV4R1XL5z8k6bFPvi+x3Qs3ddKwjubN5bVaHd2JWpqHWpqHWpqHWpqDOpqnMmtZ8Bd5V7g18AYFBcnT01MpKSkO+1NSUhQSElLsuRkZGVq2bJlmzpxZ4uu0aNFCQUFBOnjwoNPA6+Pj4/SmNi8vrzJ9s8p6XlXTMKCWsvNKnqrQMKBWhbxfq9SxKqCW5qGW5qGW5qGW5qCO5qmMWpbm+m69ac3b21uRkZHasGGDfV9+fr42bNjgMMXBmRUrVig7O1tjxowp8XX++OMPnTp1SqGhrChQGj3CAxUa4KuiIq9NF1Zr6BEeWJndAgAAKBW3r9IwdepUvfPOO3rvvff0008/afLkycrIyNCECRMkSWPHjnW4qa3A/PnzNXLkyEI3oqWnp+vRRx/Vtm3bdPjwYW3YsEHXX3+9WrVqpcGDB1fKe7IKTw+bpo+IkKRCobdge/qICFNvWAMAADCb2+fwjho1SidOnNC0adOUnJysLl26KDY2VsHBwZKkI0eOyMPDMZfv379fX3/9tdavX1/oep6envr+++/13nvv6ezZswoLC9OgQYP01FNPsRZvGQzpEKo3x3QrtA5vCOvwAgCAasLtgVeSpkyZoilTpjg9tmnTpkL72rZtq6IWl6hZs6bWrVtnZvcue0M6hGpgRIh2JJ7W8XNZaljnwjQGRnYBAEB1UCUCL6o+Tw+berd0vo4xAABAVeb2ObwAAABARSLwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAAS6vh7g7AmvLyDe1IPK3j57LUsI6veoQHytPD5u5uAQCAyxCBF6aL3ZukmNX7lJSaZd8XGuCr6SMiNKRDqBt7BgAALkdMaYCpYvcmafIHexzCriQlp2Zp8gd7FLs3yU09AwAAlysCL0yTl28oZvU+GU6OFeyLWb1PefnOWgAAAFQMAi9MsyPxdKGR3YsZkpJSs7Qj8XTldQoAAFz2CLwwzfFzRYfdsrQDAAAwA4EXpmlYx9fUdgAAAGYg8MI0PcIDFRrgq6IWH7PpwmoNPcIDK7NbAADgMkfghWk8PWyaPiJCkgqF3oLt6SMiWI8XAABUKgIvTDWkQ6jeHNNNIQGO0xZCAnz15phurMMLAAAqHQ+egOmGdAjVwIgQnrQGAACqBAIvKoSnh029W9Z3dzcAAACY0gAAAABrqxKBd+7cuWrevLl8fX3Vs2dP7dixo8i2ixYtks1mc/jy9XWcL2oYhqZNm6bQ0FDVrFlTUVFROnDgQEW/DQAAAFRBbg+8y5cv19SpUzV9+nTt2bNHnTt31uDBg3X8+PEiz/H391dSUpL967fffnM4/sILL+g///mP5s2bp+3bt6tWrVoaPHiwsrJ44AEAAMDlxu2B95VXXtGkSZM0YcIERUREaN68efLz89OCBQuKPMdmsykkJMT+FRwcbD9mGIZmz56tf//737r++uvVqVMnLV68WMeOHdOqVasq4R0BAACgKnHrTWs5OTnavXu3oqOj7fs8PDwUFRWl+Pj4Is9LT09Xs2bNlJ+fr27duunZZ59V+/btJUmJiYlKTk5WVFSUvX1AQIB69uyp+Ph43XbbbYWul52drezsbPt2WlqaJCk3N1e5ubkuv5+CtqU5B4VRR/NQS/NQS/NQS/NQS3NQR/NUZi1L8xpuDbwnT55UXl6ewwitJAUHB+vnn392ek7btm21YMECderUSampqXrppZd01VVX6ccff1Tjxo2VnJxsv8al1yw4dqlZs2YpJiam0P7169fLz8+v1O8rLi6u1OegMOpoHmppHmppHmppHmppDuponsqoZWZmpsttq92yZL1791bv3r3t21dddZWuuOIKvfXWW3rqqafKdM3o6GhNnTrVvp2WlqYmTZpo0KBB8vf3d/k6ubm5iouL08CBA+Xl5VWmvoA6molamodamodamodamoM6mqcya1nwF3lXuDXwBgUFydPTUykpKQ77U1JSFBIS4tI1vLy81LVrVx08eFCS7OelpKQoNPR/T/VKSUlRly5dnF7Dx8dHPj4+Tq9dlm9WWc+DI+poHmppHmppHmppHmppDuponsqoZWmu79ab1ry9vRUZGakNGzbY9+Xn52vDhg0Oo7jFycvL0w8//GAPt+Hh4QoJCXG4ZlpamrZv3+7yNQEAAGAdbp/SMHXqVI0bN07du3dXjx49NHv2bGVkZGjChAmSpLFjx6pRo0aaNWuWJGnmzJnq1auXWrVqpbNnz+rFF1/Ub7/9pr/97W+SLqzg8OCDD+rpp59W69atFR4erieffFJhYWEaOXKku94mAAAA3MTtgXfUqFE6ceKEpk2bpuTkZHXp0kWxsbH2m86OHDkiD4//DUSfOXNGkyZNUnJysurVq6fIyEht3bpVERER9jaPPfaYMjIydPfdd+vs2bP6y1/+otjY2EIPqAAAAID1uT3wStKUKVM0ZcoUp8c2bdrksP3qq6/q1VdfLfZ6NptNM2fO1MyZM83qIgAAAKoptz94AgAAAKhIBF4AAABYGoEXAAAAlkbgBQAAgKUReAEAAGBpBF4AAABYGoEXAAAAlkbgBQAAgKUReAEAAGBpBF4AAABYGoEXAAAAlkbgBQAAgKUReAEAAGBpBF4AAABYGoEXAAAAlkbgBQAAgKUReAEAAGBpBF4AAABYGoEXAAAAlkbgBQAAgKUReAEAAGBpBF4AAABYGoEXAAAAlkbgBQAAgKUReAEAAGBpBF4AAABYGoEXAAAAlkbgBQAAgKUReAEAAGBpBF4AAABYGoEXAAAAlkbgBQAAgKUReAEAAGBpBF4AAABYGoEXAAAAlkbgBQAAgKUReAEAAGBpBF4AAABYGoEXAAAAllbD3R0AyiMv39COxNM6fi5LDev4qkd4oDw9bO7uFgAAqEIIvKi2YvcmKWb1PiWlZtn3hQb4avqICA3pEOrGngEAgKqEKQ2olmL3JmnyB3scwq4kJadmafIHexS7N8lNPQMAAFUNgRfVTl6+oZjV+2Q4OVawL2b1PuXlO2sBAAAuNwReVDs7Ek8XGtm9mCEpKTVLOxJPV16nAABAlUXgRbVz/FzRYbcs7QAAgLUReFHtNKzja2o7AABgbQReVDs9wgMVGuCrohYfs+nCag09wgMrs1sAAKCKIvCi2vH0sGn6iAhJKhR6C7anj4hgPV4AACCJwItqakiHUL05pptCAhynLYQE+OrNMd1YhxcAANjx4AlUW0M6hGpgRAhPWgMAAMWqEiO8c+fOVfPmzeXr66uePXtqx44dRbZ955131KdPH9WrV0/16tVTVFRUofbjx4+XzWZz+BoyZEhFvw24gaeHTb1b1tf1XRqpd8v6hF0AAFCI2wPv8uXLNXXqVE2fPl179uxR586dNXjwYB0/ftxp+02bNmn06NHauHGj4uPj1aRJEw0aNEhHjx51aDdkyBAlJSXZvz788MPKeDsAAACoYtweeF955RVNmjRJEyZMUEREhObNmyc/Pz8tWLDAafslS5bo73//u7p06aJ27drp3XffVX5+vjZs2ODQzsfHRyEhIfavevXqVcbbAQAAQBXj1sCbk5Oj3bt3Kyoqyr7Pw8NDUVFRio+Pd+kamZmZys3NVWCg4xJUmzZtUsOGDdW2bVtNnjxZp06dMrXvAAAAqB7cetPayZMnlZeXp+DgYIf9wcHB+vnnn126xj//+U+FhYU5hOYhQ4boxhtvVHh4uA4dOqR//etfGjp0qOLj4+Xp6VnoGtnZ2crOzrZvp6WlSZJyc3OVm5vr8vspaFuac1AYdTQPtTQPtTQPtTQPtTQHdTRPZdayNK9hMwzDqMC+FOvYsWNq1KiRtm7dqt69e9v3P/bYY9q8ebO2b99e7PnPPfecXnjhBW3atEmdOnUqst2vv/6qli1b6osvvtC1115b6PiMGTMUExNTaP/SpUvl5+dXincEAACAypCZmanbb79dqamp8vf3L7atW0d4g4KC5OnpqZSUFIf9KSkpCgkJKfbcl156Sc8995y++OKLYsOuJLVo0UJBQUE6ePCg08AbHR2tqVOn2rfT0tLsN8OVVMCL5ebmKi4uTgMHDpSXl5fL58ERdTQPtTQPtTQPtTQPtTQHdTRPZday4C/yrnBr4PX29lZkZKQ2bNigkSNHSpL9BrQpU6YUed4LL7ygZ555RuvWrVP37t1LfJ0//vhDp06dUmio84cR+Pj4yMfHp9B+Ly+vMn2zynoeHFFH81BL81BL81BL81BLc1BH81RGLUtzfbev0jB16lS98847eu+99/TTTz9p8uTJysjI0IQJEyRJY8eOVXR0tL39888/ryeffFILFixQ8+bNlZycrOTkZKWnp0uS0tPT9eijj2rbtm06fPiwNmzYoOuvv16tWrXS4MGD3fIeAQAA4D5uf9LaqFGjdOLECU2bNk3Jycnq0qWLYmNj7TeyHTlyRB4e/8vlb775pnJycnTzzTc7XGf69OmaMWOGPD099f333+u9997T2bNnFRYWpkGDBumpp55yOooLAAAAa3N74JWkKVOmFDmFYdOmTQ7bhw8fLvZaNWvW1Lp160zqGQAAAKo7t09pAAAAACoSgRcAAACWRuAFAACApRF4AQAAYGlV4qY1wAry8g3tSDyt4+ey1LCOr3qEB8rTw+bubgEAcNkj8AImiN2bpJjV+5SUmmXfFxrgq+kjIjSkg/MHngAAgMrBlAagnGL3JmnyB3scwq4kJadmafIHexS7N8lNPQMAABKBFyiXvHxDMav3yXByrGBfzOp9yst31gIAAFQGAi9QDjsSTxca2b2YISkpNUs7Ek9XXqcAAIAD5vAC5XD8XNFhtyztnOFmOAAAyofAC5RDwzq+pra7FDfDAQBQfkxpAMqhR3igQgN8VdR4q00XAmqP8MBSX9uMm+EK5g5//kOS4g+dYi4xAOCyROAFysHTw6bpIyIkqVDoLdiePiKi1FMQzLgZLnZvkgbP3iJJeuyT7zX6nW36y/NfsmoEAOCyQ+AFymlIh1C9OaabQgIcpy2EBPjqzTHdyjT1oLw3wxWMDiensVQaAADM4QVMMKRDqAZGhJh2c1l5boYraXTYpgujwwMjQrj5DQBwWSDwAibx9LCpd8v6plyrPDfDlWZ02Kz+XoxVJQAAVQ2BF6iCCm6GS07NcjpSa9OFKRPOboarjKXSilKaVSUIxgCAykLgBaqggpvhJn+wRzbJIfSWdDNcRS+VVpSCecOXBvSCecMXz2dmuTUAQGXipjWgiirrzXAVuVRaUUqzqoQZy61d+trxh07pvwlHWXoNAOAUI7xAFVaWm+EuHR2+WHmWSiuOq/OGtx06ZeoNdYwUAwBcwQgvUMUV3Ax3fZdG6t2yvktBsGB0ONjfvKXSiuPqfOD4X0+Wa7m1i5V1pJgRYQC4/DDCC1jUkA6h6te6vtbFrtULN3VSw4BaFXZjmOvzgV177ZICdFmXXivtiPDFN9YF+fHjEkD5VcUbds3ok/0aqRn2ba+K6GwZ8RMcsLCCH1jDOobKy6vifvS4uqpE75b19frGgyVer6QAXZal10pzU11B+4vDsY+noRd6SF/8lKKhnRoXes28fEPbDp1S/K8nJV0Yle/VwrUReQCucxbOJLk1RF7ap8hm9bT7tzOF+lMVp2GZ0aeLr1Hws3Lw7C2KHt6+ykwvI/ACKDdXV5Xo1aJ+mZdbu1hpl14r7YhwUeFYkh5aniCbh2ehcPz4yh90NjPXvu/1jQdV189Lz93Y0aUl2SQ5BOae4YHy8LDpZHp2lRkFwuUp53y+3o8/rN9OZ6pZoJ/u7N1c3jVcnxFZ0uhhaUYXnYWzun4X/jF/8X9/lRkinfXJwyZdPFsqNMBX13UO1dtbEl3+R3dlKO1AQGmukZLmvvflDIEXgCkK5g1f+oM/5JJfPGVdbu1ipV16rTQjwj3CA4sMxwUuDcf3frDHabuzmbm694M9mlfCkmx1/byUcz5fmTl59n2vb3S8VklTL7YePKmVe/5QevZ5NfT3UbemgQqrW7NKjH6h4uXlG9p16JSS07J0Oj1bgbW8L3z+bbL/o6moUccCzoLty+t/1jtfJTqEt2c+/0mT+oQrelhEif0qafSwNKOLRQWri4NugcoKkUX16dJbA5JTs/TWlkSn13DXEzDNeCqnqyv0VIUnexJ4AZjGlVUlXA3GxSntgzlKMyJc2nA84/9+LPG6BT/w4/Ylu/wL+1LFTb14+KPvlHFRWJakJdt/l+R89Cugppe6NAlQ08Baahrop3bBdXT6zxx7KNqZeFrfHDqhY2ezFBZQU/VqeSuwlrdOpmfpx2NpOnb2TzWq66eIMH8F1fbR2cwcBdbyVkhATfeF6awsacUKadUq6dQpqX59aeRI6ZZbJF9z15wujZzz+Xpv62HtSDyljOxc2Ww2+fnUUI/m9XVr9yZ6af3POnwqU83r++lfwyLkXcND2w6d0tZfT+romT+VZ+TLQzY1DvTTVS2D7NNkLp0vOejVzTpyNqfYvjgbdSz4b27W5/sKBdun1vzk9Dr5huzhrbjQW9Lo4d3XhLs84llcsHKmMkJkafpUUpuKfgKmM2Y8ldPdT/YsDQIvAFO58ojlsiy3dulrlGakuDQjwqUNx8lp2SW2TUrN0rZfi16SzRVFTb0oanS5gLMwnfpnrjb/clLSyULHLq1nUXb9dlb//e5Yof2+NWzqEOYv2TwUVtdXHcICVNfPS2v3JumnY2nKzjPUIcRPNwdLf3tvh05l5snL06aAml46fCpThiEZ+fk6ny/lSwqq5a2rWgWpbk0vbfnluPYeO6c/z+fJ28Om0ABfNQ6sqdDNcYr+6EXVzU5Xns0mT8O48L8rVyp10t/12IiHtKVdL/l5eaiWt6f8/XzVqXGAejepp2lrf1J6Vq5skmr71pCfdw21alBLNWp4qLaPl9oF19HxjCx9+dMJnc8zVNPLQ43r+So3X4oI81dG9nmdz8vXweMZ8q7hoVPp2apfy0u1fb2Vk5evLb+cdFrPuH3H9czn/wuUXx2Q3t92RDU8bDpfxMohczceUl0/L43q3lj/912Sw3zJlHPZKummUGejjpM/2KOoiIaK23e8+G+4E+98laiHB7VzOr3BldHDd74qHHYvPn7xZ72kYOVMRYetsvSpJBXxBMzyvlZx7dz5ZM/SIvACcAtXgnFxSjNSXJoRYVeWRJNKF44lKf7QqXL/ciw8uryvXNcr6jXKI+u8oV1HUi9s/Cb933eFl4fb8dtZ3RwsbUs8o+y84kNaclq29iadK7T/z3xDv576Uy22bdKslU/b93sahsP/1snO0JsfP627b/y3vmjdU6cy86SzOdp7LE1Ld/zucM3Tmed1OvO8/jhb/PfpwIkLo6pfHzxVbLuyKCrsFjibmVvkn8ZLqyBYliXsShcC9PvxhzWxT4tCx1wZ+TOKeauXhtXyBKaKClsVcV2zn4BpxmsV185dT/YsCwIvgGrL1ZHi0owIuxKOQ0sZji8wb73f/40uu3/UxJ18zufopTWvSpI8iqivhwzly6aXPn9VPe9brOwa3pXZxSqvvJ/K305nOt1vVhgsuE55AlNFhS0zr+vqDbtmKu3UsIq6RmXhwRMAqjVXH8zh6qOaC8KxVPQfiC8OxyH+PiX2MTTAV71bBLn+pkpQ2tFlqxr289eqm51eZNgt4CFDdbPSNXT/N5XUs8tHs0A/p/vNCoMF1ynpkenOVMRj1C9Wlj45U1FPwCxJcT/rXO2TGdeoLAReAJeNIR1C9fU/B+jDSb0057Yu+nBSL339zwGFbpQrKhxL0qujujiE4xnXtS/xdaePiFCvlvXL/cvx4l/gVeFPhO426MA25dlcq2iezabBv8RXcI8uLx426c7ezZ0eKykM2v7/+UW5NKy68g/RS8+XKjZslaZPtv//dc814Qot4R/dlcnVgYCyXCPY333vyxmmNAC4rLg6d/jS6RJBfjV08qdtiroiuFC7eWO6FVqHV5Lq+Xlp1kXr8BY1rcIVzqZehPj7XtbTGur+mWafq1sST8NQ3T8LzwW+3JXls1hgUp/wItfjdWUa0aQ+F1ZpUBHHLw2rRc3br+fnJUOON2iWZtWX8iiqT5euiHFxfx4bckWVWiawvDcRF7pGaob0+7da9+A18vWpOlOICLwAUISLw3Fubq4+d75Kk/2HfUlPWivql6OzdXgvdekv8AujyxElrtJgZWdr+ttXZShJns2mszXrVEKvqo+CT+bAElZpuDSwetjk0jq8rtxY2rVpvVItUVhUOJPct9a0sz4Vt+ZxeW/YrQhm9KngGrm5/vr892+rxDSGixF4AcAEnh42Xd06SFe3Ln6ubnG/sEv7pLWC0WVn6/AWqOvnpdzz+UUer87Wt+6lob9sdamtp2FoXZveFdyjqq24UUdn6/AWBNuHB7Ur85PWSho9LMvoYlHhzJ0h0lmfqlqovdwReAGgkhX1C9uVwHypgsBQ0pPWXv/ygBZ+c1hn/yz+IRfl+RN3Zfu83V80/Yu35Z+dUeyNa/myKc23lta2vboSe1c2xa3DK1348/2tF63DWyDE31c3RjZT0/p+ZXrSWvSwiGKDrbOlx1xV0uhhVRzxhPUQeAGgmvP0sKlPmwbq06ZBkW3+EdVGUwa01o7E0zp2JlMJf5yVZCv3k9biD53U5iIerlDRsmt46+G/PqR3Pnla+bI5Db35//8P9w8Pf8htS5LV8a2h8CA/1fb2NO1Ja/Z5oKWcL1lcsPSu4VGuYAtUZQReALhM/G8krb5u6t6kyHalGWm+p29L5ZzP1/vxh5V4KkNGnqG07PNKSs0q9klr0in1Cq9X7iet5bYeqmi/Gope8aLqZl3ypDXD0DnfWnrsrw9pa7teql/JT1ob1D5Ejev5Ffsn+qdGdixT/av6fEmgqiHwAgDKxZWRwVuvbGr//7m5ufr888/17rge8vLycvl1/j6gtfMDE3tLbz8mffyxPD/9VDp9Wp6BgdINNyjg5pv1lm/RS7iNuLLo4H+xaX91uZsAqiACLwCg+vP1lcaMufAFAJfgwRMAAACwNAIvAAAALI3ACwAAAEsj8AIAAMDSCLwAAACwNAIvAAAALI3ACwAAAEsj8AIAAMDSCLwAAACwNAIvAAAALI3ACwAAAEsj8AIAAMDSari7A1WRYRiSpLS0tFKdl5ubq8zMTKWlpcnLy6siunZZoI7moZbmoZbmoZbmoZbmoI7mqcxaFuS0gtxWHAKvE+fOnZMkNWnSxM09AQAAQHHOnTungICAYtvYDFdi8WUmPz9fx44d04ABA7Rr1y6HY1deeaV27tzpdDstLU1NmjTR77//Ln9//wrp26WvXxHnltSuuONFHSuubpfuq4w6FtdXM881u5au7Kvsz2RR/TL7XGpp3rllrWVp9lfnWpbmPGpp3nkVXUt+75R8vKw/Ky/eV5m13LFjh86dO6ewsDB5eBQ/S5cRXic8PDzUuHFj1ahRo9A3y9PT02HfpduS5O/vX2HfZGevZ/a5JbUr7nhRx1yp26X7KrKOxfXVzHPNrqUr+yr7M1nUa5p9LrU079yy1rI0+6tzLUtzHrU077yKriW/d0o+Xtaflc72VUYtAwICShzZLcBNa8W47777StznrE1FKs/ruXpuSe2KO17UMVfqRi1LPlYVP5PlfU1qWXwfKuLcstayNPurcy1Lcx61NO+8iq4lv3dKPl7Wn5WuvK7ZSvt6TGkwUVpamgICApSamlqh/6qxOupoHmppHmppHmppHmppDuponqpaS0Z4TeTj46Pp06fLx8fH3V2p1qijeaileaileaileailOaijeapqLRnhBQAAgKUxwgsAAABLI/ACAADA0gi8AAAAsDQCLwAAACyNwAsAAABLI/C6UWZmppo1a6ZHHnnE3V2pts6ePavu3burS5cu6tChg9555x13d6na+v3339WvXz9FRESoU6dOWrFihbu7VG3dcMMNqlevnm6++WZ3d6Xa+eyzz9S2bVu1bt1a7777rru7U63xOTQHPxvN487f2SxL5kZPPPGEDh48qCZNmuill15yd3eqpby8PGVnZ8vPz08ZGRnq0KGDdu3apfr167u7a9VOUlKSUlJS1KVLFyUnJysyMlK//PKLatWq5e6uVTubNm3SuXPn9N577+njjz92d3eqjfPnzysiIkIbN25UQECAIiMjtXXrVv57LiM+h+bgZ6N53Pk7mxFeNzlw4IB+/vlnDR061N1dqdY8PT3l5+cnScrOzpZhGOLfcGUTGhqqLl26SJJCQkIUFBSk06dPu7dT1VS/fv1Up04dd3ej2tmxY4fat2+vRo0aqXbt2ho6dKjWr1/v7m5VW3wOzcHPRvO483c2gdeJLVu2aMSIEQoLC5PNZtOqVasKtZk7d66aN28uX19f9ezZUzt27CjVazzyyCOaNWuWST2uuiqjlmfPnlXnzp3VuHFjPfroowoKCjKp91VLZdSywO7du5WXl6cmTZqUs9dVT2XW8XJT3toeO3ZMjRo1sm83atRIR48erYyuVzl8Ts1jZi2t/LPRFWbU0l2/swm8TmRkZKhz586aO3eu0+PLly/X1KlTNX36dO3Zs0edO3fW4MGDdfz4cXubgvkpl34dO3ZM//3vf9WmTRu1adOmst6S21R0LSWpbt26+u6775SYmKilS5cqJSWlUt5bZauMWkrS6dOnNXbsWL399tsV/p7cobLqeDkyo7a4gFqax6xaWv1noyvMqKXbfmcbKJYk49NPP3XY16NHD+O+++6zb+fl5RlhYWHGrFmzXLrm448/bjRu3Nho1qyZUb9+fcPf39+IiYkxs9tVUkXU8lKTJ082VqxYUZ5uVgsVVcusrCyjT58+xuLFi83qapVWkZ/JjRs3GjfddJMZ3ayWylLbb775xhg5cqT9+D/+8Q9jyZIlldLfqqw8n9PL/XN4qbLW8nL72egKM35+VubvbEZ4SyknJ0e7d+9WVFSUfZ+Hh4eioqIUHx/v0jVmzZql33//XYcPH9ZLL72kSZMmadq0aRXV5SrLjFqmpKTo3LlzkqTU1FRt2bJFbdu2rZD+VmVm1NIwDI0fP14DBgzQnXfeWVFdrdLMqCOcc6W2PXr00N69e3X06FGlp6dr7dq1Gjx4sLu6XGXxOTWPK7XkZ6NrXKmlO39nE3hL6eTJk8rLy1NwcLDD/uDgYCUnJ7upV9WTGbX87bff1KdPH3Xu3Fl9+vTR/fffr44dO1ZEd6s0M2r5zTffaPny5Vq1apW6dOmiLl266IcffqiI7lZZZv33HRUVpVtuuUWff/65GjduTAiRa7WtUaOGXn75ZfXv319dunTRww8/zAoNTrj6OeVzWDJXasnPRte4Ukt3/s6uUSmvgiKNHz/e3V2o1nr06KGEhAR3d8MS/vKXvyg/P9/d3bCEL774wt1dqLauu+46XXfdde7uhiXwOTQHPxvN487f2YzwllJQUJA8PT0LTbJOSUlRSEiIm3pVPVFL81BLc1DHikNtzUMtzUMtzVPVa0ngLSVvb29FRkZqw4YN9n35+fnasGGDevfu7caeVT/U0jzU0hzUseJQW/NQS/NQS/NU9VoypcGJ9PR0HTx40L6dmJiohIQEBQYGqmnTppo6darGjRun7t27q0ePHpo9e7YyMjI0YcIEN/a6aqKW5qGW5qCOFYfamodamodamqda17JS1oKoZjZu3GhIKvQ1btw4e5vXXnvNaNq0qeHt7W306NHD2LZtm/s6XIVRS/NQS3NQx4pDbc1DLc1DLc1TnWtpMwyewwoAAADrYg4vAAAALI3ACwAAAEsj8AIAAMDSCLwAAACwNAIvAAAALI3ACwAAAEsj8AIAAMDSCLwAAACwNAIvAFSQfv366cEHH3R3N1yyaNEi1a1bt1zXOHz4sGw2mxISEir1dQGgJAReALjEiBEjNGTIEKfHvvrqK9lsNn3//feV3KvKtWjRIvXr16/Q/j/++EPe3t7q0KFD5XcKAMqIwAsAl5g4caLi4uL0xx9/FDq2cOFCde/eXZ06dXJDzwrLycmp1NdbtGiRbr31VqWlpWn79u2V+toAUFYEXgC4xF//+lc1aNBAixYtctifnp6uFStWaOLEiTp16pRGjx6tRo0ayc/PTx07dtSHH35Y7HWzs7P1yCOPqFGjRqpVq5Z69uypTZs22Y/PmDFDXbp0cThn9uzZat68uX17/PjxGjlypJ555hmFhYWpbdu2kqQ33nhDrVu3lq+vr4KDg3XzzTcX25dFixapadOm8vPz0w033KBTp06VWBfDMLRw4ULdeeeduv322zV//vxi22/atEk2m01r1qxRp06d5Ovrq169emnv3r2F2q5bt05XXHGFateurSFDhigpKcl+bOfOnRo4cKCCgoIUEBCgvn37as+ePSX2FwAKEHgB4BI1atTQ2LFjtWjRIhmGYd+/YsUK5eXlafTo0crKylJkZKTWrFmjvXv36u6779add96pHTt2FHndKVOmKD4+XsuWLdP333+vW265RUOGDNGBAwdK1b8NGzZo//79iouL02effaZdu3bpgQce0MyZM7V//37FxsbqmmuuKfL87du3a+LEiZoyZYoSEhLUv39/Pf300yW+7saNG5WZmamoqCiNGTNGy5YtU0ZGRonnPfroo3r55Ze1c+dONWjQQCNGjFBubq79eGZmpl566SW9//772rJli44cOaJHHnnEfvzcuXMaN26cvv76a23btk2tW7fWsGHDdO7cuRJfGwAkSQYAoJCffvrJkGRs3LjRvq9Pnz7GmDFjijxn+PDhxsMPP2zf7tu3r/GPf/zDMAzD+O233wxPT0/j6NGjDudce+21RnR0tGEYhjF9+nSjc+fODsdfffVVo1mzZvbtcePGGcHBwUZ2drZ93yeffGL4+/sbaWlpLr230aNHG8OGDXPYN2rUKCMgIKDY826//XbjwQcftG937tzZWLhwoX07MTHRkGR8++23hmEYxsaNGw1JxrJly+xtTp06ZdSsWdNYvny5YRiGsXDhQkOScfDgQXubuXPnGsHBwUX2Iy8vz6hTp46xevXqkt4qABiGYRiM8AKAE+3atdNVV12lBQsWSJIOHjyor776ShMnTpQk5eXl6amnnlLHjh0VGBio2rVra926dTpy5IjT6/3www/Ky8tTmzZtVLt2bfvX5s2bdejQoVL1rWPHjvL29rZvDxw4UM2aNVOLFi105513asmSJcrMzCzy/J9++kk9e/Z02Ne7d+9iX/Ps2bNauXKlxowZY983ZsyYEqc1XHrtwMBAtW3bVj/99JN9n5+fn1q2bGnfDg0N1fHjx+3bKSkpmjRpklq3bq2AgAD5+/srPT29yFoDwKVquLsDAFBVTZw4Uffff7/mzp2rhQsXqmXLlurbt68k6cUXX9ScOXM0e/ZsdezYUbVq1dKDDz5Y5E1k6enp8vT01O7du+Xp6elwrHbt2pIkDw8PhykUkhz+9F+gVq1aDtt16tTRnj17tGnTJq1fv17Tpk3TjBkztHPnTtOW/Fq6dKmysrIcgrJhGMrPz9cvv/yiNm3alPnaXl5eDts2m82hDuPGjdOpU6c0Z84cNWvWTD4+Purdu3el37AHoPpihBcAinDrrbfKw8NDS5cu1eLFi3XXXXfJZrNJkr755htdf/31GjNmjDp37qwWLVrol19+KfJaXbt2VV5eno4fP65WrVo5fIWEhEiSGjRooOTkZIew5+qatjVq1FBUVJReeOEFff/99zp8+LC+/PJLp22vuOKKQissbNu2rdjrz58/Xw8//LASEhLsX99995369OljHwUvysXXPnPmjH755RddccUVLr0v6UKtH3jgAQ0bNkzt27eXj4+PTp486fL5AMAILwAUoXbt2ho1apSio6OVlpam8ePH24+1bt1aH3/8sbZu3ap69erplVdeUUpKiiIiIpxeq02bNrrjjjs0duxYvfzyy+ratatOnDihDRs2qFOnTho+fLj69eunEydO6IUXXtDNN9+s2NhYrV27Vv7+/sX287PPPtOvv/6qa665RvXq1dPnn3+u/Px8+woOl3rggQd09dVX66WXXtL111+vdevWKTY2tsjrJyQkaM+ePVqyZInatWvncGz06NGaOXNmsTe9zZw5U/Xr11dwcLCeeOIJBQUFaeTIkcW+p4u1bt1a77//vrp37660tDQ9+uijqlmzpsvnAwAjvABQjIkTJ+rMmTMaPHiwwsLC7Pv//e9/q1u3bho8eLD69eunkJCQEkPcwoULNXbsWD388MNq27atRo4cqZ07d6pp06aSLoy8vvHGG5o7d646d+6sHTt2OKxWUJS6detq5cqVGjBggK644grNmzdPH374odq3b++0fa9evfTOO+9ozpw56ty5s9avX69///vfRV5//vz5ioiIKBR2JemGG27Q8ePH9fnnnxd5/nPPPad//OMfioyMVHJyslavXu0wB7kk8+fP15kzZ9StWzfdeeedeuCBB9SwYUOXzwcAm3HphDEAAEywadMm9e/fX2fOnOHxwQDcihFeAAAAWBqBFwAAAJbGlAYAAABYGiO8AAAAsDQCLwAAACyNwAsAAABLI/ACAADA0gi8AAAAsDQCLwAAACyNwAsAAABLI/ACAADA0gi8AAAAsLT/BytE9IlKApzMAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha_values = []\n",
    "mse_scores = []\n",
    "\n",
    "def objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-4, 1000, log=True)\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    y_pred = ridge.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # Stocke l'alpha et le score MSE correspondant\n",
    "    alpha_values.append(alpha)\n",
    "    mse_scores.append(mse)\n",
    "    return mse\n",
    "\n",
    "# Création d'une étude Optuna\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=200)\n",
    "\n",
    "# Obtient le meilleur alpha de Optuna\n",
    "best_alpha = study.best_params['alpha']\n",
    "\n",
    "# Entraîne le modèle Ridge en utilisant le meilleur alpha\n",
    "best_ridge = Ridge(alpha=best_alpha)\n",
    "best_ridge.fit(X_train, y_train)\n",
    "y_pred = best_ridge.predict(X_test)\n",
    "\n",
    "# Calcul des métriques\n",
    "mse_ridge = mean_squared_error(y_test, y_pred)\n",
    "r2_ridge = r2_score(y_test, y_pred)\n",
    "\n",
    "print('\\n')\n",
    "print(f\"Meilleur Alpha pour Ridge (Optuna) : {best_alpha}\")\n",
    "print(f\"Erreur quadratique moyenne avec Ridge (utilisant le meilleur alpha d'Optuna) : {mse_ridge}\")\n",
    "print(f\"r2 avec Ridge (utilisant le meilleur alpha d'Optuna) : {r2_ridge}\")\n",
    "\n",
    "affichage_poids(best_ridge)\n",
    "\n",
    "# Trace les scores MSE en fonction des valeurs d'alpha\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(alpha_values, mse_scores, marker='o')\n",
    "plt.plot(best_alpha, mse_ridge, marker='o', markersize=8, color='red')  # Point le plus optimisé\n",
    "plt.title('Score MSE vs Valeurs d\\'Alpha')\n",
    "plt.xlabel('Valeurs d\\'Alpha')\n",
    "plt.ylabel('Score MSE')\n",
    "plt.xscale('log')  # Puisque alpha est dans un espace logarithmique\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElasticNet\n",
    "ElasticNet utilise à la fois les pénalités L1 (comme Lasso) et L2 (comme Ridge) dans sa fonction de coût.\n",
    "Pouvant opter pour une stratégie hybride, ElasticNet est donc supposé être plus précis et pourrait générer des meilleures prédictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 17:02:40,763] A new study created in memory with name: no-name-1f377d5b-9db8-41f8-b1da-311eb1dac76b\n",
      "[I 2024-01-08 17:02:40,798] Trial 0 finished with value: 11885352.54302972 and parameters: {'alpha': 137.78530693371363, 'l1_ratio': 0.8370376137074338}. Best is trial 0 with value: 11885352.54302972.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.148e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:02:40,903] Trial 1 finished with value: 10675458.936381642 and parameters: {'alpha': 0.010090278500506289, 'l1_ratio': 0.7897984673110608}. Best is trial 1 with value: 10675458.936381642.\n",
      "[I 2024-01-08 17:02:40,979] Trial 2 finished with value: 9771093.967120782 and parameters: {'alpha': 0.027165887037114613, 'l1_ratio': 0.3011028345840959}. Best is trial 2 with value: 9771093.967120782.\n",
      "[I 2024-01-08 17:02:41,036] Trial 3 finished with value: 11857052.797669932 and parameters: {'alpha': 24.285636124917225, 'l1_ratio': 0.03511857035276633}. Best is trial 2 with value: 9771093.967120782.\n",
      "[I 2024-01-08 17:02:41,079] Trial 4 finished with value: 11735343.930656679 and parameters: {'alpha': 24.067794319066714, 'l1_ratio': 0.840952685286585}. Best is trial 2 with value: 9771093.967120782.\n",
      "[I 2024-01-08 17:02:41,132] Trial 5 finished with value: 11895353.41656098 and parameters: {'alpha': 62.23923482573397, 'l1_ratio': 0.5263415007473284}. Best is trial 2 with value: 9771093.967120782.\n",
      "[I 2024-01-08 17:02:41,219] Trial 6 finished with value: 10299538.156818835 and parameters: {'alpha': 0.12260722377957073, 'l1_ratio': 0.474079747166261}. Best is trial 2 with value: 9771093.967120782.\n",
      "[I 2024-01-08 17:02:41,290] Trial 7 finished with value: 11607718.453109648 and parameters: {'alpha': 1.4161240864509235, 'l1_ratio': 0.046909844710423476}. Best is trial 2 with value: 9771093.967120782.\n",
      "[I 2024-01-08 17:02:41,340] Trial 8 finished with value: 12397719.440189678 and parameters: {'alpha': 174.17858532114386, 'l1_ratio': 0.024005340527137875}. Best is trial 2 with value: 9771093.967120782.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.197e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:02:41,473] Trial 9 finished with value: 12603273.932576887 and parameters: {'alpha': 0.0003711067334732372, 'l1_ratio': 0.01869871310181548}. Best is trial 2 with value: 9771093.967120782.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.999e+06, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:02:41,631] Trial 10 finished with value: 16165917.656664237 and parameters: {'alpha': 0.00010541970683170914, 'l1_ratio': 0.3263195468277994}. Best is trial 2 with value: 9771093.967120782.\n",
      "[I 2024-01-08 17:02:41,733] Trial 11 finished with value: 9876466.13743231 and parameters: {'alpha': 0.05212425735280792, 'l1_ratio': 0.4607177217888284}. Best is trial 2 with value: 9771093.967120782.\n",
      "[I 2024-01-08 17:02:41,853] Trial 12 finished with value: 9797478.205974832 and parameters: {'alpha': 0.012617339898239993, 'l1_ratio': 0.28073928447426816}. Best is trial 2 with value: 9771093.967120782.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.613e+06, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:02:41,965] Trial 13 finished with value: 10550040.986387677 and parameters: {'alpha': 0.003259046207511129, 'l1_ratio': 0.25195313945654924}. Best is trial 2 with value: 9771093.967120782.\n",
      "[I 2024-01-08 17:02:42,001] Trial 14 finished with value: 11573901.451390412 and parameters: {'alpha': 1.4855823501718355, 'l1_ratio': 0.25278349725701943}. Best is trial 2 with value: 9771093.967120782.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.280e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:02:42,081] Trial 15 finished with value: 11994372.876485055 and parameters: {'alpha': 0.0018909748036391744, 'l1_ratio': 0.6447348444893702}. Best is trial 2 with value: 9771093.967120782.\n",
      "[I 2024-01-08 17:02:42,148] Trial 16 finished with value: 9756630.473779196 and parameters: {'alpha': 0.02110540835355801, 'l1_ratio': 0.18883860787723192}. Best is trial 16 with value: 9756630.473779196.\n",
      "[I 2024-01-08 17:02:42,192] Trial 17 finished with value: 11453318.2308135 and parameters: {'alpha': 0.833996019464603, 'l1_ratio': 0.2038191178625747}. Best is trial 16 with value: 9756630.473779196.\n",
      "[I 2024-01-08 17:02:42,258] Trial 18 finished with value: 10041104.542510971 and parameters: {'alpha': 0.04813948572347949, 'l1_ratio': 0.15210436016173923}. Best is trial 16 with value: 9756630.473779196.\n",
      "[I 2024-01-08 17:02:42,288] Trial 19 finished with value: 13376150.15946126 and parameters: {'alpha': 923.3569966149785, 'l1_ratio': 0.3853300067279417}. Best is trial 16 with value: 9756630.473779196.\n",
      "[I 2024-01-08 17:02:42,353] Trial 20 finished with value: 9744821.632020075 and parameters: {'alpha': 0.27413942251218654, 'l1_ratio': 0.956889000813532}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:42,430] Trial 21 finished with value: 9818156.685250804 and parameters: {'alpha': 0.16077786426938578, 'l1_ratio': 0.9497259533227187}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:42,464] Trial 22 finished with value: 11712335.551294522 and parameters: {'alpha': 4.206974250389856, 'l1_ratio': 0.14347574976996968}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:42,550] Trial 23 finished with value: 9912083.892607028 and parameters: {'alpha': 0.0169164216669704, 'l1_ratio': 0.6201537267093777}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:42,614] Trial 24 finished with value: 11013451.859088594 and parameters: {'alpha': 0.33894076228010106, 'l1_ratio': 0.3617546278932816}. Best is trial 20 with value: 9744821.632020075.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.916e+06, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:02:42,688] Trial 25 finished with value: 18882982.542167976 and parameters: {'alpha': 0.0021518301655659576, 'l1_ratio': 0.9799438570628081}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:42,753] Trial 26 finished with value: 9939392.388911659 and parameters: {'alpha': 0.03796050048871366, 'l1_ratio': 0.1331115511943579}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:42,805] Trial 27 finished with value: 10786124.119226474 and parameters: {'alpha': 0.33835919541140624, 'l1_ratio': 0.5786894649479042}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:42,865] Trial 28 finished with value: 11666954.816854274 and parameters: {'alpha': 6.592477416346577, 'l1_ratio': 0.6935392539845002}. Best is trial 20 with value: 9744821.632020075.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.465e+06, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:02:42,981] Trial 29 finished with value: 10486591.381113146 and parameters: {'alpha': 0.004430372558401986, 'l1_ratio': 0.4076600507595013}. Best is trial 20 with value: 9744821.632020075.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.289e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:02:43,069] Trial 30 finished with value: 13894977.33117353 and parameters: {'alpha': 0.0006542953726040191, 'l1_ratio': 0.7927442072199464}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:43,153] Trial 31 finished with value: 9790241.293242855 and parameters: {'alpha': 0.013414933961362749, 'l1_ratio': 0.30220056565201403}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:43,249] Trial 32 finished with value: 9961327.568608547 and parameters: {'alpha': 0.008350911475282313, 'l1_ratio': 0.3090131444919276}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:43,324] Trial 33 finished with value: 9756293.515579853 and parameters: {'alpha': 0.021383662218754297, 'l1_ratio': 0.20178445811004206}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:43,374] Trial 34 finished with value: 10378900.007526264 and parameters: {'alpha': 0.09125302135683015, 'l1_ratio': 0.19746948918057183}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:43,449] Trial 35 finished with value: 9859301.968897529 and parameters: {'alpha': 0.028992141738562058, 'l1_ratio': 0.07695546087140104}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:43,502] Trial 36 finished with value: 10793045.128593696 and parameters: {'alpha': 0.15939894698393378, 'l1_ratio': 0.09631382860754029}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:43,556] Trial 37 finished with value: 10453239.588899788 and parameters: {'alpha': 0.605696698333734, 'l1_ratio': 0.8624592547675292}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:43,667] Trial 38 finished with value: 10134672.034944085 and parameters: {'alpha': 0.005339521388574227, 'l1_ratio': 0.20876928213691517}. Best is trial 20 with value: 9744821.632020075.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.227e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:02:43,736] Trial 39 finished with value: 12022453.899903823 and parameters: {'alpha': 0.0011382835878010749, 'l1_ratio': 0.42319201697574993}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:43,800] Trial 40 finished with value: 10021374.265351668 and parameters: {'alpha': 0.0810400249771978, 'l1_ratio': 0.5150980882059679}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:43,882] Trial 41 finished with value: 9756559.898152398 and parameters: {'alpha': 0.026387857090741398, 'l1_ratio': 0.35122671763495067}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:43,958] Trial 42 finished with value: 9749142.613307102 and parameters: {'alpha': 0.024971918795241167, 'l1_ratio': 0.36919824531163126}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:44,025] Trial 43 finished with value: 9770123.219514113 and parameters: {'alpha': 0.02955939995653973, 'l1_ratio': 0.36132485593070773}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:44,074] Trial 44 finished with value: 10644106.46187201 and parameters: {'alpha': 0.19959789669954167, 'l1_ratio': 0.43743022182630537}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:44,183] Trial 45 finished with value: 9949329.194063284 and parameters: {'alpha': 0.0077668117462228225, 'l1_ratio': 0.2378566284021399}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:44,255] Trial 46 finished with value: 9746414.694225674 and parameters: {'alpha': 0.019879952722629945, 'l1_ratio': 0.3421820813738612}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:44,314] Trial 47 finished with value: 10108924.901227208 and parameters: {'alpha': 0.08812148829080112, 'l1_ratio': 0.4722670375708672}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:44,380] Trial 48 finished with value: 10038632.910737244 and parameters: {'alpha': 0.06170504691712181, 'l1_ratio': 0.3414205707801392}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:44,423] Trial 49 finished with value: 11629173.098388037 and parameters: {'alpha': 3.4111039852024985, 'l1_ratio': 0.5504903565924454}. Best is trial 20 with value: 9744821.632020075.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.645e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:02:44,507] Trial 50 finished with value: 13055944.800795184 and parameters: {'alpha': 0.0003050849794884173, 'l1_ratio': 0.27452282698869573}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:44,600] Trial 51 finished with value: 9747514.123783756 and parameters: {'alpha': 0.018439967718331663, 'l1_ratio': 0.1706514294179902}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:44,685] Trial 52 finished with value: 9772415.338307498 and parameters: {'alpha': 0.016798356680766832, 'l1_ratio': 0.39091487258376745}. Best is trial 20 with value: 9744821.632020075.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.138e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:02:44,801] Trial 53 finished with value: 10827404.329892024 and parameters: {'alpha': 0.006481939529879522, 'l1_ratio': 0.7202802516445471}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:44,864] Trial 54 finished with value: 9866265.206265822 and parameters: {'alpha': 0.040055274357371363, 'l1_ratio': 0.3182428364429516}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:44,907] Trial 55 finished with value: 11361050.31097916 and parameters: {'alpha': 0.6436593404469421, 'l1_ratio': 0.2340496038067513}. Best is trial 20 with value: 9744821.632020075.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.298e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:02:45,039] Trial 56 finished with value: 10309937.142121308 and parameters: {'alpha': 0.0038763021984731466, 'l1_ratio': 0.15468869306174843}. Best is trial 20 with value: 9744821.632020075.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.348e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:02:45,124] Trial 57 finished with value: 11473723.466008637 and parameters: {'alpha': 0.0019964703352389297, 'l1_ratio': 0.4913419706469697}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:45,201] Trial 58 finished with value: 9773357.224498814 and parameters: {'alpha': 0.021680202708737325, 'l1_ratio': 0.11293324918799885}. Best is trial 20 with value: 9744821.632020075.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.748e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:02:45,291] Trial 59 finished with value: 11319167.958708629 and parameters: {'alpha': 0.01149777021707752, 'l1_ratio': 0.8995501774368294}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:45,352] Trial 60 finished with value: 10963077.232497722 and parameters: {'alpha': 0.2070666535074668, 'l1_ratio': 0.053513036341079484}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:45,421] Trial 61 finished with value: 9765579.481804812 and parameters: {'alpha': 0.02247631883917446, 'l1_ratio': 0.1843343714253032}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:45,488] Trial 62 finished with value: 9873843.183448516 and parameters: {'alpha': 0.04303469672141659, 'l1_ratio': 0.3517778861196302}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:45,582] Trial 63 finished with value: 9841612.13028656 and parameters: {'alpha': 0.01055122030044422, 'l1_ratio': 0.2638753412946094}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:45,634] Trial 64 finished with value: 10551652.415425017 and parameters: {'alpha': 0.11522976366988576, 'l1_ratio': 0.16186832272449636}. Best is trial 20 with value: 9744821.632020075.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.164e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:02:45,755] Trial 65 finished with value: 10518699.97596442 and parameters: {'alpha': 0.0032407094691017553, 'l1_ratio': 0.2200617620389178}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:45,805] Trial 66 finished with value: 11119072.699285466 and parameters: {'alpha': 0.376289821990438, 'l1_ratio': 0.2848453134542547}. Best is trial 20 with value: 9744821.632020075.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.046e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:02:45,882] Trial 67 finished with value: 12125393.659995658 and parameters: {'alpha': 0.0010710303118124517, 'l1_ratio': 0.4373613279631499}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:45,918] Trial 68 finished with value: 11591614.142901465 and parameters: {'alpha': 1.393897067848309, 'l1_ratio': 0.12119799236123072}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:46,001] Trial 69 finished with value: 9745626.98996768 and parameters: {'alpha': 0.015585070528221315, 'l1_ratio': 0.07268033742704227}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:46,063] Trial 70 finished with value: 10158269.542424843 and parameters: {'alpha': 0.05481450656464677, 'l1_ratio': 0.07533515359773622}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:46,148] Trial 71 finished with value: 9757128.995411111 and parameters: {'alpha': 0.017445880834715526, 'l1_ratio': 0.01477583399774058}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:46,238] Trial 72 finished with value: 9905300.747342953 and parameters: {'alpha': 0.008032270807004421, 'l1_ratio': 0.1856231312140597}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:46,304] Trial 73 finished with value: 9870672.92322655 and parameters: {'alpha': 0.03051583624654338, 'l1_ratio': 0.09400903623131174}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:46,370] Trial 74 finished with value: 10290548.243758311 and parameters: {'alpha': 0.06582388990086357, 'l1_ratio': 0.03671573661168223}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:46,450] Trial 75 finished with value: 9759825.50352301 and parameters: {'alpha': 0.013515141085366321, 'l1_ratio': 0.17581987789522918}. Best is trial 20 with value: 9744821.632020075.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.474e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:02:46,570] Trial 76 finished with value: 10813282.16527961 and parameters: {'alpha': 0.002955702477213268, 'l1_ratio': 0.3775973845282577}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:46,670] Trial 77 finished with value: 10159739.157058636 and parameters: {'alpha': 0.00596713791570429, 'l1_ratio': 0.3192729392222322}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:46,704] Trial 78 finished with value: 11953141.700336866 and parameters: {'alpha': 49.514930555915264, 'l1_ratio': 0.1296296236690549}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:46,758] Trial 79 finished with value: 10524677.512959924 and parameters: {'alpha': 0.12104515859612226, 'l1_ratio': 0.23581874899194988}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:46,834] Trial 80 finished with value: 9756477.989765655 and parameters: {'alpha': 0.024226008388736182, 'l1_ratio': 0.29402793307564407}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:46,901] Trial 81 finished with value: 9776694.057905445 and parameters: {'alpha': 0.027321957483357487, 'l1_ratio': 0.2827371415874471}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:46,982] Trial 82 finished with value: 9745304.112792378 and parameters: {'alpha': 0.018328195395941906, 'l1_ratio': 0.2500235409082894}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:47,045] Trial 83 finished with value: 9933494.626292612 and parameters: {'alpha': 0.049552456213217244, 'l1_ratio': 0.3446131767955686}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:47,136] Trial 84 finished with value: 9916671.071698025 and parameters: {'alpha': 0.010680388157813145, 'l1_ratio': 0.404074792744615}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:47,205] Trial 85 finished with value: 9747219.2622631 and parameters: {'alpha': 0.01824837569405296, 'l1_ratio': 0.2960267947165627}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:47,316] Trial 86 finished with value: 10207996.389700338 and parameters: {'alpha': 0.0050784849037074, 'l1_ratio': 0.25601443002490765}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:47,388] Trial 87 finished with value: 9745243.727358097 and parameters: {'alpha': 0.019590867248973284, 'l1_ratio': 0.2929001508351086}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:47,467] Trial 88 finished with value: 9745438.386819756 and parameters: {'alpha': 0.017400661444776127, 'l1_ratio': 0.21710001723849304}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:47,542] Trial 89 finished with value: 9754946.543417893 and parameters: {'alpha': 0.014915729060671575, 'l1_ratio': 0.22133661105480457}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:47,641] Trial 90 finished with value: 9947632.847254775 and parameters: {'alpha': 0.008531809366884168, 'l1_ratio': 0.3037383562924132}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:47,779] Trial 91 finished with value: 9762235.264864534 and parameters: {'alpha': 0.014092863729948547, 'l1_ratio': 0.22401351991207763}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:47,859] Trial 92 finished with value: 9847457.913489131 and parameters: {'alpha': 0.0350311960948887, 'l1_ratio': 0.26267146034395933}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:47,919] Trial 93 finished with value: 10127653.257718854 and parameters: {'alpha': 0.07205925449673392, 'l1_ratio': 0.33310670495229033}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:48,003] Trial 94 finished with value: 9751644.52040096 and parameters: {'alpha': 0.01594264012125864, 'l1_ratio': 0.24575516969413846}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:48,086] Trial 95 finished with value: 9745403.105345631 and parameters: {'alpha': 0.018123452119786856, 'l1_ratio': 0.24760595746069766}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:48,121] Trial 96 finished with value: 11779313.172003156 and parameters: {'alpha': 12.074769067268127, 'l1_ratio': 0.1657019942036814}. Best is trial 20 with value: 9744821.632020075.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.439e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:02:48,208] Trial 97 finished with value: 11908041.842735568 and parameters: {'alpha': 0.0025979621865329307, 'l1_ratio': 0.7229006346175231}. Best is trial 20 with value: 9744821.632020075.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.183e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:02:48,320] Trial 98 finished with value: 11544258.615056027 and parameters: {'alpha': 0.0015186278652867542, 'l1_ratio': 0.3684019444188167}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:48,369] Trial 99 finished with value: 10943999.30857871 and parameters: {'alpha': 0.2370818222397187, 'l1_ratio': 0.2024184121544984}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:48,488] Trial 100 finished with value: 10327183.786858806 and parameters: {'alpha': 0.0046806307668681504, 'l1_ratio': 0.31587544705159587}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:48,555] Trial 101 finished with value: 9925544.317291742 and parameters: {'alpha': 0.042534520312796587, 'l1_ratio': 0.2509171723946375}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:48,642] Trial 102 finished with value: 9745609.619912224 and parameters: {'alpha': 0.01863031777391103, 'l1_ratio': 0.27735922382624123}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:48,740] Trial 103 finished with value: 9892366.70777289 and parameters: {'alpha': 0.009450558759720548, 'l1_ratio': 0.2856607808120119}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:48,770] Trial 104 finished with value: 12885125.338928623 and parameters: {'alpha': 479.2145346887723, 'l1_ratio': 0.2657131538025586}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:48,856] Trial 105 finished with value: 9750217.881958421 and parameters: {'alpha': 0.01879384389294289, 'l1_ratio': 0.14994764149753304}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:48,967] Trial 106 finished with value: 10086964.014534235 and parameters: {'alpha': 0.006523025693343051, 'l1_ratio': 0.2998506965192973}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:49,031] Trial 107 finished with value: 10369036.566467673 and parameters: {'alpha': 0.10806096330401499, 'l1_ratio': 0.332608699147415}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:49,099] Trial 108 finished with value: 9885911.47321751 and parameters: {'alpha': 0.03628079312488871, 'l1_ratio': 0.20524083021406841}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:49,172] Trial 109 finished with value: 9801338.463163346 and parameters: {'alpha': 0.02174709023137542, 'l1_ratio': 0.5903423207552542}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:49,258] Trial 110 finished with value: 9767301.904367687 and parameters: {'alpha': 0.011234044500568589, 'l1_ratio': 0.058857628349711755}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:49,336] Trial 111 finished with value: 9756294.390673509 and parameters: {'alpha': 0.01989604260829719, 'l1_ratio': 0.14224833580630686}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:49,389] Trial 112 finished with value: 10150308.445468856 and parameters: {'alpha': 0.060834777002817315, 'l1_ratio': 0.17815130906741444}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:49,467] Trial 113 finished with value: 9872733.177301584 and parameters: {'alpha': 0.032651694981189576, 'l1_ratio': 0.14836842815063528}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:49,565] Trial 114 finished with value: 9880984.82125111 and parameters: {'alpha': 0.007732344299323645, 'l1_ratio': 0.10078871452648677}. Best is trial 20 with value: 9744821.632020075.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.112e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:02:49,635] Trial 115 finished with value: 15263623.097757012 and parameters: {'alpha': 0.01777087108070833, 'l1_ratio': 0.9953382221618863}. Best is trial 20 with value: 9744821.632020075.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.082e+06, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:02:49,741] Trial 116 finished with value: 10533200.724988827 and parameters: {'alpha': 0.004089431564320125, 'l1_ratio': 0.3922681443530352}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:49,850] Trial 117 finished with value: 9756036.243340926 and parameters: {'alpha': 0.011519617542310723, 'l1_ratio': 0.0008552499491084192}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:49,952] Trial 118 finished with value: 10296960.076220632 and parameters: {'alpha': 0.045022895778169224, 'l1_ratio': 0.9262380018334357}. Best is trial 20 with value: 9744821.632020075.\n",
      "[I 2024-01-08 17:02:50,008] Trial 119 finished with value: 9743965.326113414 and parameters: {'alpha': 0.07608429602697854, 'l1_ratio': 0.8193821330601591}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:50,074] Trial 120 finished with value: 9744320.612152487 and parameters: {'alpha': 0.08822303775222096, 'l1_ratio': 0.8514071046419232}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:50,133] Trial 121 finished with value: 9749666.291771539 and parameters: {'alpha': 0.1687951249666901, 'l1_ratio': 0.9035319385686329}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:50,185] Trial 122 finished with value: 10188442.872355094 and parameters: {'alpha': 0.2740931955254408, 'l1_ratio': 0.8031263670711917}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:50,233] Trial 123 finished with value: 10479146.905319111 and parameters: {'alpha': 0.5364818061291375, 'l1_ratio': 0.8384525490239909}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:50,299] Trial 124 finished with value: 9858969.235129682 and parameters: {'alpha': 0.08606720982843274, 'l1_ratio': 0.6891390675109664}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:50,357] Trial 125 finished with value: 9781372.055002816 and parameters: {'alpha': 0.14489095312917766, 'l1_ratio': 0.8606828407937684}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:50,467] Trial 126 finished with value: 10554687.115364684 and parameters: {'alpha': 0.026919822312081867, 'l1_ratio': 0.9101212296728519}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:50,567] Trial 127 finished with value: 10354307.173266985 and parameters: {'alpha': 0.07277730240127354, 'l1_ratio': 0.9578138250157002}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:50,632] Trial 128 finished with value: 9786137.071921397 and parameters: {'alpha': 0.044594533872081676, 'l1_ratio': 0.7881175269646773}. Best is trial 119 with value: 9743965.326113414.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.220e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:02:50,731] Trial 129 finished with value: 11083562.376575647 and parameters: {'alpha': 0.03210163491181186, 'l1_ratio': 0.9558593645788952}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:50,815] Trial 130 finished with value: 9767837.202934897 and parameters: {'alpha': 0.013772849700074006, 'l1_ratio': 0.2356118232552035}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:50,869] Trial 131 finished with value: 9790481.479174357 and parameters: {'alpha': 0.15753577235844493, 'l1_ratio': 0.8661956993092098}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:50,920] Trial 132 finished with value: 10244801.490773905 and parameters: {'alpha': 0.3263403283773826, 'l1_ratio': 0.8179419696619624}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:50,991] Trial 133 finished with value: 9802291.50678962 and parameters: {'alpha': 0.0957808542523955, 'l1_ratio': 0.7691365164365075}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:51,070] Trial 134 finished with value: 9881134.03226168 and parameters: {'alpha': 0.05854925964291512, 'l1_ratio': 0.8825332380729949}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:51,120] Trial 135 finished with value: 9935739.608076006 and parameters: {'alpha': 0.4819657052830338, 'l1_ratio': 0.9312660118980557}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:51,169] Trial 136 finished with value: 10753465.29692547 and parameters: {'alpha': 0.1853954550167389, 'l1_ratio': 0.27373322946095047}. Best is trial 119 with value: 9743965.326113414.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.109e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:02:51,252] Trial 137 finished with value: 12099828.662401464 and parameters: {'alpha': 0.006846778968495096, 'l1_ratio': 0.9099545406263598}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:51,321] Trial 138 finished with value: 9775810.092276506 and parameters: {'alpha': 0.027866436914880017, 'l1_ratio': 0.30010149406002734}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:51,382] Trial 139 finished with value: 10818224.253657613 and parameters: {'alpha': 1.3089320908624216, 'l1_ratio': 0.883869542545948}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:51,531] Trial 140 finished with value: 9747880.843391566 and parameters: {'alpha': 0.01964862505832906, 'l1_ratio': 0.3551986551899499}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:51,603] Trial 141 finished with value: 9747096.475659326 and parameters: {'alpha': 0.019914973155999664, 'l1_ratio': 0.35399727667037}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:51,699] Trial 142 finished with value: 9823949.298732473 and parameters: {'alpha': 0.014128651723422739, 'l1_ratio': 0.418486021017217}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:51,775] Trial 143 finished with value: 9745298.39321415 and parameters: {'alpha': 0.02239909145072685, 'l1_ratio': 0.36454645741166614}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:51,855] Trial 144 finished with value: 9746117.745814368 and parameters: {'alpha': 0.02048668936418232, 'l1_ratio': 0.3565676608745184}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:51,955] Trial 145 finished with value: 9925342.137291417 and parameters: {'alpha': 0.00916973587301984, 'l1_ratio': 0.3194689450403011}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:52,035] Trial 146 finished with value: 9745381.786905792 and parameters: {'alpha': 0.02184618697468311, 'l1_ratio': 0.3795125776832781}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:52,120] Trial 147 finished with value: 9745277.88686253 and parameters: {'alpha': 0.023049954769193234, 'l1_ratio': 0.38310011988713444}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:52,192] Trial 148 finished with value: 9778255.277949775 and parameters: {'alpha': 0.034805655585437995, 'l1_ratio': 0.4320465740612425}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:52,271] Trial 149 finished with value: 9750705.011718253 and parameters: {'alpha': 0.025627257998781995, 'l1_ratio': 0.37186081405216975}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:52,358] Trial 150 finished with value: 9837428.38751212 and parameters: {'alpha': 0.01294021704720431, 'l1_ratio': 0.3922239897944324}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:52,442] Trial 151 finished with value: 9779674.06844979 and parameters: {'alpha': 0.018093408510595266, 'l1_ratio': 0.4564890905216182}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:52,536] Trial 152 finished with value: 9901171.93991056 and parameters: {'alpha': 0.00998806460333276, 'l1_ratio': 0.3387542186924277}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:52,603] Trial 153 finished with value: 9920211.536358485 and parameters: {'alpha': 0.048795396907168435, 'l1_ratio': 0.3551309014418352}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:52,688] Trial 154 finished with value: 9747708.609818634 and parameters: {'alpha': 0.02258848631612139, 'l1_ratio': 0.31959286136184006}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:52,753] Trial 155 finished with value: 9813756.242678592 and parameters: {'alpha': 0.03711802543237327, 'l1_ratio': 0.37854248975169397}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:52,838] Trial 156 finished with value: 9772658.847632281 and parameters: {'alpha': 0.015355422164759209, 'l1_ratio': 0.33430560598650916}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:52,922] Trial 157 finished with value: 9745220.612371242 and parameters: {'alpha': 0.023755888449352246, 'l1_ratio': 0.40486409559613434}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:52,988] Trial 158 finished with value: 9928251.237398133 and parameters: {'alpha': 0.05840086948702549, 'l1_ratio': 0.4505021892636718}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:53,058] Trial 159 finished with value: 9745482.546340689 and parameters: {'alpha': 0.026255920999451125, 'l1_ratio': 0.48973101450867196}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:53,171] Trial 160 finished with value: 10391886.81482104 and parameters: {'alpha': 0.005921891553802806, 'l1_ratio': 0.5026116148779174}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:53,247] Trial 161 finished with value: 9750965.841426918 and parameters: {'alpha': 0.026491230827888932, 'l1_ratio': 0.3902600585099414}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:53,340] Trial 162 finished with value: 10065832.386243017 and parameters: {'alpha': 0.010377012026486557, 'l1_ratio': 0.5439879948377132}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:53,409] Trial 163 finished with value: 9807273.195357874 and parameters: {'alpha': 0.03834117928676893, 'l1_ratio': 0.41295140390832147}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:53,484] Trial 164 finished with value: 9755037.048258264 and parameters: {'alpha': 0.0223345164715252, 'l1_ratio': 0.48181335537591385}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:53,574] Trial 165 finished with value: 9812184.911463534 and parameters: {'alpha': 0.014307754088268256, 'l1_ratio': 0.4014818873427479}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:53,652] Trial 166 finished with value: 9766807.074080724 and parameters: {'alpha': 0.02902699334178209, 'l1_ratio': 0.3629840314661249}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:53,720] Trial 167 finished with value: 9872370.232610641 and parameters: {'alpha': 0.07501853520287474, 'l1_ratio': 0.6293434605068411}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:53,787] Trial 168 finished with value: 9923119.732367357 and parameters: {'alpha': 0.04359894264348581, 'l1_ratio': 0.2733905579468273}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:53,887] Trial 169 finished with value: 10067713.512910716 and parameters: {'alpha': 0.008316138449798087, 'l1_ratio': 0.4326615673898752}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:53,956] Trial 170 finished with value: 9749687.887711564 and parameters: {'alpha': 0.01905347338857215, 'l1_ratio': 0.3536908389515471}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:54,044] Trial 171 finished with value: 9807763.894111536 and parameters: {'alpha': 0.0126684702551236, 'l1_ratio': 0.31241705690895455}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:54,119] Trial 172 finished with value: 9745956.095210098 and parameters: {'alpha': 0.01875649974917769, 'l1_ratio': 0.2922573785908025}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:54,201] Trial 173 finished with value: 9760911.555694861 and parameters: {'alpha': 0.025122425226784637, 'l1_ratio': 0.29392091659069175}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:54,280] Trial 174 finished with value: 9748647.767709242 and parameters: {'alpha': 0.016668061721799205, 'l1_ratio': 0.24855654629690835}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:54,348] Trial 175 finished with value: 9789164.792037824 and parameters: {'alpha': 0.031217176801832017, 'l1_ratio': 0.33209010866437694}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:54,438] Trial 176 finished with value: 9870741.374226948 and parameters: {'alpha': 0.011576619195691862, 'l1_ratio': 0.383293070098748}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:54,483] Trial 177 finished with value: 11394987.044521092 and parameters: {'alpha': 0.835558877802474, 'l1_ratio': 0.34618867633320394}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:54,592] Trial 178 finished with value: 10010110.203813314 and parameters: {'alpha': 0.053398393618946494, 'l1_ratio': 0.281359549253804}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:54,684] Trial 179 finished with value: 9751072.111992184 and parameters: {'alpha': 0.02061721023193886, 'l1_ratio': 0.4139022787146711}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:54,782] Trial 180 finished with value: 9990794.8785386 and parameters: {'alpha': 0.007866415545943401, 'l1_ratio': 0.30892656865034507}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:54,867] Trial 181 finished with value: 9747065.447652278 and parameters: {'alpha': 0.01738969932501966, 'l1_ratio': 0.2583464149585582}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:54,942] Trial 182 finished with value: 9747697.660521338 and parameters: {'alpha': 0.017133618576837168, 'l1_ratio': 0.2568559720452357}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:55,008] Trial 183 finished with value: 9884767.438023299 and parameters: {'alpha': 0.03695606435994632, 'l1_ratio': 0.22210137076126785}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:55,097] Trial 184 finished with value: 9926828.980005298 and parameters: {'alpha': 0.02544034777373378, 'l1_ratio': 0.7561973753696342}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:55,183] Trial 185 finished with value: 9797583.377828063 and parameters: {'alpha': 0.012389151635898881, 'l1_ratio': 0.26776256818972183}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:55,258] Trial 186 finished with value: 9777403.819948789 and parameters: {'alpha': 0.0159107728809104, 'l1_ratio': 0.37419278449674503}. Best is trial 119 with value: 9743965.326113414.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.336e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:02:55,348] Trial 187 finished with value: 12575447.519626377 and parameters: {'alpha': 0.022075606908829672, 'l1_ratio': 0.9826095330680338}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:55,415] Trial 188 finished with value: 9853407.347500866 and parameters: {'alpha': 0.03424081592277867, 'l1_ratio': 0.23191387217082984}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:55,508] Trial 189 finished with value: 9939945.082077837 and parameters: {'alpha': 0.009010265484307667, 'l1_ratio': 0.3296404115273641}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:55,573] Trial 190 finished with value: 9816614.300728481 and parameters: {'alpha': 0.04945581714175757, 'l1_ratio': 0.5284962761780472}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:55,655] Trial 191 finished with value: 9750406.83946776 and parameters: {'alpha': 0.01762913289354034, 'l1_ratio': 0.30781141641441084}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:55,742] Trial 192 finished with value: 9749622.38381686 and parameters: {'alpha': 0.022359479060042133, 'l1_ratio': 0.2909035779857207}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:55,826] Trial 193 finished with value: 9808587.194185441 and parameters: {'alpha': 0.012159890737689086, 'l1_ratio': 0.2857898710198899}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:55,899] Trial 194 finished with value: 9785218.403802428 and parameters: {'alpha': 0.027652647135558775, 'l1_ratio': 0.2599287738513578}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:55,984] Trial 195 finished with value: 9795012.189648036 and parameters: {'alpha': 0.014376329424222595, 'l1_ratio': 0.3624866674146071}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:56,072] Trial 196 finished with value: 9858077.284916947 and parameters: {'alpha': 0.01830450528261423, 'l1_ratio': 0.59656542731496}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:56,153] Trial 197 finished with value: 9762716.642972348 and parameters: {'alpha': 0.03369295686152109, 'l1_ratio': 0.6788503599430917}. Best is trial 119 with value: 9743965.326113414.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.259e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:02:56,240] Trial 198 finished with value: 14013096.19836389 and parameters: {'alpha': 0.00016339142490142818, 'l1_ratio': 0.21029570870436948}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:56,349] Trial 199 finished with value: 10169333.079653576 and parameters: {'alpha': 0.005278832104770103, 'l1_ratio': 0.24167605131938935}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:56,440] Trial 200 finished with value: 9919089.300476314 and parameters: {'alpha': 0.009613453156572792, 'l1_ratio': 0.34153220733461936}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:56,520] Trial 201 finished with value: 9747372.906430803 and parameters: {'alpha': 0.02106748926678933, 'l1_ratio': 0.27559202236577807}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:56,599] Trial 202 finished with value: 9761385.165301526 and parameters: {'alpha': 0.02496635178218722, 'l1_ratio': 0.28697626356532163}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:56,686] Trial 203 finished with value: 9785754.48594676 and parameters: {'alpha': 0.013896400667712437, 'l1_ratio': 0.3123101975160527}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:56,773] Trial 204 finished with value: 9745350.132191733 and parameters: {'alpha': 0.018414260405727283, 'l1_ratio': 0.2569376649411285}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:56,842] Trial 205 finished with value: 9776413.952465564 and parameters: {'alpha': 0.032171721047808244, 'l1_ratio': 0.3916335260792411}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:56,938] Trial 206 finished with value: 9824205.960256943 and parameters: {'alpha': 0.010925249239094041, 'l1_ratio': 0.2480269399692117}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:57,009] Trial 207 finished with value: 9889706.794249918 and parameters: {'alpha': 0.043299762723974344, 'l1_ratio': 0.32708649045792526}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:57,100] Trial 208 finished with value: 9776639.178657873 and parameters: {'alpha': 0.018780643797792124, 'l1_ratio': 0.46812276162908856}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:57,218] Trial 209 finished with value: 10533961.359719222 and parameters: {'alpha': 0.11692653024230243, 'l1_ratio': 0.1971111352529229}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:57,355] Trial 210 finished with value: 9788894.667632684 and parameters: {'alpha': 0.014883411145658986, 'l1_ratio': 0.36750442053941856}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:57,516] Trial 211 finished with value: 9750294.259363307 and parameters: {'alpha': 0.021939012129057904, 'l1_ratio': 0.27064806518956874}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:57,599] Trial 212 finished with value: 9749675.218114644 and parameters: {'alpha': 0.021635175337838746, 'l1_ratio': 0.2667167118146295}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:57,674] Trial 213 finished with value: 9778080.877155876 and parameters: {'alpha': 0.02805305225380388, 'l1_ratio': 0.2962127643572843}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:57,752] Trial 214 finished with value: 9746224.513353676 and parameters: {'alpha': 0.017383996326099643, 'l1_ratio': 0.2419266396026028}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:57,837] Trial 215 finished with value: 9762614.521089982 and parameters: {'alpha': 0.014366470516908834, 'l1_ratio': 0.24093989331817878}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:57,940] Trial 216 finished with value: 9985997.467530616 and parameters: {'alpha': 0.007100763924116787, 'l1_ratio': 0.2270278684181778}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:58,026] Trial 217 finished with value: 9826622.284919472 and parameters: {'alpha': 0.010439674223101459, 'l1_ratio': 0.21934545360210103}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:58,109] Trial 218 finished with value: 9763616.034801438 and parameters: {'alpha': 0.016540218934534317, 'l1_ratio': 0.3460695146205295}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:58,181] Trial 219 finished with value: 9779503.111719642 and parameters: {'alpha': 0.03370703093875069, 'l1_ratio': 0.4097378220032816}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:58,238] Trial 220 finished with value: 10168232.644307062 and parameters: {'alpha': 0.06970872478532868, 'l1_ratio': 0.25958156414512906}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:58,318] Trial 221 finished with value: 9747614.297804086 and parameters: {'alpha': 0.021404565570785343, 'l1_ratio': 0.28349269528333954}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:58,391] Trial 222 finished with value: 9748655.55507721 and parameters: {'alpha': 0.017885797565025074, 'l1_ratio': 0.3002754005312702}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:58,458] Trial 223 finished with value: 9773120.32904584 and parameters: {'alpha': 0.02576129753795129, 'l1_ratio': 0.2543009016139302}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:58,554] Trial 224 finished with value: 9795370.875261195 and parameters: {'alpha': 0.012571779125512269, 'l1_ratio': 0.27169397487887204}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:58,625] Trial 225 finished with value: 9840864.925944433 and parameters: {'alpha': 0.037293378598361945, 'l1_ratio': 0.321482881613663}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:58,704] Trial 226 finished with value: 9754030.471819136 and parameters: {'alpha': 0.018899323873552573, 'l1_ratio': 0.38079917968343574}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:58,776] Trial 227 finished with value: 9790241.461833265 and parameters: {'alpha': 0.0274030818993889, 'l1_ratio': 0.23548510055342872}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:58,876] Trial 228 finished with value: 9893472.163319953 and parameters: {'alpha': 0.010447366315939276, 'l1_ratio': 0.35573715424285746}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:58,941] Trial 229 finished with value: 9951530.02147662 and parameters: {'alpha': 0.04691597110991286, 'l1_ratio': 0.27861963268378703}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:59,035] Trial 230 finished with value: 9757513.876783872 and parameters: {'alpha': 0.016438017123941967, 'l1_ratio': 0.3100565565682347}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:59,109] Trial 231 finished with value: 9765136.542561667 and parameters: {'alpha': 0.02243510770265415, 'l1_ratio': 0.1852690832778302}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:59,192] Trial 232 finished with value: 9761160.4748812 and parameters: {'alpha': 0.013956242647078893, 'l1_ratio': 0.21012794519418088}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:59,270] Trial 233 finished with value: 9766208.581159953 and parameters: {'alpha': 0.019881892265507236, 'l1_ratio': 0.07421110804315004}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:59,356] Trial 234 finished with value: 9980061.073079392 and parameters: {'alpha': 0.03117171189636981, 'l1_ratio': 0.8224656693001801}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:59,481] Trial 235 finished with value: 9878192.498018393 and parameters: {'alpha': 0.009339699270642468, 'l1_ratio': 0.25031671504010805}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:59,558] Trial 236 finished with value: 9767173.093564719 and parameters: {'alpha': 0.015004515620211477, 'l1_ratio': 0.29568428538680386}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:59,647] Trial 237 finished with value: 9763119.243373029 and parameters: {'alpha': 0.02527402028608759, 'l1_ratio': 0.5719218086422322}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:59,735] Trial 238 finished with value: 9745284.874464378 and parameters: {'alpha': 0.018323583006363473, 'l1_ratio': 0.23313607933849467}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:59,821] Trial 239 finished with value: 9787092.334017823 and parameters: {'alpha': 0.012368288572881678, 'l1_ratio': 0.23187761646086585}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:02:59,953] Trial 240 finished with value: 9747595.832542563 and parameters: {'alpha': 0.020798576230843597, 'l1_ratio': 0.2630084846027762}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:00,052] Trial 241 finished with value: 9746681.298796892 and parameters: {'alpha': 0.016396880897155307, 'l1_ratio': 0.20566050960207963}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:00,149] Trial 242 finished with value: 9750011.572225139 and parameters: {'alpha': 0.015323465090036925, 'l1_ratio': 0.1985406706382753}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:00,221] Trial 243 finished with value: 9805922.175635424 and parameters: {'alpha': 0.02871023686356546, 'l1_ratio': 0.22040610350308865}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:00,307] Trial 244 finished with value: 9745438.560314246 and parameters: {'alpha': 0.018980740994422186, 'l1_ratio': 0.2448371405804825}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:00,417] Trial 245 finished with value: 9915752.41583467 and parameters: {'alpha': 0.008525388348054169, 'l1_ratio': 0.25156568559084885}. Best is trial 119 with value: 9743965.326113414.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.560e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:03:00,508] Trial 246 finished with value: 11858161.50616839 and parameters: {'alpha': 0.011994637162632686, 'l1_ratio': 0.9374989854490595}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:00,590] Trial 247 finished with value: 9748248.593827816 and parameters: {'alpha': 0.016547035099427263, 'l1_ratio': 0.23791767544681416}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:00,668] Trial 248 finished with value: 9901764.405164916 and parameters: {'alpha': 0.03831774954478521, 'l1_ratio': 0.21581483980722144}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:00,752] Trial 249 finished with value: 9750270.38964291 and parameters: {'alpha': 0.025611354121233186, 'l1_ratio': 0.3750132623877482}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:00,850] Trial 250 finished with value: 9928052.500776814 and parameters: {'alpha': 0.01826361076469095, 'l1_ratio': 0.6609307536024529}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:00,952] Trial 251 finished with value: 9873542.211435108 and parameters: {'alpha': 0.011820484072516261, 'l1_ratio': 0.40059202308917086}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:01,058] Trial 252 finished with value: 10065012.180420846 and parameters: {'alpha': 0.007149097527725455, 'l1_ratio': 0.3368333157099248}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:01,109] Trial 253 finished with value: 11226257.172135528 and parameters: {'alpha': 0.4145303819533651, 'l1_ratio': 0.1700787707872013}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:01,193] Trial 254 finished with value: 9814878.762379076 and parameters: {'alpha': 0.030605806410723704, 'l1_ratio': 0.24332692349911653}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:01,282] Trial 255 finished with value: 9751509.148071472 and parameters: {'alpha': 0.02020432798980032, 'l1_ratio': 0.19591776967405944}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:01,348] Trial 256 finished with value: 9937235.333214676 and parameters: {'alpha': 0.05105816701363598, 'l1_ratio': 0.35833282253119997}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:01,401] Trial 257 finished with value: 10700197.356093893 and parameters: {'alpha': 0.22173085066344575, 'l1_ratio': 0.4444610804974204}. Best is trial 119 with value: 9743965.326113414.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:03:01,499] Trial 258 finished with value: 12343173.20939293 and parameters: {'alpha': 0.014581210936472987, 'l1_ratio': 0.9660007580068988}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:01,577] Trial 259 finished with value: 9749582.608328685 and parameters: {'alpha': 0.02481666241779158, 'l1_ratio': 0.5044445916240904}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:01,696] Trial 260 finished with value: 10488186.074722573 and parameters: {'alpha': 0.010634723886423954, 'l1_ratio': 0.7538488223226645}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:01,766] Trial 261 finished with value: 9852493.072032457 and parameters: {'alpha': 0.03566342926599059, 'l1_ratio': 0.2645591938448755}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:01,871] Trial 262 finished with value: 9753392.39958011 and parameters: {'alpha': 0.01516574717959469, 'l1_ratio': 0.22217812573003912}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:01,957] Trial 263 finished with value: 9749719.891152246 and parameters: {'alpha': 0.02125339679801948, 'l1_ratio': 0.4214709755527521}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:02,043] Trial 264 finished with value: 9754878.738938442 and parameters: {'alpha': 0.042164721413350016, 'l1_ratio': 0.7270314003961384}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:02,130] Trial 265 finished with value: 9748490.765384326 and parameters: {'alpha': 0.01767338150536062, 'l1_ratio': 0.28986788447404704}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:02,217] Trial 266 finished with value: 9761340.535843553 and parameters: {'alpha': 0.026435277044907068, 'l1_ratio': 0.3267339687658212}. Best is trial 119 with value: 9743965.326113414.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.335e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:03:02,372] Trial 267 finished with value: 11117766.97286253 and parameters: {'alpha': 0.009277027089352748, 'l1_ratio': 0.8516476803476958}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:02,432] Trial 268 finished with value: 10216455.968944332 and parameters: {'alpha': 0.09216907005147255, 'l1_ratio': 0.3911578622026741}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:02,503] Trial 269 finished with value: 10083388.67297454 and parameters: {'alpha': 0.05881673007407252, 'l1_ratio': 0.24744842972076464}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:02,593] Trial 270 finished with value: 9763834.858836425 and parameters: {'alpha': 0.014945172513905472, 'l1_ratio': 0.276960772567853}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:02,659] Trial 271 finished with value: 9829141.454089593 and parameters: {'alpha': 0.03520263036923157, 'l1_ratio': 0.3082198998254816}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:02,737] Trial 272 finished with value: 9745553.094889857 and parameters: {'alpha': 0.022065192839223376, 'l1_ratio': 0.34393535329821145}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:02,771] Trial 273 finished with value: 12154096.62470418 and parameters: {'alpha': 142.23577436016646, 'l1_ratio': 0.35361993477790765}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:02,853] Trial 274 finished with value: 9749419.599629173 and parameters: {'alpha': 0.025166869503043237, 'l1_ratio': 0.3714911600597144}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:02,981] Trial 275 finished with value: 10128691.939432604 and parameters: {'alpha': 0.006456198760407928, 'l1_ratio': 0.33943800149829956}. Best is trial 119 with value: 9743965.326113414.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.294e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:03:03,097] Trial 276 finished with value: 11126252.930185957 and parameters: {'alpha': 0.011640247292160283, 'l1_ratio': 0.88268667391551}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:03,171] Trial 277 finished with value: 9823145.47632558 and parameters: {'alpha': 0.03008624335286956, 'l1_ratio': 0.207135097794768}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:03,254] Trial 278 finished with value: 9763472.922468625 and parameters: {'alpha': 0.017659207871400892, 'l1_ratio': 0.38714341995981594}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:03,324] Trial 279 finished with value: 9757344.536297547 and parameters: {'alpha': 0.022308373847698543, 'l1_ratio': 0.22765252869463654}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:03,400] Trial 280 finished with value: 10060936.37165894 and parameters: {'alpha': 0.044322930528180614, 'l1_ratio': 0.043166510859688145}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:03,500] Trial 281 finished with value: 9843302.24563429 and parameters: {'alpha': 0.011893564432825948, 'l1_ratio': 0.350529046585388}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:03,551] Trial 282 finished with value: 11340537.955213832 and parameters: {'alpha': 0.7817436613462975, 'l1_ratio': 0.4058363322535755}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:03,638] Trial 283 finished with value: 9748974.555016316 and parameters: {'alpha': 0.021054333362709766, 'l1_ratio': 0.2543659094255971}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:03,734] Trial 284 finished with value: 9792653.436089603 and parameters: {'alpha': 0.014695215394688934, 'l1_ratio': 0.37000392718549935}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:03,814] Trial 285 finished with value: 9789155.683107931 and parameters: {'alpha': 0.030701094797725027, 'l1_ratio': 0.3209036622138929}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:03,854] Trial 286 finished with value: 12043442.03897421 and parameters: {'alpha': 72.07631808517782, 'l1_ratio': 0.10521974664724504}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:03,964] Trial 287 finished with value: 9890237.579203317 and parameters: {'alpha': 0.00832369073507196, 'l1_ratio': 0.18440046056644535}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:04,036] Trial 288 finished with value: 9750090.166984294 and parameters: {'alpha': 0.020721602172192825, 'l1_ratio': 0.23008915137840552}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:04,105] Trial 289 finished with value: 11027833.301784754 and parameters: {'alpha': 0.3075603712542417, 'l1_ratio': 0.27642045241463176}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:04,168] Trial 290 finished with value: 10176831.606636422 and parameters: {'alpha': 0.0695241111388179, 'l1_ratio': 0.24647244551255376}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:04,272] Trial 291 finished with value: 9824285.557086071 and parameters: {'alpha': 0.012306409120188667, 'l1_ratio': 0.3328350546476701}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:04,392] Trial 292 finished with value: 9860607.327618182 and parameters: {'alpha': 0.03806759773421901, 'l1_ratio': 0.29424687754633805}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:04,502] Trial 293 finished with value: 9831612.598356385 and parameters: {'alpha': 0.016758232352242834, 'l1_ratio': 0.5223766972102593}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:04,557] Trial 294 finished with value: 10472413.894096881 and parameters: {'alpha': 0.13385805607622, 'l1_ratio': 0.36415612181704093}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:04,641] Trial 295 finished with value: 9809573.257261146 and parameters: {'alpha': 0.026105770200199878, 'l1_ratio': 0.13048867809755396}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:04,756] Trial 296 finished with value: 10080241.42236498 and parameters: {'alpha': 0.00900706257666052, 'l1_ratio': 0.4872629163629074}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:04,837] Trial 297 finished with value: 9745710.413804557 and parameters: {'alpha': 0.018421500740383335, 'l1_ratio': 0.21042408253443565}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:04,938] Trial 298 finished with value: 9765206.920858296 and parameters: {'alpha': 0.01356077719016056, 'l1_ratio': 0.21019160233785725}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:05,022] Trial 299 finished with value: 9836055.839480383 and parameters: {'alpha': 0.029704163013640945, 'l1_ratio': 0.1612910462605876}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:05,102] Trial 300 finished with value: 9746827.776441313 and parameters: {'alpha': 0.018733646788403648, 'l1_ratio': 0.19572160133740185}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:05,176] Trial 301 finished with value: 9772297.325940227 and parameters: {'alpha': 0.02369515085087161, 'l1_ratio': 0.19321370153900458}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:05,221] Trial 302 finished with value: 11673124.968208192 and parameters: {'alpha': 2.834916366480157, 'l1_ratio': 0.2094181879712892}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:05,300] Trial 303 finished with value: 10052004.81875432 and parameters: {'alpha': 0.05025687838387962, 'l1_ratio': 0.17036635779130946}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:05,391] Trial 304 finished with value: 9755853.709005125 and parameters: {'alpha': 0.017397882653040014, 'l1_ratio': 0.023312398851290328}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:05,516] Trial 305 finished with value: 10137470.228404371 and parameters: {'alpha': 0.00517645007070588, 'l1_ratio': 0.18743378566693028}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:05,615] Trial 306 finished with value: 9827412.159588754 and parameters: {'alpha': 0.010511661064964997, 'l1_ratio': 0.2267492920373202}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:05,689] Trial 307 finished with value: 9845351.666470598 and parameters: {'alpha': 0.03348100476599326, 'l1_ratio': 0.23355696644142593}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:05,769] Trial 308 finished with value: 9777341.686444717 and parameters: {'alpha': 0.022107600739824384, 'l1_ratio': 0.550296223096844}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:05,871] Trial 309 finished with value: 9835321.33075052 and parameters: {'alpha': 0.01389193603719261, 'l1_ratio': 0.4302155917779717}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:05,948] Trial 310 finished with value: 9989952.84860718 and parameters: {'alpha': 0.045733364028460746, 'l1_ratio': 0.19547083540632484}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:06,043] Trial 311 finished with value: 9974088.70990873 and parameters: {'alpha': 0.00718869212384698, 'l1_ratio': 0.21800152418297897}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:06,132] Trial 312 finished with value: 9964608.946761895 and parameters: {'alpha': 0.028002088971561243, 'l1_ratio': 0.7959433120099795}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:06,210] Trial 313 finished with value: 9746173.817832526 and parameters: {'alpha': 0.017914148953092773, 'l1_ratio': 0.2635964097071753}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:06,338] Trial 314 finished with value: 9819655.931529447 and parameters: {'alpha': 0.011411601230540103, 'l1_ratio': 0.2688248030030478}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:06,383] Trial 315 finished with value: 13652586.250595693 and parameters: {'alpha': 950.3922834080096, 'l1_ratio': 0.2524121922466412}. Best is trial 119 with value: 9743965.326113414.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.951e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:03:06,481] Trial 316 finished with value: 12858115.726375103 and parameters: {'alpha': 0.03702679765006825, 'l1_ratio': 0.9927096016109402}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:06,540] Trial 317 finished with value: 10312437.947107859 and parameters: {'alpha': 0.09154510494835696, 'l1_ratio': 0.28145812127740955}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:06,634] Trial 318 finished with value: 9754675.86661479 and parameters: {'alpha': 0.016801438757678585, 'l1_ratio': 0.30738708458805164}. Best is trial 119 with value: 9743965.326113414.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.608e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:03:06,742] Trial 319 finished with value: 10804167.617598403 and parameters: {'alpha': 0.02399379878166525, 'l1_ratio': 0.9227749394383843}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:06,833] Trial 320 finished with value: 9774166.691518182 and parameters: {'alpha': 0.013420755458286776, 'l1_ratio': 0.24434984281606395}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:06,892] Trial 321 finished with value: 10095669.200517228 and parameters: {'alpha': 0.061690640561049025, 'l1_ratio': 0.2653955859117268}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:07,015] Trial 322 finished with value: 10214391.750519572 and parameters: {'alpha': 0.00949250675235939, 'l1_ratio': 0.6059284928176214}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:07,095] Trial 323 finished with value: 9751981.602885192 and parameters: {'alpha': 0.030265718336876947, 'l1_ratio': 0.45896870773382004}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:07,185] Trial 324 finished with value: 9749310.440063452 and parameters: {'alpha': 0.020291614746374836, 'l1_ratio': 0.39019585981030996}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:07,215] Trial 325 finished with value: 12578732.754920462 and parameters: {'alpha': 340.2650676204325, 'l1_ratio': 0.31875262849615993}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:07,318] Trial 326 finished with value: 9768429.28578501 and parameters: {'alpha': 0.01470391464494991, 'l1_ratio': 0.28689089302751963}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:07,398] Trial 327 finished with value: 9745548.3610393 and parameters: {'alpha': 0.02456678053308189, 'l1_ratio': 0.4096877998103893}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:07,466] Trial 328 finished with value: 9814859.532963214 and parameters: {'alpha': 0.039759976436465554, 'l1_ratio': 0.4174245048917562}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:07,557] Trial 329 finished with value: 9746679.010174382 and parameters: {'alpha': 0.02164659786837777, 'l1_ratio': 0.4007731217903115}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:07,639] Trial 330 finished with value: 9766808.130741134 and parameters: {'alpha': 0.029909518541566715, 'l1_ratio': 0.3817375982778868}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:07,699] Trial 331 finished with value: 10695751.713334417 and parameters: {'alpha': 0.21599754346903877, 'l1_ratio': 0.43394240940304973}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:07,775] Trial 332 finished with value: 9781317.038652912 and parameters: {'alpha': 0.05350623370254201, 'l1_ratio': 0.8195682763936734}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:07,857] Trial 333 finished with value: 9752751.165824363 and parameters: {'alpha': 0.02581265775975895, 'l1_ratio': 0.3607945822610231}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:07,938] Trial 334 finished with value: 9838704.005586032 and parameters: {'alpha': 0.03817763330482176, 'l1_ratio': 0.3417374094475745}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:08,102] Trial 335 finished with value: 9914980.306879183 and parameters: {'alpha': 0.010897096965201164, 'l1_ratio': 0.413632850456754}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:08,190] Trial 336 finished with value: 9762972.230066104 and parameters: {'alpha': 0.017715956109524967, 'l1_ratio': 0.38692133558146075}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:08,289] Trial 337 finished with value: 9762720.603459159 and parameters: {'alpha': 0.0244328554980172, 'l1_ratio': 0.2642663960914774}. Best is trial 119 with value: 9743965.326113414.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.650e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:03:08,400] Trial 338 finished with value: 13083168.79819034 and parameters: {'alpha': 0.007522083346815501, 'l1_ratio': 0.971160547954357}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:08,517] Trial 339 finished with value: 9763844.918199312 and parameters: {'alpha': 0.015715901408354757, 'l1_ratio': 0.31266010707497716}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:08,608] Trial 340 finished with value: 9817919.21995197 and parameters: {'alpha': 0.030740321232574697, 'l1_ratio': 0.23824552355223855}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:08,708] Trial 341 finished with value: 9819652.83742872 and parameters: {'alpha': 0.0117874143115077, 'l1_ratio': 0.2922004559266889}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:08,804] Trial 342 finished with value: 9745208.407587875 and parameters: {'alpha': 0.02246770300210913, 'l1_ratio': 0.37642187087019024}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:08,872] Trial 343 finished with value: 10500426.406301126 and parameters: {'alpha': 0.14752793622290775, 'l1_ratio': 0.39654828612426973}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:08,924] Trial 344 finished with value: 11767360.80968236 and parameters: {'alpha': 13.167034690055615, 'l1_ratio': 0.37456680013847776}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:09,010] Trial 345 finished with value: 9816639.069687797 and parameters: {'alpha': 0.042012688519905604, 'l1_ratio': 0.4450303277359151}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:09,086] Trial 346 finished with value: 9879248.265624447 and parameters: {'alpha': 0.06589453907512849, 'l1_ratio': 0.5696551906983092}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:09,171] Trial 347 finished with value: 9745586.164907224 and parameters: {'alpha': 0.023286686394922314, 'l1_ratio': 0.4249557807327932}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:09,256] Trial 348 finished with value: 9749200.292610105 and parameters: {'alpha': 0.023676384652425025, 'l1_ratio': 0.477423095121526}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:09,337] Trial 349 finished with value: 9778443.618349964 and parameters: {'alpha': 0.03349876350789943, 'l1_ratio': 0.4093417720737682}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:09,424] Trial 350 finished with value: 9754316.968854263 and parameters: {'alpha': 0.02096993951495989, 'l1_ratio': 0.44395863576497097}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:09,491] Trial 351 finished with value: 9874532.667176845 and parameters: {'alpha': 0.047134066936036396, 'l1_ratio': 0.40694650887950634}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:09,577] Trial 352 finished with value: 9754103.851532256 and parameters: {'alpha': 0.02720724613169988, 'l1_ratio': 0.3848062174808365}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:09,668] Trial 353 finished with value: 9813917.545964057 and parameters: {'alpha': 0.014882352488630778, 'l1_ratio': 0.4283221942645107}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:09,752] Trial 354 finished with value: 9768078.804220965 and parameters: {'alpha': 0.020317232193554288, 'l1_ratio': 0.08301259389949103}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:09,808] Trial 355 finished with value: 10232676.598786578 and parameters: {'alpha': 0.10835032446865826, 'l1_ratio': 0.46739099740753315}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:09,967] Trial 356 finished with value: 9802540.11847101 and parameters: {'alpha': 0.03504320791269463, 'l1_ratio': 0.36969114878884896}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:10,072] Trial 357 finished with value: 9996321.376185523 and parameters: {'alpha': 0.009381570508557065, 'l1_ratio': 0.42690055132565546}. Best is trial 119 with value: 9743965.326113414.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.325e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:03:10,160] Trial 358 finished with value: 11987430.228710528 and parameters: {'alpha': 0.012457551783644617, 'l1_ratio': 0.9456776047837584}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:10,234] Trial 359 finished with value: 9766014.813099837 and parameters: {'alpha': 0.07683711717197102, 'l1_ratio': 0.8643265546823519}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:10,307] Trial 360 finished with value: 9754105.87209507 and parameters: {'alpha': 0.02569354234516474, 'l1_ratio': 0.34873039031524405}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:10,402] Trial 361 finished with value: 10024898.207947627 and parameters: {'alpha': 0.017533318472467613, 'l1_ratio': 0.7098858268203736}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:10,460] Trial 362 finished with value: 9933013.412085215 and parameters: {'alpha': 0.05372265500055849, 'l1_ratio': 0.39605379028639676}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:10,517] Trial 363 finished with value: 10483860.56852528 and parameters: {'alpha': 0.5314596954016594, 'l1_ratio': 0.8357234863410209}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:10,610] Trial 364 finished with value: 9745187.962049441 and parameters: {'alpha': 0.02198088738925312, 'l1_ratio': 0.3707477569239636}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:10,691] Trial 365 finished with value: 9804299.699480461 and parameters: {'alpha': 0.035699033898045504, 'l1_ratio': 0.3768812156243013}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:10,790] Trial 366 finished with value: 9752379.977732709 and parameters: {'alpha': 0.02545103866811091, 'l1_ratio': 0.3543969633458538}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:10,894] Trial 367 finished with value: 9816525.293896498 and parameters: {'alpha': 0.014227319751354493, 'l1_ratio': 0.40748467457859716}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:10,950] Trial 368 finished with value: 11617116.780903228 and parameters: {'alpha': 2.13831507274131, 'l1_ratio': 0.33295778266789827}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:11,036] Trial 369 finished with value: 9745190.333471728 and parameters: {'alpha': 0.021948894472945353, 'l1_ratio': 0.3689670163637178}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:11,108] Trial 370 finished with value: 9845166.952410882 and parameters: {'alpha': 0.04437636794037531, 'l1_ratio': 0.4219637484366197}. Best is trial 119 with value: 9743965.326113414.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.140e+06, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:03:11,249] Trial 371 finished with value: 10537707.60169576 and parameters: {'alpha': 0.003980665802359766, 'l1_ratio': 0.37888718291652224}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:11,328] Trial 372 finished with value: 11444839.436153684 and parameters: {'alpha': 1.0734109497857631, 'l1_ratio': 0.40029434148045334}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:11,422] Trial 373 finished with value: 9904128.122556284 and parameters: {'alpha': 0.030417581201371897, 'l1_ratio': 0.006660994037791593}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:11,519] Trial 374 finished with value: 9745201.84562439 and parameters: {'alpha': 0.022296499684464396, 'l1_ratio': 0.37507116125634066}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:11,591] Trial 375 finished with value: 10994548.125301203 and parameters: {'alpha': 0.3334457375820124, 'l1_ratio': 0.3748619306328221}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:11,737] Trial 376 finished with value: 9752060.992314465 and parameters: {'alpha': 0.025809169894431876, 'l1_ratio': 0.3655850696457654}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:11,822] Trial 377 finished with value: 9770337.892950267 and parameters: {'alpha': 0.04446314211064267, 'l1_ratio': 0.7691418421956396}. Best is trial 119 with value: 9743965.326113414.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.046e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:03:11,939] Trial 378 finished with value: 11214493.538127232 and parameters: {'alpha': 0.01215556136070028, 'l1_ratio': 0.8961084871243462}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:12,043] Trial 379 finished with value: 9748369.545084601 and parameters: {'alpha': 0.020798485380730054, 'l1_ratio': 0.39641356811968986}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:12,132] Trial 380 finished with value: 9766682.053074114 and parameters: {'alpha': 0.032031208913433876, 'l1_ratio': 0.4230759703788773}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:12,255] Trial 381 finished with value: 10106591.71012373 and parameters: {'alpha': 0.008181367523951268, 'l1_ratio': 0.4597854698444783}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:12,359] Trial 382 finished with value: 9992792.092024567 and parameters: {'alpha': 0.058010254845094686, 'l1_ratio': 0.36165654721417323}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:12,458] Trial 383 finished with value: 9788767.647650125 and parameters: {'alpha': 0.015397315762787528, 'l1_ratio': 0.38836009985593084}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:12,565] Trial 384 finished with value: 9745696.964474242 and parameters: {'alpha': 0.022735937717572728, 'l1_ratio': 0.4132457191048362}. Best is trial 119 with value: 9743965.326113414.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.508e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2024-01-08 17:03:12,650] Trial 385 finished with value: 12431957.523651786 and parameters: {'alpha': 0.00076431678436851, 'l1_ratio': 0.4129929991084115}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:12,742] Trial 386 finished with value: 9761664.088016566 and parameters: {'alpha': 0.03587312389996105, 'l1_ratio': 0.5022573737650973}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:12,827] Trial 387 finished with value: 9745138.21426583 and parameters: {'alpha': 0.024209143723153012, 'l1_ratio': 0.4308543330375686}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:12,920] Trial 388 finished with value: 10122622.699482076 and parameters: {'alpha': 0.08451920200770027, 'l1_ratio': 0.436123155054709}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:13,014] Trial 389 finished with value: 9749163.460443523 and parameters: {'alpha': 0.02844097784776313, 'l1_ratio': 0.44556616821831607}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:13,110] Trial 390 finished with value: 9853729.17220899 and parameters: {'alpha': 0.011442440422729093, 'l1_ratio': 0.345522934452327}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:13,190] Trial 391 finished with value: 9813148.371089626 and parameters: {'alpha': 0.04446033588449587, 'l1_ratio': 0.48222624889868443}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:13,258] Trial 392 finished with value: 10653590.941349538 and parameters: {'alpha': 0.18488551053416868, 'l1_ratio': 0.38328462556210596}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:13,412] Trial 393 finished with value: 9750104.35899831 and parameters: {'alpha': 0.020634176066766274, 'l1_ratio': 0.40706495562139183}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:13,501] Trial 394 finished with value: 9754075.036299657 and parameters: {'alpha': 0.029925505143316974, 'l1_ratio': 0.4405696175720841}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:13,625] Trial 395 finished with value: 10273631.70774151 and parameters: {'alpha': 0.006371324664444649, 'l1_ratio': 0.4598365414365507}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:13,719] Trial 396 finished with value: 9785596.285396015 and parameters: {'alpha': 0.01496204601635666, 'l1_ratio': 0.36100192312008716}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:13,808] Trial 397 finished with value: 9745232.068564193 and parameters: {'alpha': 0.022384769192650453, 'l1_ratio': 0.3887974988522078}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:13,890] Trial 398 finished with value: 9816340.315560073 and parameters: {'alpha': 0.03827839619880234, 'l1_ratio': 0.3916156367356029}. Best is trial 119 with value: 9743965.326113414.\n",
      "[I 2024-01-08 17:03:13,985] Trial 399 finished with value: 10016950.394517254 and parameters: {'alpha': 0.06242010607740967, 'l1_ratio': 0.37643424920694596}. Best is trial 119 with value: 9743965.326113414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Meilleur Alpha pour ElasticNet (Optuna) : 0.07608429602697854\n",
      "Meilleur L1 Ratio pour ElasticNet (Optuna) : 0.8193821330601591\n",
      "Erreur quadratique moyenne avec ElasticNet (utilisant les meilleurs hyperparamètres d'Optuna) : 9743965.326113414\n",
      "r2 avec ElasticNet (utilisant les meilleurs hyperparamètres d'Optuna) : 0.8420251048306355\n",
      "\n",
      "                    0             1            2            3            4            5                     6                                 7                           8                            9                    10                  11                 12                 13                           14                15                16              17              18              19              20              21                     22                                23                             24                                25                               26                                       27                     28                     29                        30                             31                           32                           33                       34                          35                            36                                 37                  38                         39                         40                     41                    42                         43                       44                   45                          46                        47                           48                        49                     50                    51                           52                  53                 54                 55                 56                        57                 58                 59                 60                   61                        62                          63                        64                  65                     66                       67                      68                     69                         70                         71                            72                          73                            74                         75                      76                   77                   78                   79                   80                    81                    82                   83                   84                    85                   86                    87                    88                    89                   90                   91                        92                                 93                     94                        95                       96                                97                         98                                      99                        100                        101                     102                      103                    104                   105                    106               107                 108                109             110                  111                 112                113                114                115                    116                     117                    118                       119                                120                     121                          122                               123                              124                            125                    126                            127                             128                            129                      130                     131                     132                    133                     134                       135                                   136                          137                        138                           139                        140                               141                              142                        143                  144                      145                  146                147                148                  149                   150                151                152              153           154             155               156              157             158                  159              160                161            162            163             164             165             166                   167                  168              169               170           171             172              173              174               175                   176                  177                  178                 179                   180                    181                 182              183              184              185             186             187              188              189              190         191         192         193        194         195         196        197          198               199         200      201         202         203\n",
      "Variable  symboling_-2  symboling_-1  symboling_0  symboling_1  symboling_2  symboling_3  CarName_Nissan versa  CarName_alfa-romero Quadrifoglio  CarName_alfa-romero giulia  CarName_alfa-romero stelvio  CarName_audi 100 ls  CarName_audi 100ls  CarName_audi 4000  CarName_audi 5000  CarName_audi 5000s (diesel)  CarName_audi fox  CarName_bmw 320i  CarName_bmw x1  CarName_bmw x3  CarName_bmw x4  CarName_bmw x5  CarName_bmw z4  CarName_buick century  CarName_buick century luxus (sw)  CarName_buick century special  CarName_buick electra 225 custom  CarName_buick opel isuzu deluxe  CarName_buick regal sport coupe (turbo)  CarName_buick skyhawk  CarName_buick skylark  CarName_chevrolet impala  CarName_chevrolet monte carlo  CarName_chevrolet vega 2300  CarName_dodge challenger se  CarName_dodge colt (sw)  CarName_dodge colt hardtop  CarName_dodge coronet custom  CarName_dodge coronet custom (sw)  CarName_dodge d200  CarName_dodge dart custom  CarName_dodge monaco (sw)  CarName_dodge rampage  CarName_honda accord  CarName_honda accord cvcc  CarName_honda accord lx  CarName_honda civic  CarName_honda civic (auto)  CarName_honda civic 1300  CarName_honda civic 1500 gl  CarName_honda civic cvcc  CarName_honda prelude  CarName_isuzu D-Max   CarName_isuzu D-Max V-Cross  CarName_isuzu MU-X  CarName_jaguar xf  CarName_jaguar xj  CarName_jaguar xk  CarName_maxda glc deluxe  CarName_maxda rx3  CarName_mazda 626  CarName_mazda glc  CarName_mazda glc 4  CarName_mazda glc custom  CarName_mazda glc custom l  CarName_mazda glc deluxe  CarName_mazda rx-4  CarName_mazda rx-7 gs  CarName_mazda rx2 coupe  CarName_mercury cougar  CarName_mitsubishi g4  CarName_mitsubishi lancer  CarName_mitsubishi mirage  CarName_mitsubishi mirage g4  CarName_mitsubishi montero  CarName_mitsubishi outlander  CarName_mitsubishi pajero  CarName_nissan clipper  CarName_nissan dayz  CarName_nissan fuga  CarName_nissan gt-r  CarName_nissan juke  CarName_nissan kicks  CarName_nissan latio  CarName_nissan leaf  CarName_nissan note  CarName_nissan nv200  CarName_nissan otti  CarName_nissan rogue  CarName_nissan teana  CarName_nissan titan  CarName_peugeot 304  CarName_peugeot 504  CarName_peugeot 504 (sw)  CarName_peugeot 505s turbo diesel  CarName_peugeot 604sl  CarName_plymouth cricket  CarName_plymouth duster  CarName_plymouth fury gran sedan  CarName_plymouth fury iii  CarName_plymouth satellite custom (sw)  CarName_plymouth valiant  CarName_porcshce panamera  CarName_porsche boxter  CarName_porsche cayenne  CarName_porsche macan  CarName_renault 12tl  CarName_renault 5 gtl  CarName_saab 99e  CarName_saab 99gle  CarName_saab 99le  CarName_subaru  CarName_subaru baja  CarName_subaru brz  CarName_subaru dl  CarName_subaru r1  CarName_subaru r2  CarName_subaru trezia  CarName_subaru tribeca  CarName_toyota carina  CarName_toyota celica gt  CarName_toyota celica gt liftback  CarName_toyota corolla  CarName_toyota corolla 1200  CarName_toyota corolla 1600 (sw)  CarName_toyota corolla liftback  CarName_toyota corolla tercel  CarName_toyota corona  CarName_toyota corona hardtop  CarName_toyota corona liftback  CarName_toyota corona mark ii  CarName_toyota cressida  CarName_toyota mark ii  CarName_toyota starlet  CarName_toyota tercel  CarName_toyouta tercel  CarName_vokswagen rabbit  CarName_volkswagen 1131 deluxe sedan  CarName_volkswagen 411 (sw)  CarName_volkswagen dasher  CarName_volkswagen model 111  CarName_volkswagen rabbit  CarName_volkswagen rabbit custom  CarName_volkswagen super beetle  CarName_volkswagen type 3  CarName_volvo 144ea  CarName_volvo 145e (sw)  CarName_volvo 244dl  CarName_volvo 245  CarName_volvo 246  CarName_volvo 264gl  CarName_volvo diesel  CarName_vw dasher  CarName_vw rabbit  fueltype_diesel  fueltype_gas  aspiration_std  aspiration_turbo  doornumber_four  doornumber_two  carbody_convertible  carbody_hardtop  carbody_hatchback  carbody_sedan  carbody_wagon  drivewheel_4wd  drivewheel_fwd  drivewheel_rwd  enginelocation_front  enginelocation_rear  enginetype_dohc  enginetype_dohcv  enginetype_l  enginetype_ohc  enginetype_ohcf  enginetype_ohcv  enginetype_rotor  cylindernumber_eight  cylindernumber_five  cylindernumber_four  cylindernumber_six  cylindernumber_three  cylindernumber_twelve  cylindernumber_two  fuelsystem_1bbl  fuelsystem_2bbl  fuelsystem_4bbl  fuelsystem_idi  fuelsystem_mfi  fuelsystem_mpfi  fuelsystem_spdi  fuelsystem_spfi   wheelbase   carlength    carwidth  carheight  curbweight  enginesize  boreratio       stroke  compressionratio  horsepower  peakrpm     citympg  highwaympg\n",
      "Poids             -0.0   -179.036893          0.0   128.979906         -0.0          0.0                   0.0                               0.0                        -0.0                          0.0                  0.0                -0.0                0.0                0.0                         -0.0               0.0         694.36843             0.0      802.534996             0.0             0.0             0.0                    0.0                               0.0                            0.0                              -0.0                              0.0                                      0.0                    0.0                    0.0                       0.0                            0.0                          0.0                          0.0                      0.0                        -0.0                          -0.0                               -0.0                -0.0                       -0.0                        0.0                    0.0                   0.0                        0.0                     -0.0                  0.0                        -0.0                      -0.0                         -0.0                      -0.0                   -0.0                  -0.0                          0.0                -0.0                0.0                0.0               -0.0                       0.0               -0.0                0.0                0.0                  0.0                       0.0                         0.0                       0.0                 0.0                    0.0                      0.0                     0.0                   -0.0                       -0.0                        0.0                          -0.0                        -0.0                          -0.0                        0.0                     0.0                  0.0                 -0.0                  0.0                  0.0                  -0.0                   0.0                  0.0                  0.0                  -0.0                 -0.0                  -0.0                   0.0                   0.0                 -0.0                 -0.0                      -0.0                                0.0                    0.0                       0.0                     -0.0                               0.0                        0.0                                     0.0                      -0.0                        0.0                     0.0                      0.0                    0.0                   0.0                    0.0               0.0                 0.0               -0.0            -0.0                  0.0                -0.0               -0.0                0.0                0.0                   -0.0                     0.0                    0.0                      -0.0                               -0.0                    -0.0                          0.0                               0.0                             -0.0                           -0.0                    0.0                            0.0                            -0.0                           -0.0                     -0.0                     0.0             -636.334308                    0.0                     0.0                      -0.0                                   0.0                          0.0                        0.0                          -0.0                       -0.0                               0.0                              0.0                       -0.0                 -0.0              -122.863124                 -0.0                0.0               -0.0                  0.0                   0.0                0.0                0.0              0.0          -0.0            -0.0               0.0         7.245277            -0.0          3233.973384             -0.0               -0.0     716.693989     -89.226865            -0.0            -0.0      1114.74163          -6534.456127                  0.0             -0.0               0.0   -854.754849     1134.303548              0.0      -3454.16592               0.0           3418.183377                 -0.0         -3052.767746                 0.0                   0.0                   -0.0                 0.0             -0.0        93.361983              0.0             0.0            -0.0              0.0       -386.77849             -0.0  157.441213 -116.942595  572.192939  96.528896    2.933109   75.393875       -0.0 -2057.118284        175.797963   31.057408   1.2699 -227.411857  139.686469\n"
     ]
    }
   ],
   "source": [
    "# Réinitialise les listes pour ElasticNet\n",
    "alpha_values_en = []\n",
    "r2_scores_en = []\n",
    "l1_ratio_values_en = []\n",
    "\n",
    "def objective_en(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-4, 1000, log=True)\n",
    "    l1_ratio = trial.suggest_float('l1_ratio', 0, 1)\n",
    "\n",
    "    en = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "    en.fit(X_train, y_train)\n",
    "    y_pred = en.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Stocke alpha et le score MSE correspondant\n",
    "    alpha_values_en.append(alpha)\n",
    "    l1_ratio_values_en.append(l1_ratio)\n",
    "    r2_scores_en.append(r2)\n",
    "    return mse\n",
    "\n",
    "# Crée une étude Optuna pour ElasticNet\n",
    "study_en = optuna.create_study(direction='minimize')\n",
    "study_en.optimize(objective_en, n_trials=400)\n",
    "\n",
    "# Obtient le meilleur alpha et l1_ratio de Optuna\n",
    "best_alpha_en = study_en.best_params['alpha']\n",
    "best_l1_ratio_en = study_en.best_params['l1_ratio']\n",
    "\n",
    "# Entraîne le modèle ElasticNet en utilisant les meilleurs hyperparamètres\n",
    "best_en = ElasticNet(alpha=best_alpha_en, l1_ratio=best_l1_ratio_en)\n",
    "best_en.fit(X_train, y_train)\n",
    "y_pred_en = best_en.predict(X_test)\n",
    "\n",
    "# Calcule les métriques pour ElasticNet\n",
    "mse_en = mean_squared_error(y_test, y_pred_en)\n",
    "r2_en = r2_score(y_test, y_pred_en)\n",
    "\n",
    "print('\\n')\n",
    "print(f\"Meilleur Alpha pour ElasticNet (Optuna) : {best_alpha_en}\")\n",
    "print(f\"Meilleur L1 Ratio pour ElasticNet (Optuna) : {best_l1_ratio_en}\")\n",
    "print(f\"Erreur quadratique moyenne avec ElasticNet (utilisant les meilleurs hyperparamètres d'Optuna) : {mse_en}\")\n",
    "print(f\"r2 avec ElasticNet (utilisant les meilleurs hyperparamètres d'Optuna) : {r2_en}\")\n",
    "\n",
    "affichage_poids(best_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le L1_ratio optimal de ElasticNet est proche de 1 donc ElasticNet opère majoritairement comme Lasso et les meilleures performances sont d'ailleurs obtenues par Lasso.\n",
    "Donc il doit il y avoir un faible nombre de paramètres significatifs. Lasso a réduit à 0 les poids des autres ce qui a produit une meilleure performance que Ridge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.776e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.798e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.112e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.358e+06, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.264e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.719e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.817e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.893e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.727e+06, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.278e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.190e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.360e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.759e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.389e+06, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.154e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.986e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.189e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.308e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.357e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.455e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.037e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.092e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.973e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.933e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.346e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.394e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.489e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.373e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.319e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.395e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.679e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.389e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.003e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.277e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.307e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.450e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.294e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.620e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.895e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.109e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.890e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.887e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.219e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.907e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.873e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.686e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.590e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.616e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.746e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.411e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.620e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.675e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.307e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.326e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.391e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.273e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.474e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.313e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.943e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.899e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.382e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.094e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.371e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.879e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.832e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.883e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.668e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.123e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.820e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.521e+06, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.836e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.880e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.942e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.099e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.447e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.876e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.748e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.579e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.480e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.951e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.239e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.040e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.144e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.711e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.071e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.210e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.177e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.588e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.802e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.734e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.836e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.562e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.276e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.313e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.370e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.949e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.357e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.312e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.735e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.889e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.091e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.663e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.838e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.585e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.595e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.132e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.286e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.386e+06, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.748e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.653e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.072e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.835e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.009e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.377e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.158e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.271e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.673e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.751e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.656e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.549e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.674e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.186e+06, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.278e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.765e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.679e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.126e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.360e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.765e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.772e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.575e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.172e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.275e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.085e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.858e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.376e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.069e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.178e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.796e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.913e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.407e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.191e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.287e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.269e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.557e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.691e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.652e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.618e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.118e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.647e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.699e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.639e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.340e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.522e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.243e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.605e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.054e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.194e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.913e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.585e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.265e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.133e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.335e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.282e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.499e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.474e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.186e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.968e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.834e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.917e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.767e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.936e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.371e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.775e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.187e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.752e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.338e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.251e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.281e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.287e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.560e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.349e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.926e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.880e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.055e+06, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.041e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.379e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.962e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.806e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.698e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.416e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.380e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.599e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.314e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.380e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.676e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.931e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.777e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.906e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.035e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.554e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.594e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.803e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.031e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.732e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.277e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.068e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.368e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.567e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.435e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.030e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.386e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.071e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.149e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.183e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.572e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.419e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.153e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.925e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.104e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.989e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.127e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.719e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.986e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.293e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.624e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.919e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.767e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.311e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.639e+06, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.284e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.808e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.194e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.255e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.196e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.236e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.054e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.951e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.484e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.427e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.288e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.223e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.560e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.656e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.073e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.724e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.840e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.141e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.559e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.624e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.136e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.656e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.017e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.236e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.277e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.542e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.706e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.358e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.998e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.387e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.191e+07, tolerance: 8.812e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Créer des sous-graphiques pour les tracés côte à côte\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Fixer alpha à best_alpha, faire varier l1_ratio\n",
    "mse_scores_fixed_alpha = []\n",
    "for i in range(len(l1_ratio_values_en)):\n",
    "    alpha_fixed_model_en = ElasticNet(alpha=best_alpha_en, l1_ratio=l1_ratio_values_en[i])\n",
    "    alpha_fixed_model_en.fit(X_train, y_train)\n",
    "    y_pred_en = alpha_fixed_model_en.predict(X_test)\n",
    "    mse_dot = mean_squared_error(y_test, y_pred_en)\n",
    "    mse_scores_fixed_alpha.append(mse_dot)\n",
    "\n",
    "axs[0].scatter(l1_ratio_values_en, mse_scores_fixed_alpha, marker='o')\n",
    "axs[0].plot(best_l1_ratio_en, mse_en, marker='o', markersize=8, color='red')  # Point représentant le meilleur alpha\n",
    "axs[0].set_title('Evolution du MSE en faisant varier L1 Ratio (Alpha fixé)')\n",
    "axs[0].set_xlabel('L1 Ratio')\n",
    "axs[0].set_ylabel('MSE')\n",
    "\n",
    "# Fixer L1_ratio à best_l1_ratio, faire varier alpha\n",
    "mse_scores_fixed_l1_ratio = []\n",
    "for i in range(len(alpha_values_en)):\n",
    "    l1_ratio_fixed_model_en = ElasticNet(alpha=alpha_values_en[i], l1_ratio=best_l1_ratio_en)\n",
    "    l1_ratio_fixed_model_en.fit(X_train, y_train)\n",
    "    y_pred_en = l1_ratio_fixed_model_en.predict(X_test)\n",
    "    mse_dot = mean_squared_error(y_test, y_pred_en)\n",
    "    mse_scores_fixed_l1_ratio.append(mse_dot)\n",
    "\n",
    "axs[1].scatter(alpha_values_en, mse_scores_fixed_l1_ratio, marker='o')\n",
    "axs[1].set_title('Evolution du MSE en faisant varier Alpha (L1 Ratio fixé)')\n",
    "axs[1].plot(best_alpha_en, mse_en, marker='o', markersize=8, color='red')  # Point représentant le meilleur L1 ratio\n",
    "axs[1].set_xlabel('Alpha')\n",
    "axs[1].set_ylabel('MSE')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestRegressor\n",
    "RandomForestRegressor peut étudier des relations non-linéaires entre les variables explicatives et la variable à prédire. Il est également moins influencé par les points aberrants et peut prendre en compte les intéractions entre les variables. \n",
    "\n",
    "Avec une bonne optimisation de ses hyperparamètres, le modèle devrait donc avoir de meilleurs résultats que les méthodes de régularisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 18:24:22,555] A new study created in memory with name: no-name-01cf30ff-71ba-40e1-841e-c8624fa19ca7\n",
      "[I 2024-01-08 18:24:22,673] Trial 0 finished with value: 7273612.352649658 and parameters: {'n_estimators': 21, 'max_depth': 3, 'min_samples_split': 12, 'min_samples_leaf': 5}. Best is trial 0 with value: 7273612.352649658.\n",
      "[I 2024-01-08 18:24:23,150] Trial 1 finished with value: 6683528.154639624 and parameters: {'n_estimators': 83, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 1 with value: 6683528.154639624.\n",
      "[I 2024-01-08 18:24:23,330] Trial 2 finished with value: 6919046.752718257 and parameters: {'n_estimators': 36, 'max_depth': 24, 'min_samples_split': 13, 'min_samples_leaf': 3}. Best is trial 1 with value: 6683528.154639624.\n",
      "[I 2024-01-08 18:24:23,612] Trial 3 finished with value: 7184885.30843728 and parameters: {'n_estimators': 73, 'max_depth': 9, 'min_samples_split': 18, 'min_samples_leaf': 4}. Best is trial 1 with value: 6683528.154639624.\n",
      "[I 2024-01-08 18:24:23,742] Trial 4 finished with value: 6734078.5144882435 and parameters: {'n_estimators': 25, 'max_depth': 24, 'min_samples_split': 16, 'min_samples_leaf': 1}. Best is trial 1 with value: 6683528.154639624.\n",
      "[I 2024-01-08 18:24:23,942] Trial 5 finished with value: 7232794.250325885 and parameters: {'n_estimators': 53, 'max_depth': 11, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 1 with value: 6683528.154639624.\n",
      "[I 2024-01-08 18:24:24,217] Trial 6 finished with value: 9388463.545132983 and parameters: {'n_estimators': 81, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 1 with value: 6683528.154639624.\n",
      "[I 2024-01-08 18:24:24,416] Trial 7 finished with value: 8273823.038515679 and parameters: {'n_estimators': 54, 'max_depth': 8, 'min_samples_split': 15, 'min_samples_leaf': 8}. Best is trial 1 with value: 6683528.154639624.\n",
      "[I 2024-01-08 18:24:24,736] Trial 8 finished with value: 7743795.701364398 and parameters: {'n_estimators': 76, 'max_depth': 13, 'min_samples_split': 20, 'min_samples_leaf': 4}. Best is trial 1 with value: 6683528.154639624.\n",
      "[I 2024-01-08 18:24:24,944] Trial 9 finished with value: 7195541.790972032 and parameters: {'n_estimators': 46, 'max_depth': 11, 'min_samples_split': 15, 'min_samples_leaf': 5}. Best is trial 1 with value: 6683528.154639624.\n",
      "[I 2024-01-08 18:24:25,328] Trial 10 finished with value: 12967795.386277048 and parameters: {'n_estimators': 100, 'max_depth': 2, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 1 with value: 6683528.154639624.\n",
      "[I 2024-01-08 18:24:25,434] Trial 11 finished with value: 6267065.039510404 and parameters: {'n_estimators': 12, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 11 with value: 6267065.039510404.\n",
      "[I 2024-01-08 18:24:25,547] Trial 12 finished with value: 5778297.132849657 and parameters: {'n_estimators': 11, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 12 with value: 5778297.132849657.\n",
      "[I 2024-01-08 18:24:25,664] Trial 13 finished with value: 6084791.488629666 and parameters: {'n_estimators': 11, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 12 with value: 5778297.132849657.\n",
      "[I 2024-01-08 18:24:25,769] Trial 14 finished with value: 6762859.0669760285 and parameters: {'n_estimators': 11, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 12 with value: 5778297.132849657.\n",
      "[I 2024-01-08 18:24:25,964] Trial 15 finished with value: 6225545.412252449 and parameters: {'n_estimators': 32, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 12 with value: 5778297.132849657.\n",
      "[I 2024-01-08 18:24:26,118] Trial 16 finished with value: 8042608.676941256 and parameters: {'n_estimators': 38, 'max_depth': 2, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 12 with value: 5778297.132849657.\n",
      "[I 2024-01-08 18:24:26,279] Trial 17 finished with value: 6430408.008946046 and parameters: {'n_estimators': 23, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 12 with value: 5778297.132849657.\n",
      "[I 2024-01-08 18:24:26,367] Trial 18 finished with value: 6519646.86687332 and parameters: {'n_estimators': 10, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 12 with value: 5778297.132849657.\n",
      "[I 2024-01-08 18:24:26,667] Trial 19 finished with value: 6941685.262188721 and parameters: {'n_estimators': 63, 'max_depth': 17, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 12 with value: 5778297.132849657.\n",
      "[I 2024-01-08 18:24:26,798] Trial 20 finished with value: 6750107.77606008 and parameters: {'n_estimators': 19, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 12 with value: 5778297.132849657.\n",
      "[I 2024-01-08 18:24:27,005] Trial 21 finished with value: 5812428.5204074755 and parameters: {'n_estimators': 33, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 12 with value: 5778297.132849657.\n",
      "[I 2024-01-08 18:24:27,202] Trial 22 finished with value: 5661469.640195121 and parameters: {'n_estimators': 30, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 22 with value: 5661469.640195121.\n",
      "[I 2024-01-08 18:24:27,442] Trial 23 finished with value: 5699504.069415505 and parameters: {'n_estimators': 30, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 22 with value: 5661469.640195121.\n",
      "[I 2024-01-08 18:24:27,738] Trial 24 finished with value: 5763954.675920676 and parameters: {'n_estimators': 46, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 22 with value: 5661469.640195121.\n",
      "[I 2024-01-08 18:24:28,014] Trial 25 finished with value: 5942383.0011292575 and parameters: {'n_estimators': 46, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 22 with value: 5661469.640195121.\n",
      "[I 2024-01-08 18:24:28,256] Trial 26 finished with value: 6275326.796769203 and parameters: {'n_estimators': 43, 'max_depth': 16, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 22 with value: 5661469.640195121.\n",
      "[I 2024-01-08 18:24:28,650] Trial 27 finished with value: 5856254.284531921 and parameters: {'n_estimators': 62, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 22 with value: 5661469.640195121.\n",
      "[I 2024-01-08 18:24:28,829] Trial 28 finished with value: 6018827.0104302745 and parameters: {'n_estimators': 28, 'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 22 with value: 5661469.640195121.\n",
      "[I 2024-01-08 18:24:29,034] Trial 29 finished with value: 7282526.977737223 and parameters: {'n_estimators': 41, 'max_depth': 16, 'min_samples_split': 11, 'min_samples_leaf': 6}. Best is trial 22 with value: 5661469.640195121.\n",
      "[I 2024-01-08 18:24:29,153] Trial 30 finished with value: 12840405.383206865 and parameters: {'n_estimators': 19, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 22 with value: 5661469.640195121.\n",
      "[I 2024-01-08 18:24:29,346] Trial 31 finished with value: 5883431.470200556 and parameters: {'n_estimators': 29, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 22 with value: 5661469.640195121.\n",
      "[I 2024-01-08 18:24:29,468] Trial 32 finished with value: 6635148.074052893 and parameters: {'n_estimators': 17, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 22 with value: 5661469.640195121.\n",
      "[I 2024-01-08 18:24:29,686] Trial 33 finished with value: 6841135.349067046 and parameters: {'n_estimators': 49, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 22 with value: 5661469.640195121.\n",
      "[I 2024-01-08 18:24:29,988] Trial 34 finished with value: 5825979.145162783 and parameters: {'n_estimators': 63, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 22 with value: 5661469.640195121.\n",
      "[I 2024-01-08 18:24:30,258] Trial 35 finished with value: 6041954.887468719 and parameters: {'n_estimators': 37, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 22 with value: 5661469.640195121.\n",
      "[I 2024-01-08 18:24:30,444] Trial 36 finished with value: 6033497.268459044 and parameters: {'n_estimators': 24, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 22 with value: 5661469.640195121.\n",
      "[I 2024-01-08 18:24:30,644] Trial 37 finished with value: 6689599.711965136 and parameters: {'n_estimators': 34, 'max_depth': 31, 'min_samples_split': 12, 'min_samples_leaf': 3}. Best is trial 22 with value: 5661469.640195121.\n",
      "[I 2024-01-08 18:24:30,779] Trial 38 finished with value: 6586543.188662921 and parameters: {'n_estimators': 16, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 22 with value: 5661469.640195121.\n",
      "[I 2024-01-08 18:24:31,070] Trial 39 finished with value: 5934588.083210629 and parameters: {'n_estimators': 51, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 22 with value: 5661469.640195121.\n",
      "[I 2024-01-08 18:24:31,262] Trial 40 finished with value: 5579438.958782051 and parameters: {'n_estimators': 28, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 40 with value: 5579438.958782051.\n",
      "[I 2024-01-08 18:24:31,451] Trial 41 finished with value: 5622343.621539682 and parameters: {'n_estimators': 28, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 40 with value: 5579438.958782051.\n",
      "[I 2024-01-08 18:24:31,677] Trial 42 finished with value: 5975922.00732999 and parameters: {'n_estimators': 29, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 40 with value: 5579438.958782051.\n",
      "[I 2024-01-08 18:24:31,925] Trial 43 finished with value: 5697010.13462153 and parameters: {'n_estimators': 40, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 40 with value: 5579438.958782051.\n",
      "[I 2024-01-08 18:24:32,076] Trial 44 finished with value: 6602530.628667019 and parameters: {'n_estimators': 26, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 40 with value: 5579438.958782051.\n",
      "[I 2024-01-08 18:24:32,311] Trial 45 finished with value: 6101637.489939003 and parameters: {'n_estimators': 41, 'max_depth': 13, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 40 with value: 5579438.958782051.\n",
      "[I 2024-01-08 18:24:32,490] Trial 46 finished with value: 7909499.165916925 and parameters: {'n_estimators': 37, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 40 with value: 5579438.958782051.\n",
      "[I 2024-01-08 18:24:32,667] Trial 47 finished with value: 6330104.159387399 and parameters: {'n_estimators': 31, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 40 with value: 5579438.958782051.\n",
      "[I 2024-01-08 18:24:33,248] Trial 48 finished with value: 5658850.726967424 and parameters: {'n_estimators': 100, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 40 with value: 5579438.958782051.\n",
      "[I 2024-01-08 18:24:33,665] Trial 49 finished with value: 7379862.259391383 and parameters: {'n_estimators': 99, 'max_depth': 12, 'min_samples_split': 14, 'min_samples_leaf': 4}. Best is trial 40 with value: 5579438.958782051.\n",
      "[I 2024-01-08 18:24:34,015] Trial 50 finished with value: 9441240.601737803 and parameters: {'n_estimators': 91, 'max_depth': 6, 'min_samples_split': 17, 'min_samples_leaf': 9}. Best is trial 40 with value: 5579438.958782051.\n",
      "[I 2024-01-08 18:24:34,201] Trial 51 finished with value: 5475476.069650318 and parameters: {'n_estimators': 23, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 51 with value: 5475476.069650318.\n",
      "[I 2024-01-08 18:24:34,383] Trial 52 finished with value: 6113642.051530955 and parameters: {'n_estimators': 22, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 51 with value: 5475476.069650318.\n",
      "[I 2024-01-08 18:24:34,811] Trial 53 finished with value: 6368997.10471379 and parameters: {'n_estimators': 77, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 51 with value: 5475476.069650318.\n",
      "[I 2024-01-08 18:24:35,112] Trial 54 finished with value: 6002754.304620557 and parameters: {'n_estimators': 58, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 51 with value: 5475476.069650318.\n",
      "[I 2024-01-08 18:24:35,486] Trial 55 finished with value: 5861352.964035335 and parameters: {'n_estimators': 68, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 51 with value: 5475476.069650318.\n",
      "[I 2024-01-08 18:24:35,594] Trial 56 finished with value: 7406461.793749548 and parameters: {'n_estimators': 14, 'max_depth': 9, 'min_samples_split': 20, 'min_samples_leaf': 3}. Best is trial 51 with value: 5475476.069650318.\n",
      "[I 2024-01-08 18:24:35,790] Trial 57 finished with value: 5978465.850181918 and parameters: {'n_estimators': 26, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 51 with value: 5475476.069650318.\n",
      "[I 2024-01-08 18:24:36,207] Trial 58 finished with value: 5849274.098511081 and parameters: {'n_estimators': 85, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 51 with value: 5475476.069650318.\n",
      "[I 2024-01-08 18:24:36,344] Trial 59 finished with value: 6968424.185749483 and parameters: {'n_estimators': 20, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 51 with value: 5475476.069650318.\n",
      "[I 2024-01-08 18:24:36,562] Trial 60 finished with value: 6102561.54341904 and parameters: {'n_estimators': 34, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 51 with value: 5475476.069650318.\n",
      "[I 2024-01-08 18:24:36,783] Trial 61 finished with value: 5805188.755790853 and parameters: {'n_estimators': 30, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 51 with value: 5475476.069650318.\n",
      "[I 2024-01-08 18:24:36,974] Trial 62 finished with value: 5704563.617145136 and parameters: {'n_estimators': 23, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 51 with value: 5475476.069650318.\n",
      "[I 2024-01-08 18:24:37,250] Trial 63 finished with value: 5356492.999195113 and parameters: {'n_estimators': 40, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:37,510] Trial 64 finished with value: 6293991.85853976 and parameters: {'n_estimators': 41, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:37,749] Trial 65 finished with value: 5972542.8439556435 and parameters: {'n_estimators': 35, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:38,063] Trial 66 finished with value: 6012720.767559673 and parameters: {'n_estimators': 56, 'max_depth': 12, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:38,214] Trial 67 finished with value: 8072849.580684006 and parameters: {'n_estimators': 26, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:38,498] Trial 68 finished with value: 5750266.739111711 and parameters: {'n_estimators': 40, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:38,726] Trial 69 finished with value: 7072824.081463273 and parameters: {'n_estimators': 44, 'max_depth': 6, 'min_samples_split': 19, 'min_samples_leaf': 1}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:39,008] Trial 70 finished with value: 5602247.183154873 and parameters: {'n_estimators': 49, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:39,286] Trial 71 finished with value: 5973555.224681559 and parameters: {'n_estimators': 50, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:39,610] Trial 72 finished with value: 5889486.305379229 and parameters: {'n_estimators': 48, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:39,853] Trial 73 finished with value: 6208646.315229965 and parameters: {'n_estimators': 38, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:40,117] Trial 74 finished with value: 6077861.36931512 and parameters: {'n_estimators': 44, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:40,364] Trial 75 finished with value: 6347745.751146732 and parameters: {'n_estimators': 54, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:40,629] Trial 76 finished with value: 5416307.343667579 and parameters: {'n_estimators': 47, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:40,917] Trial 77 finished with value: 5678734.987840552 and parameters: {'n_estimators': 52, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:41,280] Trial 78 finished with value: 6167697.588731095 and parameters: {'n_estimators': 47, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:41,470] Trial 79 finished with value: 5976141.841259063 and parameters: {'n_estimators': 32, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:41,881] Trial 80 finished with value: 5554995.362092199 and parameters: {'n_estimators': 58, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:42,362] Trial 81 finished with value: 5719044.585041037 and parameters: {'n_estimators': 71, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:42,731] Trial 82 finished with value: 6456504.254286004 and parameters: {'n_estimators': 96, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:42,887] Trial 83 finished with value: 6094395.411312506 and parameters: {'n_estimators': 18, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:43,277] Trial 84 finished with value: 5457103.276813629 and parameters: {'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:43,648] Trial 85 finished with value: 5598378.382399288 and parameters: {'n_estimators': 67, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:43,975] Trial 86 finished with value: 5573306.867481771 and parameters: {'n_estimators': 60, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:44,457] Trial 87 finished with value: 5371621.652502614 and parameters: {'n_estimators': 59, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:45,017] Trial 88 finished with value: 5411284.764894352 and parameters: {'n_estimators': 66, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:45,516] Trial 89 finished with value: 5689238.920095583 and parameters: {'n_estimators': 60, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:46,091] Trial 90 finished with value: 5583865.500924962 and parameters: {'n_estimators': 65, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:46,781] Trial 91 finished with value: 5737271.235700363 and parameters: {'n_estimators': 66, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:47,350] Trial 92 finished with value: 5570051.401333819 and parameters: {'n_estimators': 57, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:47,814] Trial 93 finished with value: 5541021.562516907 and parameters: {'n_estimators': 59, 'max_depth': 17, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:48,280] Trial 94 finished with value: 5549165.78118002 and parameters: {'n_estimators': 57, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:48,752] Trial 95 finished with value: 6128319.06889362 and parameters: {'n_estimators': 58, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:49,210] Trial 96 finished with value: 5695309.039194924 and parameters: {'n_estimators': 56, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:49,669] Trial 97 finished with value: 5939883.080682102 and parameters: {'n_estimators': 70, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:50,282] Trial 98 finished with value: 5657045.865125326 and parameters: {'n_estimators': 61, 'max_depth': 23, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:50,849] Trial 99 finished with value: 5366620.306864886 and parameters: {'n_estimators': 64, 'max_depth': 14, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:51,313] Trial 100 finished with value: 5877599.293458089 and parameters: {'n_estimators': 75, 'max_depth': 18, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:51,780] Trial 101 finished with value: 5681578.651714071 and parameters: {'n_estimators': 58, 'max_depth': 14, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:52,183] Trial 102 finished with value: 6065937.034017079 and parameters: {'n_estimators': 64, 'max_depth': 17, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:52,624] Trial 103 finished with value: 6022055.222457642 and parameters: {'n_estimators': 54, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:52,911] Trial 104 finished with value: 6736390.114227651 and parameters: {'n_estimators': 62, 'max_depth': 23, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:53,328] Trial 105 finished with value: 5663968.314748635 and parameters: {'n_estimators': 57, 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 63 with value: 5356492.999195113.\n",
      "[I 2024-01-08 18:24:53,669] Trial 106 finished with value: 5304768.810275134 and parameters: {'n_estimators': 52, 'max_depth': 26, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:24:53,980] Trial 107 finished with value: 5938082.772437306 and parameters: {'n_estimators': 53, 'max_depth': 32, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:24:54,454] Trial 108 finished with value: 5936518.227331724 and parameters: {'n_estimators': 60, 'max_depth': 26, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:24:54,816] Trial 109 finished with value: 6462696.403389311 and parameters: {'n_estimators': 68, 'max_depth': 27, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:24:55,211] Trial 110 finished with value: 5743323.267606894 and parameters: {'n_estimators': 63, 'max_depth': 21, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:24:55,629] Trial 111 finished with value: 6070121.103659087 and parameters: {'n_estimators': 52, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:24:56,103] Trial 112 finished with value: 5961313.406802796 and parameters: {'n_estimators': 55, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:24:56,577] Trial 113 finished with value: 5946445.315690655 and parameters: {'n_estimators': 59, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:24:57,002] Trial 114 finished with value: 5665595.707758976 and parameters: {'n_estimators': 56, 'max_depth': 17, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:24:57,396] Trial 115 finished with value: 6027524.864850147 and parameters: {'n_estimators': 62, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:24:57,967] Trial 116 finished with value: 5918722.23022357 and parameters: {'n_estimators': 65, 'max_depth': 18, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:24:58,310] Trial 117 finished with value: 5705615.738615058 and parameters: {'n_estimators': 52, 'max_depth': 29, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:24:58,777] Trial 118 finished with value: 5389882.016859798 and parameters: {'n_estimators': 50, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:24:59,045] Trial 119 finished with value: 6843832.979777067 and parameters: {'n_estimators': 50, 'max_depth': 25, 'min_samples_split': 13, 'min_samples_leaf': 1}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:24:59,265] Trial 120 finished with value: 7098838.944880044 and parameters: {'n_estimators': 45, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:24:59,749] Trial 121 finished with value: 6015424.10163885 and parameters: {'n_estimators': 55, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:25:00,187] Trial 122 finished with value: 5684918.334283306 and parameters: {'n_estimators': 47, 'max_depth': 22, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:25:00,646] Trial 123 finished with value: 6318486.17213183 and parameters: {'n_estimators': 58, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:25:01,039] Trial 124 finished with value: 5539375.223920144 and parameters: {'n_estimators': 50, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:25:01,380] Trial 125 finished with value: 6138318.785371448 and parameters: {'n_estimators': 50, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:25:01,927] Trial 126 finished with value: 5818766.710933148 and parameters: {'n_estimators': 71, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:25:02,359] Trial 127 finished with value: 5868687.608916842 and parameters: {'n_estimators': 53, 'max_depth': 16, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:25:02,781] Trial 128 finished with value: 5561918.809160523 and parameters: {'n_estimators': 48, 'max_depth': 17, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:25:03,300] Trial 129 finished with value: 5881580.395379789 and parameters: {'n_estimators': 61, 'max_depth': 29, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:25:04,019] Trial 130 finished with value: 6089181.333350973 and parameters: {'n_estimators': 69, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:25:04,589] Trial 131 finished with value: 6954423.8194809975 and parameters: {'n_estimators': 43, 'max_depth': 19, 'min_samples_split': 16, 'min_samples_leaf': 1}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:25:06,065] Trial 132 finished with value: 5728489.520418392 and parameters: {'n_estimators': 49, 'max_depth': 17, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:25:07,085] Trial 133 finished with value: 5633068.188379399 and parameters: {'n_estimators': 47, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:25:08,122] Trial 134 finished with value: 5398096.9039064925 and parameters: {'n_estimators': 51, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:25:08,849] Trial 135 finished with value: 5413036.570479937 and parameters: {'n_estimators': 51, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:25:09,329] Trial 136 finished with value: 5723227.18928284 and parameters: {'n_estimators': 51, 'max_depth': 21, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:25:09,655] Trial 137 finished with value: 7688848.156869145 and parameters: {'n_estimators': 54, 'max_depth': 24, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:25:10,167] Trial 138 finished with value: 5546939.975656191 and parameters: {'n_estimators': 46, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:25:10,580] Trial 139 finished with value: 5431057.762945474 and parameters: {'n_estimators': 43, 'max_depth': 22, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:25:10,918] Trial 140 finished with value: 5873432.267418038 and parameters: {'n_estimators': 43, 'max_depth': 22, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:25:11,318] Trial 141 finished with value: 5810123.383923172 and parameters: {'n_estimators': 45, 'max_depth': 21, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 106 with value: 5304768.810275134.\n",
      "[I 2024-01-08 18:25:11,704] Trial 142 finished with value: 5205591.308850961 and parameters: {'n_estimators': 39, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 142 with value: 5205591.308850961.\n",
      "[I 2024-01-08 18:25:12,343] Trial 143 finished with value: 5431807.285537894 and parameters: {'n_estimators': 41, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 142 with value: 5205591.308850961.\n",
      "[I 2024-01-08 18:25:13,731] Trial 144 finished with value: 5145555.33949904 and parameters: {'n_estimators': 39, 'max_depth': 25, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:14,798] Trial 145 finished with value: 5770051.542117573 and parameters: {'n_estimators': 38, 'max_depth': 26, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:16,223] Trial 146 finished with value: 6091810.082552604 and parameters: {'n_estimators': 41, 'max_depth': 24, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:16,939] Trial 147 finished with value: 5529313.549509029 and parameters: {'n_estimators': 37, 'max_depth': 23, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:17,398] Trial 148 finished with value: 6077491.414810151 and parameters: {'n_estimators': 39, 'max_depth': 28, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:17,871] Trial 149 finished with value: 6382074.331611755 and parameters: {'n_estimators': 35, 'max_depth': 25, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:18,535] Trial 150 finished with value: 5169296.486064342 and parameters: {'n_estimators': 42, 'max_depth': 22, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:19,506] Trial 151 finished with value: 5926951.30268573 and parameters: {'n_estimators': 42, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:20,755] Trial 152 finished with value: 5988295.677194406 and parameters: {'n_estimators': 40, 'max_depth': 22, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:21,390] Trial 153 finished with value: 5753286.468801251 and parameters: {'n_estimators': 43, 'max_depth': 21, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:22,533] Trial 154 finished with value: 5577445.317759767 and parameters: {'n_estimators': 45, 'max_depth': 25, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:23,516] Trial 155 finished with value: 5799321.213199324 and parameters: {'n_estimators': 39, 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:24,434] Trial 156 finished with value: 6349676.846487857 and parameters: {'n_estimators': 48, 'max_depth': 27, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:24,951] Trial 157 finished with value: 5508957.504177469 and parameters: {'n_estimators': 33, 'max_depth': 23, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:25,331] Trial 158 finished with value: 6031990.336383594 and parameters: {'n_estimators': 35, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:25,641] Trial 159 finished with value: 12332300.465796683 and parameters: {'n_estimators': 43, 'max_depth': 22, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:26,147] Trial 160 finished with value: 5482470.942878027 and parameters: {'n_estimators': 36, 'max_depth': 26, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:26,567] Trial 161 finished with value: 6137771.782963407 and parameters: {'n_estimators': 37, 'max_depth': 26, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:27,001] Trial 162 finished with value: 5617484.847205343 and parameters: {'n_estimators': 41, 'max_depth': 24, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:27,523] Trial 163 finished with value: 5772418.258172191 and parameters: {'n_estimators': 39, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:27,811] Trial 164 finished with value: 9291269.05031191 and parameters: {'n_estimators': 46, 'max_depth': 28, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:28,205] Trial 165 finished with value: 5662040.178052298 and parameters: {'n_estimators': 36, 'max_depth': 19, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:28,581] Trial 166 finished with value: 6213945.684287516 and parameters: {'n_estimators': 41, 'max_depth': 23, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:28,872] Trial 167 finished with value: 5678360.04317577 and parameters: {'n_estimators': 13, 'max_depth': 21, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:29,477] Trial 168 finished with value: 6096575.533457081 and parameters: {'n_estimators': 66, 'max_depth': 26, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:29,794] Trial 169 finished with value: 5987938.018972805 and parameters: {'n_estimators': 44, 'max_depth': 25, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:30,248] Trial 170 finished with value: 5322245.793413827 and parameters: {'n_estimators': 52, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:31,053] Trial 171 finished with value: 5665466.768757554 and parameters: {'n_estimators': 52, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:31,521] Trial 172 finished with value: 5325137.151901828 and parameters: {'n_estimators': 49, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:32,235] Trial 173 finished with value: 5905613.935794873 and parameters: {'n_estimators': 51, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:32,695] Trial 174 finished with value: 5513816.902144175 and parameters: {'n_estimators': 48, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:33,128] Trial 175 finished with value: 5765746.036678677 and parameters: {'n_estimators': 54, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:33,574] Trial 176 finished with value: 5466897.202017136 and parameters: {'n_estimators': 49, 'max_depth': 22, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:34,019] Trial 177 finished with value: 5704664.731645973 and parameters: {'n_estimators': 49, 'max_depth': 21, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:34,453] Trial 178 finished with value: 5713258.5707726 and parameters: {'n_estimators': 46, 'max_depth': 22, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:34,951] Trial 179 finished with value: 5517449.154780334 and parameters: {'n_estimators': 50, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:35,521] Trial 180 finished with value: 5546929.215869506 and parameters: {'n_estimators': 53, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:35,962] Trial 181 finished with value: 5843636.212386127 and parameters: {'n_estimators': 47, 'max_depth': 24, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:36,517] Trial 182 finished with value: 5635976.652984608 and parameters: {'n_estimators': 64, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:36,963] Trial 183 finished with value: 6262233.9485039245 and parameters: {'n_estimators': 52, 'max_depth': 22, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:37,823] Trial 184 finished with value: 5869683.558761176 and parameters: {'n_estimators': 55, 'max_depth': 23, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:38,351] Trial 185 finished with value: 5751611.030901268 and parameters: {'n_estimators': 45, 'max_depth': 21, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:38,731] Trial 186 finished with value: 6197447.858615654 and parameters: {'n_estimators': 49, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:39,233] Trial 187 finished with value: 5504682.8584300745 and parameters: {'n_estimators': 51, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:39,690] Trial 188 finished with value: 5412826.137877505 and parameters: {'n_estimators': 42, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:40,123] Trial 189 finished with value: 5353689.56506209 and parameters: {'n_estimators': 44, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:40,487] Trial 190 finished with value: 5780216.27317188 and parameters: {'n_estimators': 41, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:40,902] Trial 191 finished with value: 5516194.454178914 and parameters: {'n_estimators': 44, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:41,282] Trial 192 finished with value: 5615101.273986952 and parameters: {'n_estimators': 42, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:41,650] Trial 193 finished with value: 5892371.049563147 and parameters: {'n_estimators': 38, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:42,036] Trial 194 finished with value: 5525339.615159976 and parameters: {'n_estimators': 42, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:42,487] Trial 195 finished with value: 6170134.3719751015 and parameters: {'n_estimators': 47, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:42,852] Trial 196 finished with value: 5717313.70835565 and parameters: {'n_estimators': 39, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:43,132] Trial 197 finished with value: 6893745.695826836 and parameters: {'n_estimators': 44, 'max_depth': 22, 'min_samples_split': 12, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:43,567] Trial 198 finished with value: 5759549.015572391 and parameters: {'n_estimators': 49, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n",
      "[I 2024-01-08 18:25:44,035] Trial 199 finished with value: 5580557.750503313 and parameters: {'n_estimators': 40, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 144 with value: 5145555.33949904.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Meilleurs hyperparamètres:\n",
      "n_estimators: 21\n",
      "max_depth: 3\n",
      "min_samples_split: 12\n",
      "min_samples_leaf: 5\n",
      "Meilleure MSE: 5145555.3395\n",
      "R2 correspondant: 0.9166\n",
      "\n",
      " Importance des variables :\n",
      "                 196         195       193         200             166         203        192        191        194       202               199       201       198                 179           154             21         197            162                  90                   178                  177              153                  10              186          2               19                156                  149             172             18           3               165              188                55              155                  144          5                 16               160                   176                  91                      131                161                147              174              184                            24                 60                            74                   146                  159                         73                 54                        92               169                          9                           8                185             158              189            163                    22                   45                      102                          14                 152           1                        103                109                        101                   51                 59                                25                     28                            72              164                    94               157          4                                  93                      117                               141                113                              142           0                      126                       119                 53                       145              183                      96                      121                       57                    87               173                            129                           36                      76                           122                  84                          46                              128                                120                       64                    82                    85                 58                    89              110                       47                         143                  61                  65                         98                        49                  112               175                     132                  83                   80                     116                    69                         70                            139                            127                       95                        135                 38            171                            31                           32                           33                       34                    6                          71                          35                    180                         63                     66                170                                37                   168                   167                               7                  12                     181                 11                      68               190             20                               26                                       27              187             17                15                        62                       67                     29                        30                  182                13                                23                         39                     104                        40                     41                     133                      130                  86                    88                             125                              124                               123                               97                     118                115                114                                     99                   111                       100                 108               107                    106                                   136                          137                        138                    50                    42                         43                       44                         75                   77                           48                    105                  78                         140                151                   150                  79                 148                          52                    81                 56                      134\n",
      "Variable  enginesize  curbweight  carwidth  horsepower  drivewheel_rwd  highwaympg  carlength  wheelbase  carheight   citympg  compressionratio   peakrpm    stroke  cylindernumber_six  fueltype_gas  CarName_bmw z4  boreratio  carbody_sedan  CarName_peugeot 304  cylindernumber_four  cylindernumber_five  fueltype_diesel  CarName_audi 100 ls  fuelsystem_idi  symboling_0  CarName_bmw x4  aspiration_turbo  CarName_volvo 264gl  enginetype_ohc  CarName_bmw x3  symboling_1  drivewheel_fwd  fuelsystem_mpfi  CarName_jaguar xj  aspiration_std  CarName_volvo 144ea  symboling_3  CarName_bmw 320i  carbody_hardtop  cylindernumber_eight  CarName_peugeot 504  CarName_toyota mark ii  carbody_hatchback  CarName_volvo 245  enginetype_ohcv  fuelsystem_2bbl  CarName_buick century special  CarName_mazda glc  CarName_mitsubishi outlander  CarName_volvo 244dl  carbody_convertible  CarName_mitsubishi montero  CarName_jaguar xf  CarName_peugeot 504 (sw)  enginetype_dohc  CarName_alfa-romero stelvio  CarName_alfa-romero giulia  fuelsystem_4bbl  doornumber_two  fuelsystem_spdi  carbody_wagon  CarName_buick century  CarName_honda civic  CarName_porsche boxter  CarName_audi 5000s (diesel)  CarName_vw rabbit  symboling_-1  CarName_porsche cayenne  CarName_saab 99le  CarName_porcshce panamera  CarName_isuzu D-Max   CarName_mazda 626  CarName_buick electra 225 custom  CarName_buick skyhawk  CarName_mitsubishi mirage g4  drivewheel_4wd  CarName_peugeot 604sl  doornumber_four  symboling_2  CarName_peugeot 505s turbo diesel  CarName_subaru tribeca  CarName_volkswagen rabbit custom  CarName_subaru dl  CarName_volkswagen super beetle  symboling_-2  CarName_toyota corona  CarName_toyota celica gt  CarName_isuzu MU-X  CarName_volvo 145e (sw)  fuelsystem_1bbl  CarName_plymouth duster  CarName_toyota corolla  CarName_maxda glc deluxe  CarName_nissan rogue  enginetype_ohcf  CarName_toyota corona mark ii  CarName_dodge coronet custom  CarName_nissan clipper  CarName_toyota corolla 1200  CarName_nissan note  CarName_honda civic (auto)  CarName_toyota corona liftback  CarName_toyota celica gt liftback  CarName_mazda glc deluxe  CarName_nissan latio  CarName_nissan nv200  CarName_maxda rx3  CarName_nissan titan  CarName_subaru  CarName_honda civic 1300  CarName_volkswagen type 3  CarName_mazda glc 4  CarName_mazda rx-4  CarName_plymouth fury iii  CarName_honda civic cvcc  CarName_subaru brz  enginetype_rotor  CarName_toyota starlet  CarName_nissan leaf  CarName_nissan juke  CarName_subaru trezia  CarName_mitsubishi g4  CarName_mitsubishi lancer  CarName_volkswagen model 111  CarName_toyota corona hardtop  CarName_plymouth cricket  CarName_vokswagen rabbit  CarName_dodge d200  enginetype_l  CarName_chevrolet monte carlo  CarName_chevrolet vega 2300  CarName_dodge challenger se  CarName_dodge colt (sw)  CarName_Nissan versa  CarName_mitsubishi mirage  CarName_dodge colt hardtop  cylindernumber_three  CarName_mazda glc custom l  CarName_mazda rx-7 gs  enginetype_dohcv  CarName_dodge coronet custom (sw)  enginelocation_rear  enginelocation_front  CarName_alfa-romero Quadrifoglio  CarName_audi 4000  cylindernumber_twelve  CarName_audi 100ls  CarName_mercury cougar  fuelsystem_spfi  CarName_bmw x5  CarName_buick opel isuzu deluxe  CarName_buick regal sport coupe (turbo)  fuelsystem_mfi  CarName_bmw x1  CarName_audi fox  CarName_mazda glc custom  CarName_mazda rx2 coupe  CarName_buick skylark  CarName_chevrolet impala  cylindernumber_two  CarName_audi 5000  CarName_buick century luxus (sw)  CarName_dodge dart custom  CarName_porsche macan  CarName_dodge monaco (sw)  CarName_dodge rampage  CarName_toyota tercel  CarName_toyota cressida  CarName_nissan otti  CarName_nissan teana  CarName_toyota corolla tercel  CarName_toyota corolla liftback  CarName_toyota corolla 1600 (sw)  CarName_plymouth fury gran sedan  CarName_toyota carina  CarName_subaru r2  CarName_subaru r1  CarName_plymouth satellite custom (sw)  CarName_subaru baja  CarName_plymouth valiant  CarName_saab 99gle  CarName_saab 99e  CarName_renault 5 gtl  CarName_volkswagen 1131 deluxe sedan  CarName_volkswagen 411 (sw)  CarName_volkswagen dasher  CarName_honda prelude  CarName_honda accord  CarName_honda accord cvcc  CarName_honda accord lx  CarName_mitsubishi pajero  CarName_nissan dayz  CarName_honda civic 1500 gl  CarName_renault 12tl  CarName_nissan fuga  CarName_volkswagen rabbit  CarName_vw dasher  CarName_volvo diesel  CarName_nissan gt-r  CarName_volvo 246  CarName_isuzu D-Max V-Cross  CarName_nissan kicks  CarName_jaguar xk  CarName_toyouta tercel\n",
      "Poids       0.687383    0.144791  0.039545    0.023296          0.0179     0.01647   0.012416   0.012274   0.006234  0.003806          0.003128  0.002913  0.002868            0.002226       0.00199        0.001892   0.001833       0.001112             0.000869             0.000848             0.000815         0.000813             0.000808        0.000774      0.00075        0.000714           0.00065             0.000633        0.000629        0.000614     0.000595         0.00055         0.000506           0.000488        0.000463             0.000406      0.00039          0.000357         0.000305              0.000303             0.000291                0.000211            0.00019           0.000187         0.000177         0.000163                       0.000156           0.000145                      0.000134             0.000128             0.000119                    0.000119           0.000116                  0.000114         0.000113                      0.00011                    0.000108         0.000107        0.000106         0.000102       0.000099               0.000099             0.000098                0.000092                     0.000086           0.000082      0.000078                 0.000071            0.00007                    0.00007              0.000069           0.000066                          0.000063               0.000061                      0.000059        0.000049                0.00004         0.000036     0.000032                           0.000031                 0.00003                           0.00003           0.000029                         0.000021       0.00002               0.000019                  0.000018            0.000018                 0.000017         0.000013                 0.000012                0.000012                  0.000011              0.000009         0.000009                       0.000008                      0.000008                0.000008                     0.000007             0.000007                    0.000007                        0.000007                           0.000006                  0.000006              0.000006              0.000005           0.000005              0.000005        0.000005                  0.000004                   0.000004             0.000004            0.000003                   0.000003                  0.000003            0.000003          0.000003                0.000003             0.000002             0.000002               0.000001               0.000001                   0.000001                      0.000001                       0.000001                       0.0                       0.0                 0.0           0.0                            0.0                          0.0                          0.0                      0.0                   0.0                        0.0                         0.0                   0.0                         0.0                    0.0               0.0                                0.0                  0.0                   0.0                               0.0                0.0                    0.0                 0.0                     0.0              0.0             0.0                              0.0                                      0.0             0.0             0.0               0.0                       0.0                      0.0                    0.0                       0.0                 0.0                0.0                               0.0                        0.0                    0.0                        0.0                    0.0                    0.0                      0.0                  0.0                   0.0                            0.0                              0.0                               0.0                               0.0                    0.0                0.0                0.0                                     0.0                  0.0                       0.0                 0.0               0.0                    0.0                                   0.0                          0.0                        0.0                    0.0                   0.0                        0.0                      0.0                        0.0                  0.0                          0.0                   0.0                  0.0                        0.0                0.0                   0.0                  0.0                0.0                          0.0                   0.0                0.0                     0.0\n"
     ]
    }
   ],
   "source": [
    "# On initialise avec aucune valeur d'hyperparamètres\n",
    "r2_scores_rf = {'n_estimators': [], 'max_depth': [], 'min_samples_split': [], 'min_samples_leaf': []}\n",
    "mse_scores_rf = {'n_estimators': [], 'max_depth': [], 'min_samples_split': [], 'min_samples_leaf': []}\n",
    "hyperparameters = {'n_estimators': [], 'max_depth': [], 'min_samples_split': [], 'min_samples_leaf': []}\n",
    "\n",
    "def objective_rf(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 32, log=True),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "    }\n",
    "    \n",
    "    rf = RandomForestRegressor(**params)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    \n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    # Stocke les scores R2 et MSE pour chaque hyperparamètre\n",
    "    for param_name, param_value in params.items():\n",
    "        r2_scores_rf[param_name].append(r2)\n",
    "        hyperparameters[param_name].append(param_value)\n",
    "        mse_scores_rf[param_name].append(mse)\n",
    "    \n",
    "    return mse  # Optuna cherche à minimiser, donc utilise la MSE\n",
    "\n",
    "\n",
    "# Crée une étude Optuna pour RandomForestRegressor\n",
    "study_rf = optuna.create_study(direction='minimize')\n",
    "study_rf.optimize(objective_rf, n_trials=200)\n",
    "\n",
    "# Obtient l'indice du meilleur score MSE à travers tous les hyperparamètres\n",
    "best_mse_index = np.argmin([min(mses) for mses in mse_scores_rf.values()])\n",
    "\n",
    "# Extrait les meilleurs hyperparamètres\n",
    "best_hyperparameters = {param_name: values[best_mse_index] for param_name, values in hyperparameters.items()}\n",
    "\n",
    "print('\\n')\n",
    "print(\"Meilleurs hyperparamètres:\")\n",
    "for param_name, param_value in best_hyperparameters.items():\n",
    "    print(f\"{param_name}: {param_value}\")\n",
    "\n",
    "best_mse_RandomForest = min([min(mses) for mses in mse_scores_rf.values()])\n",
    "r2_RandomForest = max([max(scores) for scores in r2_scores_rf.values()])\n",
    "print(f\"Meilleure MSE: {best_mse_RandomForest:.4f}\")\n",
    "print(f\"R2 correspondant: {r2_RandomForest:.4f}\")\n",
    "\n",
    "#Affichage des poids\n",
    "best_RandomForest= RandomForestRegressor(**study_rf.best_params)\n",
    "best_RandomForest.fit(X_train, y_train)\n",
    "\n",
    "# Obtention du poids des variables\n",
    "feature_importance = best_RandomForest.feature_importances_\n",
    "\n",
    "# Création d'un DataFrame pour afficher les importances des variables\n",
    "importance_df = pd.DataFrame({'Variable': X_train.columns, 'Poids': feature_importance})\n",
    "importance_df = importance_df.sort_values('Poids', ascending=False)\n",
    "\n",
    "print(\"\\n Importance des variables :\")\n",
    "importance=importance_df.T\n",
    "print(importance.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1200 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#AFFICHAGE (ne fonctionne pas)\n",
    "best_n_estimators_RandomForest = best_hyperparameters['n_estimators']\n",
    "best_max_depth_RandomForest = best_hyperparameters['max_depth']\n",
    "best_min_samples_RandomForest = best_hyperparameters['min_samples_split']\n",
    "best_min_samples_leaf_RandomForest = best_hyperparameters['min_samples_leaf']\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "\n",
    "def plot_RandomForest(axs_row, axs_col, name_hyperparameter):\n",
    "    mse_scores_fixed_parameter = []\n",
    "    for i in range(len(hyperparameters[name_hyperparameter])):\n",
    "        if name_hyperparameter=='n_estimators':\n",
    "            fixed_n_estimators_model_RandomForest= RandomForestRegressor(n_estimators=hyperparameters[name_hyperparameter][i],\n",
    "                                                                        max_depth=best_max_depth_RandomForest,\n",
    "                                                                        min_samples_split=best_min_samples_RandomForest,\n",
    "                                                                        min_samples_leaf=best_min_samples_leaf_RandomForest)        \n",
    "        if name_hyperparameter=='max_depth':\n",
    "            fixed_n_estimators_model_RandomForest= RandomForestRegressor(n_estimators=best_n_estimators_RandomForest,\n",
    "                                                                        max_depth=hyperparameters[name_hyperparameter][i],\n",
    "                                                                        min_samples_split=best_min_samples_RandomForest,\n",
    "                                                                        min_samples_leaf=best_min_samples_leaf_RandomForest)\n",
    "        if name_hyperparameter=='min_samples_split':\n",
    "            fixed_n_estimators_model_RandomForest= RandomForestRegressor(n_estimators=best_n_estimators_RandomForest,\n",
    "                                                                        max_depth=best_max_depth_RandomForest,\n",
    "                                                                        min_samples_split=hyperparameters[name_hyperparameter][i],\n",
    "                                                                        min_samples_leaf=best_min_samples_leaf_RandomForest)\n",
    "        if name_hyperparameter=='min_samples_leaf':\n",
    "            fixed_n_estimators_model_RandomForest= RandomForestRegressor(n_estimators=best_n_estimators_RandomForest,\n",
    "                                                                        max_depth=best_max_depth_RandomForest,\n",
    "                                                                        min_samples_split=best_min_samples_RandomForest,\n",
    "                                                                        min_samples_leaf=hyperparameters[name_hyperparameter][i])\n",
    "\n",
    "\n",
    "        fixed_n_estimators_model_RandomForest.fit(X_train, y_train)\n",
    "        y_pred_en = fixed_n_estimators_model_RandomForest.predict(X_test)\n",
    "        mse_dot = mean_squared_error(y_test, y_pred_en)\n",
    "        mse_scores_fixed_parameter.append(mse_dot)\n",
    "\n",
    "    axs[axs_row, axs_col].scatter(hyperparameters[name_hyperparameter], mse_scores_fixed_parameter, marker='o')\n",
    "    axs[axs_row, axs_col].plot(study_rf.best_params[name_hyperparameter], best_mse_RandomForest, marker='o', markersize=8, color='red')\n",
    "    axs[axs_row, axs_col].set_title('Evolution du MSE')\n",
    "    axs[axs_row, axs_col].set_xlabel(name_hyperparameter)\n",
    "    axs[axs_row, axs_col].set_ylabel('MSE')\n",
    "\n",
    "plot_RandomForest(0, 0, 'n_estimators')\n",
    "plot_RandomForest(0, 1, 'max_depth')    \n",
    "plot_RandomForest(1, 0, 'min_samples_split')\n",
    "plot_RandomForest(1, 1, 'min_samples_leaf')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoostingRegressor\n",
    "GradientBoostingRegressor construit les arbres de manière séquentielle: chaque arbre corrige les erreurs commises par le précédent. Il se concentre sur les différences entre les valeurs prédites et réelles des arbres précédents. \n",
    "Ce modèle possède plusieurs qualités des précèdents modèles: robustesse aux données aberrantes, gestion de la sélection de variables, gestion de la non-linéarité.\n",
    "\n",
    "On s'attend donc à avoir de meilleurs résultats qu'avec RandomForestRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 20:54:20,209] A new study created in memory with name: no-name-29e9001d-b1b5-42d9-a85f-1c41cc7646e2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:478: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "[I 2024-01-08 20:54:20,616] Trial 0 finished with value: inf and parameters: {'n_estimators': 74, 'learning_rate': 122, 'min_weight_fraction_leaf': 0.00757220052206431, 'max_depth': 6, 'min_impurity_decrease': 243, 'min_samples_leaf': 5}. Best is trial 0 with value: inf.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:478: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "[I 2024-01-08 20:54:21,033] Trial 1 finished with value: inf and parameters: {'n_estimators': 69, 'learning_rate': 846, 'min_weight_fraction_leaf': 0.030012323744310232, 'max_depth': 8, 'min_impurity_decrease': 148, 'min_samples_leaf': 3}. Best is trial 0 with value: inf.\n",
      "[I 2024-01-08 20:54:21,135] Trial 2 finished with value: 2.867978892293297e+166 and parameters: {'n_estimators': 42, 'learning_rate': 79, 'min_weight_fraction_leaf': 0.27805025370176367, 'max_depth': 16, 'min_impurity_decrease': 907, 'min_samples_leaf': 1}. Best is trial 2 with value: 2.867978892293297e+166.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:478: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "[I 2024-01-08 20:54:21,729] Trial 3 finished with value: inf and parameters: {'n_estimators': 99, 'learning_rate': 928, 'min_weight_fraction_leaf': 0.04490898207784677, 'max_depth': 8, 'min_impurity_decrease': 176, 'min_samples_leaf': 3}. Best is trial 2 with value: 2.867978892293297e+166.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:478: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "[I 2024-01-08 20:54:21,919] Trial 4 finished with value: inf and parameters: {'n_estimators': 85, 'learning_rate': 620, 'min_weight_fraction_leaf': 0.24958135355937489, 'max_depth': 13, 'min_impurity_decrease': 94, 'min_samples_leaf': 5}. Best is trial 2 with value: 2.867978892293297e+166.\n",
      "[I 2024-01-08 20:54:21,971] Trial 5 finished with value: 6.109646073640808e+98 and parameters: {'n_estimators': 17, 'learning_rate': 482, 'min_weight_fraction_leaf': 0.07314972338335801, 'max_depth': 2, 'min_impurity_decrease': 417, 'min_samples_leaf': 6}. Best is trial 5 with value: 6.109646073640808e+98.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:478: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "[I 2024-01-08 20:54:22,534] Trial 6 finished with value: inf and parameters: {'n_estimators': 74, 'learning_rate': 200, 'min_weight_fraction_leaf': 0.2406599257645059, 'max_depth': 8, 'min_impurity_decrease': 755, 'min_samples_leaf': 6}. Best is trial 5 with value: 6.109646073640808e+98.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:478: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "[I 2024-01-08 20:54:22,864] Trial 7 finished with value: inf and parameters: {'n_estimators': 55, 'learning_rate': 650, 'min_weight_fraction_leaf': 0.17330373559585388, 'max_depth': 2, 'min_impurity_decrease': 116, 'min_samples_leaf': 1}. Best is trial 5 with value: 6.109646073640808e+98.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:478: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "[I 2024-01-08 20:54:23,485] Trial 8 finished with value: inf and parameters: {'n_estimators': 98, 'learning_rate': 518, 'min_weight_fraction_leaf': 0.07200539922694582, 'max_depth': 14, 'min_impurity_decrease': 465, 'min_samples_leaf': 4}. Best is trial 5 with value: 6.109646073640808e+98.\n",
      "[I 2024-01-08 20:54:23,733] Trial 9 finished with value: 1.3124748930516448e+245 and parameters: {'n_estimators': 47, 'learning_rate': 338, 'min_weight_fraction_leaf': 0.29600601585715197, 'max_depth': 17, 'min_impurity_decrease': 894, 'min_samples_leaf': 4}. Best is trial 5 with value: 6.109646073640808e+98.\n",
      "[I 2024-01-08 20:54:23,984] Trial 10 finished with value: 5.164197038995909e+43 and parameters: {'n_estimators': 13, 'learning_rate': 373, 'min_weight_fraction_leaf': 0.4985531603316213, 'max_depth': 2, 'min_impurity_decrease': 478, 'min_samples_leaf': 9}. Best is trial 10 with value: 5.164197038995909e+43.\n",
      "[I 2024-01-08 20:54:24,197] Trial 11 finished with value: 1.523237613829204e+48 and parameters: {'n_estimators': 14, 'learning_rate': 353, 'min_weight_fraction_leaf': 0.49736561579733213, 'max_depth': 2, 'min_impurity_decrease': 465, 'min_samples_leaf': 9}. Best is trial 10 with value: 5.164197038995909e+43.\n",
      "[I 2024-01-08 20:54:24,450] Trial 12 finished with value: 1.8252806341912715e+62 and parameters: {'n_estimators': 11, 'learning_rate': 311, 'min_weight_fraction_leaf': 0.48772066261737135, 'max_depth': 3, 'min_impurity_decrease': 640, 'min_samples_leaf': 10}. Best is trial 10 with value: 5.164197038995909e+43.\n",
      "[I 2024-01-08 20:54:24,832] Trial 13 finished with value: 8.133955931768399e+144 and parameters: {'n_estimators': 27, 'learning_rate': 352, 'min_weight_fraction_leaf': 0.47293646475267515, 'max_depth': 4, 'min_impurity_decrease': 361, 'min_samples_leaf': 9}. Best is trial 10 with value: 5.164197038995909e+43.\n",
      "[I 2024-01-08 20:54:25,180] Trial 14 finished with value: 2.5580767468858922e+157 and parameters: {'n_estimators': 28, 'learning_rate': 476, 'min_weight_fraction_leaf': 0.39061068303948554, 'max_depth': 31, 'min_impurity_decrease': 586, 'min_samples_leaf': 8}. Best is trial 10 with value: 5.164197038995909e+43.\n",
      "[I 2024-01-08 20:54:25,471] Trial 15 finished with value: 6.31381451774041e+142 and parameters: {'n_estimators': 29, 'learning_rate': 216, 'min_weight_fraction_leaf': 0.39450855509135935, 'max_depth': 3, 'min_impurity_decrease': 315, 'min_samples_leaf': 8}. Best is trial 10 with value: 5.164197038995909e+43.\n",
      "[I 2024-01-08 20:54:25,680] Trial 16 finished with value: 3.302639298206533e+43 and parameters: {'n_estimators': 18, 'learning_rate': 11, 'min_weight_fraction_leaf': 0.41271920629362785, 'max_depth': 2, 'min_impurity_decrease': 638, 'min_samples_leaf': 10}. Best is trial 16 with value: 3.302639298206533e+43.\n",
      "[I 2024-01-08 20:54:26,119] Trial 17 finished with value: 73266579.63836151 and parameters: {'n_estimators': 37, 'learning_rate': 2, 'min_weight_fraction_leaf': 0.4126040311075976, 'max_depth': 4, 'min_impurity_decrease': 727, 'min_samples_leaf': 7}. Best is trial 17 with value: 73266579.63836151.\n",
      "[I 2024-01-08 20:54:26,321] Trial 18 finished with value: 3.9906168092073236e+31 and parameters: {'n_estimators': 40, 'learning_rate': 3, 'min_weight_fraction_leaf': 0.3744839655344543, 'max_depth': 5, 'min_impurity_decrease': 739, 'min_samples_leaf': 7}. Best is trial 17 with value: 73266579.63836151.\n",
      "[I 2024-01-08 20:54:26,625] Trial 19 finished with value: 6.780594857193457e+93 and parameters: {'n_estimators': 40, 'learning_rate': 13, 'min_weight_fraction_leaf': 0.33936877438793833, 'max_depth': 5, 'min_impurity_decrease': 779, 'min_samples_leaf': 7}. Best is trial 17 with value: 73266579.63836151.\n",
      "[I 2024-01-08 20:54:26,983] Trial 20 finished with value: 3.494778954965181e+250 and parameters: {'n_estimators': 55, 'learning_rate': 163, 'min_weight_fraction_leaf': 0.3340001386378355, 'max_depth': 4, 'min_impurity_decrease': 777, 'min_samples_leaf': 7}. Best is trial 17 with value: 73266579.63836151.\n",
      "[I 2024-01-08 20:54:27,292] Trial 21 finished with value: 29453924.494483043 and parameters: {'n_estimators': 36, 'learning_rate': 1, 'min_weight_fraction_leaf': 0.42064651225348504, 'max_depth': 3, 'min_impurity_decrease': 632, 'min_samples_leaf': 10}. Best is trial 21 with value: 29453924.494483043.\n",
      "[I 2024-01-08 20:54:27,832] Trial 22 finished with value: 8.067303930005482e+137 and parameters: {'n_estimators': 35, 'learning_rate': 74, 'min_weight_fraction_leaf': 0.43965573252641815, 'max_depth': 3, 'min_impurity_decrease': 716, 'min_samples_leaf': 7}. Best is trial 21 with value: 29453924.494483043.\n",
      "[I 2024-01-08 20:54:28,318] Trial 23 finished with value: 2.1739585089406354e+256 and parameters: {'n_estimators': 52, 'learning_rate': 248, 'min_weight_fraction_leaf': 0.35509516927544593, 'max_depth': 4, 'min_impurity_decrease': 569, 'min_samples_leaf': 8}. Best is trial 21 with value: 29453924.494483043.\n",
      "[I 2024-01-08 20:54:28,504] Trial 24 finished with value: 3.3678162843896844e+98 and parameters: {'n_estimators': 37, 'learning_rate': 18, 'min_weight_fraction_leaf': 0.4381908779130052, 'max_depth': 6, 'min_impurity_decrease': 820, 'min_samples_leaf': 10}. Best is trial 21 with value: 29453924.494483043.\n",
      "[I 2024-01-08 20:54:28,776] Trial 25 finished with value: 1.9032389799216556e+262 and parameters: {'n_estimators': 62, 'learning_rate': 114, 'min_weight_fraction_leaf': 0.19612525245672677, 'max_depth': 3, 'min_impurity_decrease': 995, 'min_samples_leaf': 6}. Best is trial 21 with value: 29453924.494483043.\n",
      "[I 2024-01-08 20:54:28,983] Trial 26 finished with value: 2.5929599487301346e+51 and parameters: {'n_estimators': 46, 'learning_rate': 4, 'min_weight_fraction_leaf': 0.36762390494188146, 'max_depth': 10, 'min_impurity_decrease': 682, 'min_samples_leaf': 8}. Best is trial 21 with value: 29453924.494483043.\n",
      "[I 2024-01-08 20:54:29,254] Trial 27 finished with value: 1.3302388788231428e+132 and parameters: {'n_estimators': 26, 'learning_rate': 250, 'min_weight_fraction_leaf': 0.31221778579896947, 'max_depth': 5, 'min_impurity_decrease': 542, 'min_samples_leaf': 7}. Best is trial 21 with value: 29453924.494483043.\n",
      "[I 2024-01-08 20:54:29,412] Trial 28 finished with value: 1.934669263162985e+151 and parameters: {'n_estimators': 33, 'learning_rate': 152, 'min_weight_fraction_leaf': 0.44772113537797165, 'max_depth': 5, 'min_impurity_decrease': 1, 'min_samples_leaf': 9}. Best is trial 21 with value: 29453924.494483043.\n",
      "[I 2024-01-08 20:54:29,628] Trial 29 finished with value: 1.2617580390411399e+247 and parameters: {'n_estimators': 61, 'learning_rate': 93, 'min_weight_fraction_leaf': 0.4147565339858087, 'max_depth': 6, 'min_impurity_decrease': 864, 'min_samples_leaf': 5}. Best is trial 21 with value: 29453924.494483043.\n",
      "[I 2024-01-08 20:54:29,816] Trial 30 finished with value: 4.815535454506212e+140 and parameters: {'n_estimators': 23, 'learning_rate': 786, 'min_weight_fraction_leaf': 0.37927305124010263, 'max_depth': 4, 'min_impurity_decrease': 663, 'min_samples_leaf': 4}. Best is trial 21 with value: 29453924.494483043.\n",
      "[I 2024-01-08 20:54:29,947] Trial 31 finished with value: 1.1054667635097036e+68 and parameters: {'n_estimators': 18, 'learning_rate': 49, 'min_weight_fraction_leaf': 0.41725907957404607, 'max_depth': 3, 'min_impurity_decrease': 629, 'min_samples_leaf': 10}. Best is trial 21 with value: 29453924.494483043.\n",
      "[I 2024-01-08 20:54:30,076] Trial 32 finished with value: 4.894305851599697e+95 and parameters: {'n_estimators': 21, 'learning_rate': 127, 'min_weight_fraction_leaf': 0.45121835864921256, 'max_depth': 4, 'min_impurity_decrease': 722, 'min_samples_leaf': 10}. Best is trial 21 with value: 29453924.494483043.\n",
      "[I 2024-01-08 20:54:30,255] Trial 33 finished with value: 1.5795969818210213e+168 and parameters: {'n_estimators': 45, 'learning_rate': 62, 'min_weight_fraction_leaf': 0.41312968643240827, 'max_depth': 3, 'min_impurity_decrease': 965, 'min_samples_leaf': 9}. Best is trial 21 with value: 29453924.494483043.\n",
      "[I 2024-01-08 20:54:30,382] Trial 34 finished with value: 20210832.022988718 and parameters: {'n_estimators': 33, 'learning_rate': 1, 'min_weight_fraction_leaf': 0.33820917262287636, 'max_depth': 7, 'min_impurity_decrease': 605, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:30,531] Trial 35 finished with value: 1.759944936830629e+150 and parameters: {'n_estimators': 32, 'learning_rate': 171, 'min_weight_fraction_leaf': 0.3206590335271801, 'max_depth': 10, 'min_impurity_decrease': 838, 'min_samples_leaf': 7}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:30,732] Trial 36 finished with value: 1.1691505382573095e+170 and parameters: {'n_estimators': 41, 'learning_rate': 97, 'min_weight_fraction_leaf': 0.2792014715192396, 'max_depth': 6, 'min_impurity_decrease': 524, 'min_samples_leaf': 6}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:30,915] Trial 37 finished with value: 1.2941548720963578e+301 and parameters: {'n_estimators': 49, 'learning_rate': 992, 'min_weight_fraction_leaf': 0.3473960798057291, 'max_depth': 7, 'min_impurity_decrease': 611, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:31,171] Trial 38 finished with value: 3.4477098585318433e+149 and parameters: {'n_estimators': 39, 'learning_rate': 67, 'min_weight_fraction_leaf': 0.21841847801739211, 'max_depth': 10, 'min_impurity_decrease': 700, 'min_samples_leaf': 6}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:31,372] Trial 39 finished with value: 3.234076479323182e+162 and parameters: {'n_estimators': 33, 'learning_rate': 224, 'min_weight_fraction_leaf': 0.26284365323377623, 'max_depth': 7, 'min_impurity_decrease': 792, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:31,629] Trial 40 finished with value: 5.154368721489854e+254 and parameters: {'n_estimators': 43, 'learning_rate': 747, 'min_weight_fraction_leaf': 0.12159258554386665, 'max_depth': 9, 'min_impurity_decrease': 416, 'min_samples_leaf': 5}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:31,781] Trial 41 finished with value: 2.9271087731590354e+29 and parameters: {'n_estimators': 23, 'learning_rate': 4, 'min_weight_fraction_leaf': 0.3968009797821561, 'max_depth': 5, 'min_impurity_decrease': 601, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:31,903] Trial 42 finished with value: 2.3228447081888523e+21 and parameters: {'n_estimators': 23, 'learning_rate': 3, 'min_weight_fraction_leaf': 0.37224156833762767, 'max_depth': 5, 'min_impurity_decrease': 555, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:32,119] Trial 43 finished with value: 2.201921151544048e+113 and parameters: {'n_estimators': 25, 'learning_rate': 131, 'min_weight_fraction_leaf': 0.0007055100814004622, 'max_depth': 8, 'min_impurity_decrease': 523, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:32,416] Trial 44 finished with value: 5.583275010206609e+83 and parameters: {'n_estimators': 22, 'learning_rate': 55, 'min_weight_fraction_leaf': 0.30835634960213726, 'max_depth': 5, 'min_impurity_decrease': 580, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:32,720] Trial 45 finished with value: 6.924061065545323e+146 and parameters: {'n_estimators': 31, 'learning_rate': 178, 'min_weight_fraction_leaf': 0.46290108610437664, 'max_depth': 6, 'min_impurity_decrease': 444, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:33,030] Trial 46 finished with value: 1.482797481662241e+86 and parameters: {'n_estimators': 16, 'learning_rate': 288, 'min_weight_fraction_leaf': 0.39672354659020653, 'max_depth': 12, 'min_impurity_decrease': 396, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:33,231] Trial 47 finished with value: 9.675944441271196e+122 and parameters: {'n_estimators': 21, 'learning_rate': 563, 'min_weight_fraction_leaf': 0.36100258018675235, 'max_depth': 7, 'min_impurity_decrease': 304, 'min_samples_leaf': 2}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:33,787] Trial 48 finished with value: 2.8436859290631085e+43 and parameters: {'n_estimators': 11, 'learning_rate': 44, 'min_weight_fraction_leaf': 0.2887524395033848, 'max_depth': 28, 'min_impurity_decrease': 669, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:478: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "[I 2024-01-08 20:54:34,421] Trial 49 finished with value: inf and parameters: {'n_estimators': 80, 'learning_rate': 109, 'min_weight_fraction_leaf': 0.42788143042706395, 'max_depth': 4, 'min_impurity_decrease': 498, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:34,804] Trial 50 finished with value: 4.283583415649609e+118 and parameters: {'n_estimators': 36, 'learning_rate': 36, 'min_weight_fraction_leaf': 0.47825625822694773, 'max_depth': 6, 'min_impurity_decrease': 600, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:35,321] Trial 51 finished with value: 8.969952703144497e+67 and parameters: {'n_estimators': 28, 'learning_rate': 13, 'min_weight_fraction_leaf': 0.37684976062472647, 'max_depth': 5, 'min_impurity_decrease': 752, 'min_samples_leaf': 7}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:35,695] Trial 52 finished with value: 26317175.188122865 and parameters: {'n_estimators': 39, 'learning_rate': 1, 'min_weight_fraction_leaf': 0.3981807700657912, 'max_depth': 5, 'min_impurity_decrease': 739, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:36,011] Trial 53 finished with value: 5.031920698772122e+163 and parameters: {'n_estimators': 30, 'learning_rate': 402, 'min_weight_fraction_leaf': 0.3937714614228902, 'max_depth': 8, 'min_impurity_decrease': 631, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:36,318] Trial 54 finished with value: 7.126045492278161e+147 and parameters: {'n_estimators': 36, 'learning_rate': 90, 'min_weight_fraction_leaf': 0.33240157594695147, 'max_depth': 4, 'min_impurity_decrease': 549, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:36,619] Trial 55 finished with value: 6.116851782119291e+225 and parameters: {'n_estimators': 51, 'learning_rate': 139, 'min_weight_fraction_leaf': 0.4013581319317828, 'max_depth': 7, 'min_impurity_decrease': 702, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:36,913] Trial 56 finished with value: 61967029.64293136 and parameters: {'n_estimators': 92, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.4290965159870636, 'max_depth': 5, 'min_impurity_decrease': 661, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:478: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "[I 2024-01-08 20:54:37,201] Trial 57 finished with value: inf and parameters: {'n_estimators': 93, 'learning_rate': 50, 'min_weight_fraction_leaf': 0.4618374241751039, 'max_depth': 18, 'min_impurity_decrease': 813, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:478: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "[I 2024-01-08 20:54:37,453] Trial 58 finished with value: inf and parameters: {'n_estimators': 73, 'learning_rate': 190, 'min_weight_fraction_leaf': 0.34972304772416946, 'max_depth': 6, 'min_impurity_decrease': 911, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:478: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "[I 2024-01-08 20:54:37,719] Trial 59 finished with value: inf and parameters: {'n_estimators': 87, 'learning_rate': 81, 'min_weight_fraction_leaf': 0.4298531576809532, 'max_depth': 5, 'min_impurity_decrease': 755, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:37,899] Trial 60 finished with value: 8.640615289497346e+33 and parameters: {'n_estimators': 44, 'learning_rate': 3, 'min_weight_fraction_leaf': 0.49039630511970406, 'max_depth': 9, 'min_impurity_decrease': 662, 'min_samples_leaf': 7}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:38,132] Trial 61 finished with value: 3.475746756487807e+218 and parameters: {'n_estimators': 65, 'learning_rate': 43, 'min_weight_fraction_leaf': 0.3840078617438353, 'max_depth': 4, 'min_impurity_decrease': 565, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:38,268] Trial 62 finished with value: 27438456.03210528 and parameters: {'n_estimators': 25, 'learning_rate': 1, 'min_weight_fraction_leaf': 0.4245072640767953, 'max_depth': 5, 'min_impurity_decrease': 611, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:38,414] Trial 63 finished with value: 3.8525422251449565e+157 and parameters: {'n_estimators': 39, 'learning_rate': 85, 'min_weight_fraction_leaf': 0.43257647834516055, 'max_depth': 3, 'min_impurity_decrease': 497, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:38,544] Trial 64 finished with value: 4.2698823506772435e+114 and parameters: {'n_estimators': 26, 'learning_rate': 116, 'min_weight_fraction_leaf': 0.45760976418987087, 'max_depth': 6, 'min_impurity_decrease': 643, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:38,755] Trial 65 finished with value: 61967029.64293136 and parameters: {'n_estimators': 57, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.3629870221769973, 'max_depth': 5, 'min_impurity_decrease': 693, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:38,955] Trial 66 finished with value: 5.052496831897295e+186 and parameters: {'n_estimators': 59, 'learning_rate': 34, 'min_weight_fraction_leaf': 0.4128738602958058, 'max_depth': 8, 'min_impurity_decrease': 728, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:478: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "[I 2024-01-08 20:54:39,167] Trial 67 finished with value: inf and parameters: {'n_estimators': 70, 'learning_rate': 146, 'min_weight_fraction_leaf': 0.47817847628511406, 'max_depth': 4, 'min_impurity_decrease': 673, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:478: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "[I 2024-01-08 20:54:39,382] Trial 68 finished with value: inf and parameters: {'n_estimators': 77, 'learning_rate': 440, 'min_weight_fraction_leaf': 0.44354500686149473, 'max_depth': 4, 'min_impurity_decrease': 701, 'min_samples_leaf': 7}. Best is trial 34 with value: 20210832.022988718.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:478: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "[I 2024-01-08 20:54:39,637] Trial 69 finished with value: inf and parameters: {'n_estimators': 98, 'learning_rate': 70, 'min_weight_fraction_leaf': 0.36724226774950647, 'max_depth': 9, 'min_impurity_decrease': 874, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:39,881] Trial 70 finished with value: 3.4205365969744775e+177 and parameters: {'n_estimators': 57, 'learning_rate': 32, 'min_weight_fraction_leaf': 0.4217996363741226, 'max_depth': 3, 'min_impurity_decrease': 759, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:40,137] Trial 71 finished with value: 4.228437867524364e+88 and parameters: {'n_estimators': 48, 'learning_rate': 8, 'min_weight_fraction_leaf': 0.33036846468847114, 'max_depth': 5, 'min_impurity_decrease': 623, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:40,303] Trial 72 finished with value: 73266579.6383616 and parameters: {'n_estimators': 29, 'learning_rate': 2, 'min_weight_fraction_leaf': 0.4043754167475828, 'max_depth': 7, 'min_impurity_decrease': 579, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:40,521] Trial 73 finished with value: 1.3466242731953626e+132 and parameters: {'n_estimators': 34, 'learning_rate': 69, 'min_weight_fraction_leaf': 0.38526678045568336, 'max_depth': 7, 'min_impurity_decrease': 650, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:40,871] Trial 74 finished with value: 1.7833890454192356e+222 and parameters: {'n_estimators': 38, 'learning_rate': 670, 'min_weight_fraction_leaf': 0.4103976350738482, 'max_depth': 7, 'min_impurity_decrease': 689, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:41,323] Trial 75 finished with value: 5.594653249829549e+95 and parameters: {'n_estimators': 29, 'learning_rate': 34, 'min_weight_fraction_leaf': 0.026636903102985887, 'max_depth': 12, 'min_impurity_decrease': 583, 'min_samples_leaf': 7}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:41,802] Trial 76 finished with value: 6.87264020324169e+175 and parameters: {'n_estimators': 42, 'learning_rate': 102, 'min_weight_fraction_leaf': 0.44451549926890777, 'max_depth': 6, 'min_impurity_decrease': 730, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:42,349] Trial 77 finished with value: 1.1340219122514124e+102 and parameters: {'n_estimators': 32, 'learning_rate': 31, 'min_weight_fraction_leaf': 0.4030665195873334, 'max_depth': 8, 'min_impurity_decrease': 786, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:42,700] Trial 78 finished with value: 2.3250026676320244e+187 and parameters: {'n_estimators': 51, 'learning_rate': 59, 'min_weight_fraction_leaf': 0.3539983030120165, 'max_depth': 11, 'min_impurity_decrease': 517, 'min_samples_leaf': 6}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:42,888] Trial 79 finished with value: 1.159111125049797e+69 and parameters: {'n_estimators': 14, 'learning_rate': 157, 'min_weight_fraction_leaf': 0.12482806129497753, 'max_depth': 5, 'min_impurity_decrease': 603, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:43,034] Trial 80 finished with value: 4.636783476749085e+85 and parameters: {'n_estimators': 19, 'learning_rate': 115, 'min_weight_fraction_leaf': 0.4262967767882363, 'max_depth': 6, 'min_impurity_decrease': 678, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:43,369] Trial 81 finished with value: 5.0806437550753656e+120 and parameters: {'n_estimators': 94, 'learning_rate': 5, 'min_weight_fraction_leaf': 0.37720014446252104, 'max_depth': 5, 'min_impurity_decrease': 557, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:43,621] Trial 82 finished with value: 61967029.64293136 and parameters: {'n_estimators': 26, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.35901799192863915, 'max_depth': 9, 'min_impurity_decrease': 536, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:43,790] Trial 83 finished with value: 8.706266748442245e+106 and parameters: {'n_estimators': 34, 'learning_rate': 30, 'min_weight_fraction_leaf': 0.3436790253077982, 'max_depth': 10, 'min_impurity_decrease': 475, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:43,953] Trial 84 finished with value: 2.9994724266917337e+106 and parameters: {'n_estimators': 27, 'learning_rate': 69, 'min_weight_fraction_leaf': 0.31164984390168715, 'max_depth': 9, 'min_impurity_decrease': 618, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:44,154] Trial 85 finished with value: 62820158.046328574 and parameters: {'n_estimators': 25, 'learning_rate': 2, 'min_weight_fraction_leaf': 0.3872725051378323, 'max_depth': 11, 'min_impurity_decrease': 590, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:44,424] Trial 86 finished with value: 2.810850374740052e+105 and parameters: {'n_estimators': 25, 'learning_rate': 92, 'min_weight_fraction_leaf': 0.3600839837163987, 'max_depth': 13, 'min_impurity_decrease': 532, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:44,600] Trial 87 finished with value: 5.573030444194595e+71 and parameters: {'n_estimators': 19, 'learning_rate': 50, 'min_weight_fraction_leaf': 0.38658327225426675, 'max_depth': 11, 'min_impurity_decrease': 174, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:44,895] Trial 88 finished with value: 2.364923679953856e+225 and parameters: {'n_estimators': 37, 'learning_rate': 880, 'min_weight_fraction_leaf': 0.3658647500281383, 'max_depth': 11, 'min_impurity_decrease': 638, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:45,149] Trial 89 finished with value: 3.0214469216397683e+50 and parameters: {'n_estimators': 16, 'learning_rate': 23, 'min_weight_fraction_leaf': 0.2995922308060137, 'max_depth': 16, 'min_impurity_decrease': 711, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:45,368] Trial 90 finished with value: 1.655678699530258e+152 and parameters: {'n_estimators': 31, 'learning_rate': 216, 'min_weight_fraction_leaf': 0.24440664007406393, 'max_depth': 13, 'min_impurity_decrease': 598, 'min_samples_leaf': 1}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:45,546] Trial 91 finished with value: 9.51920967215498e+82 and parameters: {'n_estimators': 29, 'learning_rate': 21, 'min_weight_fraction_leaf': 0.4036679078479755, 'max_depth': 14, 'min_impurity_decrease': 452, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:45,735] Trial 92 finished with value: 61967029.64293136 and parameters: {'n_estimators': 24, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.32295605214268075, 'max_depth': 9, 'min_impurity_decrease': 578, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:46,068] Trial 93 finished with value: 3.28555870174324e+94 and parameters: {'n_estimators': 24, 'learning_rate': 66, 'min_weight_fraction_leaf': 0.3424194398287295, 'max_depth': 10, 'min_impurity_decrease': 649, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:46,334] Trial 94 finished with value: 1.2849909880795287e+78 and parameters: {'n_estimators': 21, 'learning_rate': 49, 'min_weight_fraction_leaf': 0.32522019078247194, 'max_depth': 9, 'min_impurity_decrease': 615, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:46,734] Trial 95 finished with value: 3.7248850119063026e+239 and parameters: {'n_estimators': 83, 'learning_rate': 26, 'min_weight_fraction_leaf': 0.3906043198602666, 'max_depth': 8, 'min_impurity_decrease': 539, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:47,051] Trial 96 finished with value: 61967029.64293136 and parameters: {'n_estimators': 35, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.46913805534365405, 'max_depth': 24, 'min_impurity_decrease': 495, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:47,249] Trial 97 finished with value: 1.3523206202064087e+139 and parameters: {'n_estimators': 35, 'learning_rate': 77, 'min_weight_fraction_leaf': 0.4510668811256724, 'max_depth': 12, 'min_impurity_decrease': 488, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:47,394] Trial 98 finished with value: 7.691796953871256e+120 and parameters: {'n_estimators': 27, 'learning_rate': 127, 'min_weight_fraction_leaf': 0.4656375247740245, 'max_depth': 26, 'min_impurity_decrease': 510, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:47,551] Trial 99 finished with value: 8.67222530446486e+113 and parameters: {'n_estimators': 32, 'learning_rate': 47, 'min_weight_fraction_leaf': 0.2750642489067737, 'max_depth': 20, 'min_impurity_decrease': 366, 'min_samples_leaf': 2}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:47,683] Trial 100 finished with value: 1.1771037081723796e+103 and parameters: {'n_estimators': 24, 'learning_rate': 99, 'min_weight_fraction_leaf': 0.4366661377497432, 'max_depth': 29, 'min_impurity_decrease': 444, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:47,879] Trial 101 finished with value: 31742526.786497053 and parameters: {'n_estimators': 41, 'learning_rate': 1, 'min_weight_fraction_leaf': 0.46976767870194336, 'max_depth': 19, 'min_impurity_decrease': 567, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:48,419] Trial 102 finished with value: 5.574335797770482e+109 and parameters: {'n_estimators': 40, 'learning_rate': 20, 'min_weight_fraction_leaf': 0.494597358643979, 'max_depth': 24, 'min_impurity_decrease': 573, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:48,619] Trial 103 finished with value: 32094985.50890657 and parameters: {'n_estimators': 46, 'learning_rate': 1, 'min_weight_fraction_leaf': 0.4706135752132229, 'max_depth': 19, 'min_impurity_decrease': 546, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:48,793] Trial 104 finished with value: 3.630498646796695e+124 and parameters: {'n_estimators': 43, 'learning_rate': 24, 'min_weight_fraction_leaf': 0.4831305029508063, 'max_depth': 20, 'min_impurity_decrease': 548, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:49,049] Trial 105 finished with value: 6.981414597065899e+166 and parameters: {'n_estimators': 46, 'learning_rate': 55, 'min_weight_fraction_leaf': 0.47022472357393846, 'max_depth': 22, 'min_impurity_decrease': 467, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:49,244] Trial 106 finished with value: 7.070150880795161e+236 and parameters: {'n_estimators': 42, 'learning_rate': 539, 'min_weight_fraction_leaf': 0.47383700755665353, 'max_depth': 17, 'min_impurity_decrease': 423, 'min_samples_leaf': 4}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:49,401] Trial 107 finished with value: 5.2402734640206606e+153 and parameters: {'n_estimators': 38, 'learning_rate': 85, 'min_weight_fraction_leaf': 0.45183478473356603, 'max_depth': 22, 'min_impurity_decrease': 507, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:49,587] Trial 108 finished with value: 2.3515473496109707e+188 and parameters: {'n_estimators': 66, 'learning_rate': 41, 'min_weight_fraction_leaf': 0.49890078735281124, 'max_depth': 16, 'min_impurity_decrease': 660, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:49,787] Trial 109 finished with value: 61967029.64293136 and parameters: {'n_estimators': 49, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.42010495579022056, 'max_depth': 25, 'min_impurity_decrease': 564, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:50,167] Trial 110 finished with value: 6.157157534328171e+168 and parameters: {'n_estimators': 45, 'learning_rate': 63, 'min_weight_fraction_leaf': 0.4561817510906322, 'max_depth': 20, 'min_impurity_decrease': 528, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:50,507] Trial 111 finished with value: 26867510.551540844 and parameters: {'n_estimators': 48, 'learning_rate': 1, 'min_weight_fraction_leaf': 0.43802273285018944, 'max_depth': 23, 'min_impurity_decrease': 568, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:50,799] Trial 112 finished with value: 2.6927124354992065e+116 and parameters: {'n_estimators': 40, 'learning_rate': 24, 'min_weight_fraction_leaf': 0.4341400154317441, 'max_depth': 31, 'min_impurity_decrease': 632, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:50,984] Trial 113 finished with value: 61967029.64293136 and parameters: {'n_estimators': 53, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.46772882319553066, 'max_depth': 23, 'min_impurity_decrease': 610, 'min_samples_leaf': 7}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:51,181] Trial 114 finished with value: 4.516320315948656e+181 and parameters: {'n_estimators': 54, 'learning_rate': 42, 'min_weight_fraction_leaf': 0.44386202659967444, 'max_depth': 19, 'min_impurity_decrease': 689, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:51,340] Trial 115 finished with value: 9.388386289418253e+89 and parameters: {'n_estimators': 36, 'learning_rate': 15, 'min_weight_fraction_leaf': 0.48473436726086067, 'max_depth': 27, 'min_impurity_decrease': 585, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:51,511] Trial 116 finished with value: 1.8473177127927916e+197 and parameters: {'n_estimators': 50, 'learning_rate': 80, 'min_weight_fraction_leaf': 0.42577173484065145, 'max_depth': 21, 'min_impurity_decrease': 545, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:51,685] Trial 117 finished with value: 8.418252722177657e+138 and parameters: {'n_estimators': 47, 'learning_rate': 26, 'min_weight_fraction_leaf': 0.41606127239146234, 'max_depth': 18, 'min_impurity_decrease': 570, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:51,830] Trial 118 finished with value: 1.1008788973362352e+140 and parameters: {'n_estimators': 33, 'learning_rate': 103, 'min_weight_fraction_leaf': 0.4382626499449023, 'max_depth': 24, 'min_impurity_decrease': 66, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:51,993] Trial 119 finished with value: 3.5731925315595587e+149 and parameters: {'n_estimators': 41, 'learning_rate': 55, 'min_weight_fraction_leaf': 0.3182207128999458, 'max_depth': 29, 'min_impurity_decrease': 654, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:52,212] Trial 120 finished with value: 4.100911173699519e+145 and parameters: {'n_estimators': 44, 'learning_rate': 38, 'min_weight_fraction_leaf': 0.23293083079578386, 'max_depth': 14, 'min_impurity_decrease': 629, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:52,497] Trial 121 finished with value: 73266579.63836154 and parameters: {'n_estimators': 49, 'learning_rate': 2, 'min_weight_fraction_leaf': 0.42111405722929945, 'max_depth': 25, 'min_impurity_decrease': 562, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:52,738] Trial 122 finished with value: 61967029.64293136 and parameters: {'n_estimators': 58, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.4566703986838812, 'max_depth': 25, 'min_impurity_decrease': 490, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:52,990] Trial 123 finished with value: 6.538226580205483e+129 and parameters: {'n_estimators': 47, 'learning_rate': 21, 'min_weight_fraction_leaf': 0.37055702027316434, 'max_depth': 15, 'min_impurity_decrease': 598, 'min_samples_leaf': 7}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:53,166] Trial 124 finished with value: 61967029.64293136 and parameters: {'n_estimators': 38, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.4090890800926676, 'max_depth': 23, 'min_impurity_decrease': 526, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:53,345] Trial 125 finished with value: 2.842559953391279e+207 and parameters: {'n_estimators': 56, 'learning_rate': 62, 'min_weight_fraction_leaf': 0.3555738538560986, 'max_depth': 21, 'min_impurity_decrease': 554, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:53,523] Trial 126 finished with value: 6.551717943245494e+171 and parameters: {'n_estimators': 52, 'learning_rate': 39, 'min_weight_fraction_leaf': 0.39866092739704184, 'max_depth': 28, 'min_impurity_decrease': 741, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:53,682] Trial 127 finished with value: 1.0755069247466514e+97 and parameters: {'n_estimators': 35, 'learning_rate': 20, 'min_weight_fraction_leaf': 0.42217546596497985, 'max_depth': 18, 'min_impurity_decrease': 680, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:53,841] Trial 128 finished with value: 5.589224007633897e+176 and parameters: {'n_estimators': 45, 'learning_rate': 77, 'min_weight_fraction_leaf': 0.4447271519372998, 'max_depth': 26, 'min_impurity_decrease': 582, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:54,062] Trial 129 finished with value: 61967029.64293136 and parameters: {'n_estimators': 87, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.4612665502934179, 'max_depth': 19, 'min_impurity_decrease': 508, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:54,207] Trial 130 finished with value: 2.770515435176297e+160 and parameters: {'n_estimators': 31, 'learning_rate': 294, 'min_weight_fraction_leaf': 0.3368265440963025, 'max_depth': 23, 'min_impurity_decrease': 715, 'min_samples_leaf': 7}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:54,384] Trial 131 finished with value: 61967029.64293136 and parameters: {'n_estimators': 54, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.47053408470258995, 'max_depth': 32, 'min_impurity_decrease': 602, 'min_samples_leaf': 7}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:54,551] Trial 132 finished with value: 2.279227199616553e+132 and parameters: {'n_estimators': 48, 'learning_rate': 21, 'min_weight_fraction_leaf': 0.47959329092737507, 'max_depth': 23, 'min_impurity_decrease': 615, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:54,724] Trial 133 finished with value: 1.1571528123197902e+173 and parameters: {'n_estimators': 51, 'learning_rate': 43, 'min_weight_fraction_leaf': 0.4342556444226672, 'max_depth': 21, 'min_impurity_decrease': 619, 'min_samples_leaf': 7}. Best is trial 34 with value: 20210832.022988718.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:478: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "[I 2024-01-08 20:54:54,962] Trial 134 finished with value: inf and parameters: {'n_estimators': 100, 'learning_rate': 56, 'min_weight_fraction_leaf': 0.4673183867987112, 'max_depth': 22, 'min_impurity_decrease': 569, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:55,223] Trial 135 finished with value: 1.2248162103642385e+143 and parameters: {'n_estimators': 54, 'learning_rate': 19, 'min_weight_fraction_leaf': 0.3791266020365614, 'max_depth': 24, 'min_impurity_decrease': 645, 'min_samples_leaf': 6}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:55,537] Trial 136 finished with value: 3.008381828247956e+134 and parameters: {'n_estimators': 43, 'learning_rate': 31, 'min_weight_fraction_leaf': 0.4897660897517863, 'max_depth': 26, 'min_impurity_decrease': 533, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:56,023] Trial 137 finished with value: 26955766.66193681 and parameters: {'n_estimators': 60, 'learning_rate': 1, 'min_weight_fraction_leaf': 0.45018032989826123, 'max_depth': 19, 'min_impurity_decrease': 595, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:56,244] Trial 138 finished with value: 1.7226661107132662e+242 and parameters: {'n_estimators': 61, 'learning_rate': 85, 'min_weight_fraction_leaf': 0.4491176596077043, 'max_depth': 19, 'min_impurity_decrease': 667, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:56,400] Trial 139 finished with value: 2.8070220419693537e+141 and parameters: {'n_estimators': 41, 'learning_rate': 44, 'min_weight_fraction_leaf': 0.42879459021485156, 'max_depth': 15, 'min_impurity_decrease': 770, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:56,595] Trial 140 finished with value: 2.2919968744544427e+233 and parameters: {'n_estimators': 63, 'learning_rate': 63, 'min_weight_fraction_leaf': 0.4161962906426968, 'max_depth': 17, 'min_impurity_decrease': 550, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:56,771] Trial 141 finished with value: 61967029.64293136 and parameters: {'n_estimators': 50, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.4608177863177499, 'max_depth': 17, 'min_impurity_decrease': 591, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:56,954] Trial 142 finished with value: 1.2485850724645637e+158 and parameters: {'n_estimators': 60, 'learning_rate': 19, 'min_weight_fraction_leaf': 0.47322998723924276, 'max_depth': 21, 'min_impurity_decrease': 621, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:57,099] Trial 143 finished with value: 8.748602695893134e+93 and parameters: {'n_estimators': 28, 'learning_rate': 36, 'min_weight_fraction_leaf': 0.44023817656871145, 'max_depth': 2, 'min_impurity_decrease': 569, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:57,266] Trial 144 finished with value: 5.042041393558256e+132 and parameters: {'n_estimators': 52, 'learning_rate': 17, 'min_weight_fraction_leaf': 0.451557173128841, 'max_depth': 30, 'min_impurity_decrease': 604, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:57,483] Trial 145 finished with value: 61967029.64293136 and parameters: {'n_estimators': 57, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.18020485862374694, 'max_depth': 19, 'min_impurity_decrease': 696, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:57,617] Trial 146 finished with value: 6.218020012866747e+120 and parameters: {'n_estimators': 20, 'learning_rate': 680, 'min_weight_fraction_leaf': 0.40678810603439, 'max_depth': 23, 'min_impurity_decrease': 480, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:57,786] Trial 147 finished with value: 5.15226211279623e+135 and parameters: {'n_estimators': 39, 'learning_rate': 45, 'min_weight_fraction_leaf': 0.30094823005939264, 'max_depth': 27, 'min_impurity_decrease': 518, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:57,932] Trial 148 finished with value: 9.700851225666064e+195 and parameters: {'n_estimators': 34, 'learning_rate': 592, 'min_weight_fraction_leaf': 0.3973552071167413, 'max_depth': 25, 'min_impurity_decrease': 805, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:58,063] Trial 149 finished with value: 1.3401711702959603e+88 and parameters: {'n_estimators': 22, 'learning_rate': 69, 'min_weight_fraction_leaf': 0.35008983403115973, 'max_depth': 22, 'min_impurity_decrease': 632, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:58,257] Trial 150 finished with value: 1.8153999435676733e+195 and parameters: {'n_estimators': 71, 'learning_rate': 22, 'min_weight_fraction_leaf': 0.42544917951603833, 'max_depth': 18, 'min_impurity_decrease': 264, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:58,434] Trial 151 finished with value: 65321963.811685294 and parameters: {'n_estimators': 57, 'learning_rate': 2, 'min_weight_fraction_leaf': 0.46045913691745116, 'max_depth': 25, 'min_impurity_decrease': 487, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:58,701] Trial 152 finished with value: 61967029.6429315 and parameters: {'n_estimators': 54, 'learning_rate': 2, 'min_weight_fraction_leaf': 0.4558278706485442, 'max_depth': 28, 'min_impurity_decrease': 545, 'min_samples_leaf': 7}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:58,899] Trial 153 finished with value: 2.1300636453624102e+201 and parameters: {'n_estimators': 65, 'learning_rate': 32, 'min_weight_fraction_leaf': 0.4823476636938623, 'max_depth': 25, 'min_impurity_decrease': 458, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:478: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "[I 2024-01-08 20:54:59,077] Trial 154 finished with value: inf and parameters: {'n_estimators': 59, 'learning_rate': 473, 'min_weight_fraction_leaf': 0.43818440715178697, 'max_depth': 24, 'min_impurity_decrease': 504, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:59,248] Trial 155 finished with value: 61967029.64293136 and parameters: {'n_estimators': 47, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.4680798536797217, 'max_depth': 20, 'min_impurity_decrease': 583, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:59,427] Trial 156 finished with value: 8.965793298238203e+207 and parameters: {'n_estimators': 59, 'learning_rate': 51, 'min_weight_fraction_leaf': 0.447956844624706, 'max_depth': 27, 'min_impurity_decrease': 561, 'min_samples_leaf': 7}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:59,566] Trial 157 finished with value: 1.7461652315341022e+76 and parameters: {'n_estimators': 37, 'learning_rate': 23, 'min_weight_fraction_leaf': 0.49858101108190256, 'max_depth': 22, 'min_impurity_decrease': 418, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:59,737] Trial 158 finished with value: 4.010520039274188e+165 and parameters: {'n_estimators': 53, 'learning_rate': 32, 'min_weight_fraction_leaf': 0.41518563860660324, 'max_depth': 21, 'min_impurity_decrease': 660, 'min_samples_leaf': 5}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:54:59,902] Trial 159 finished with value: 1.8679126993885705e+177 and parameters: {'n_estimators': 49, 'learning_rate': 55, 'min_weight_fraction_leaf': 0.3630689703645844, 'max_depth': 16, 'min_impurity_decrease': 528, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:00,096] Trial 160 finished with value: 1.6565020579343123e+153 and parameters: {'n_estimators': 56, 'learning_rate': 21, 'min_weight_fraction_leaf': 0.42961472360521713, 'max_depth': 8, 'min_impurity_decrease': 594, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:00,246] Trial 161 finished with value: 61967029.64293136 and parameters: {'n_estimators': 38, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.40704856556742947, 'max_depth': 23, 'min_impurity_decrease': 528, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:00,411] Trial 162 finished with value: 61967029.64293136 and parameters: {'n_estimators': 40, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.3892601100985011, 'max_depth': 23, 'min_impurity_decrease': 491, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:00,578] Trial 163 finished with value: 9.335960540767636e+110 and parameters: {'n_estimators': 44, 'learning_rate': 16, 'min_weight_fraction_leaf': 0.45515020304428044, 'max_depth': 26, 'min_impurity_decrease': 612, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:00,729] Trial 164 finished with value: 1.1454601205661977e+118 and parameters: {'n_estimators': 35, 'learning_rate': 39, 'min_weight_fraction_leaf': 0.440333562681335, 'max_depth': 30, 'min_impurity_decrease': 565, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:00,920] Trial 165 finished with value: 61967029.64293136 and parameters: {'n_estimators': 30, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.4141140468690736, 'max_depth': 24, 'min_impurity_decrease': 541, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:01,368] Trial 166 finished with value: 5.54153388610806e+159 and parameters: {'n_estimators': 42, 'learning_rate': 66, 'min_weight_fraction_leaf': 0.4767418401370277, 'max_depth': 20, 'min_impurity_decrease': 642, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:01,565] Trial 167 finished with value: 2.1927843472159882e+105 and parameters: {'n_estimators': 37, 'learning_rate': 22, 'min_weight_fraction_leaf': 0.32256224130627714, 'max_depth': 5, 'min_impurity_decrease': 514, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:01,900] Trial 168 finished with value: 1.0151495620733222e+240 and parameters: {'n_estimators': 45, 'learning_rate': 384, 'min_weight_fraction_leaf': 0.37367163617265964, 'max_depth': 6, 'min_impurity_decrease': 470, 'min_samples_leaf': 7}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:02,109] Trial 169 finished with value: 9.249187422595212e+207 and parameters: {'n_estimators': 63, 'learning_rate': 40, 'min_weight_fraction_leaf': 0.4313179823893157, 'max_depth': 19, 'min_impurity_decrease': 586, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:478: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "[I 2024-01-08 20:55:02,355] Trial 170 finished with value: inf and parameters: {'n_estimators': 94, 'learning_rate': 87, 'min_weight_fraction_leaf': 0.34049963801507427, 'max_depth': 22, 'min_impurity_decrease': 437, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:02,525] Trial 171 finished with value: 5.443258438734556e+82 and parameters: {'n_estimators': 32, 'learning_rate': 16, 'min_weight_fraction_leaf': 0.46421535177936246, 'max_depth': 18, 'min_impurity_decrease': 528, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:02,766] Trial 172 finished with value: 61967029.64293136 and parameters: {'n_estimators': 89, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.4614541335237874, 'max_depth': 19, 'min_impurity_decrease': 494, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:03,005] Trial 173 finished with value: 61967029.64293136 and parameters: {'n_estimators': 90, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.48639693479140367, 'max_depth': 20, 'min_impurity_decrease': 509, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:03,154] Trial 174 finished with value: 4.196384117433932e+89 and parameters: {'n_estimators': 26, 'learning_rate': 39, 'min_weight_fraction_leaf': 0.4484307741544479, 'max_depth': 9, 'min_impurity_decrease': 560, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:478: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "[I 2024-01-08 20:55:03,433] Trial 175 finished with value: inf and parameters: {'n_estimators': 85, 'learning_rate': 971, 'min_weight_fraction_leaf': 0.42239305661249626, 'max_depth': 21, 'min_impurity_decrease': 607, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:03,707] Trial 176 finished with value: 9.320757599697075e+263 and parameters: {'n_estimators': 97, 'learning_rate': 22, 'min_weight_fraction_leaf': 0.4764975953430025, 'max_depth': 15, 'min_impurity_decrease': 544, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:478: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "[I 2024-01-08 20:55:03,951] Trial 177 finished with value: inf and parameters: {'n_estimators': 92, 'learning_rate': 50, 'min_weight_fraction_leaf': 0.4055062071198714, 'max_depth': 24, 'min_impurity_decrease': 633, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:04,185] Trial 178 finished with value: 6.734014346457353e+210 and parameters: {'n_estimators': 81, 'learning_rate': 19, 'min_weight_fraction_leaf': 0.4571180587659806, 'max_depth': 17, 'min_impurity_decrease': 576, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:04,508] Trial 179 finished with value: 61967029.64293136 and parameters: {'n_estimators': 78, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.4407240865801137, 'max_depth': 27, 'min_impurity_decrease': 507, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:04,673] Trial 180 finished with value: 6.643296445075723e+143 and parameters: {'n_estimators': 39, 'learning_rate': 57, 'min_weight_fraction_leaf': 0.47137394935662846, 'max_depth': 22, 'min_impurity_decrease': 679, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:04,871] Trial 181 finished with value: 8.258774689707931e+139 and parameters: {'n_estimators': 55, 'learning_rate': 17, 'min_weight_fraction_leaf': 0.4697506202303692, 'max_depth': 28, 'min_impurity_decrease': 602, 'min_samples_leaf': 6}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:05,065] Trial 182 finished with value: 3.717621343189336e+159 and parameters: {'n_estimators': 51, 'learning_rate': 32, 'min_weight_fraction_leaf': 0.4876056412920235, 'max_depth': 25, 'min_impurity_decrease': 592, 'min_samples_leaf': 7}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:05,261] Trial 183 finished with value: 61967029.64293136 and parameters: {'n_estimators': 54, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.4511781484677133, 'max_depth': 30, 'min_impurity_decrease': 622, 'min_samples_leaf': 6}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:05,678] Trial 184 finished with value: 61967029.64293136 and parameters: {'n_estimators': 58, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.46219868603735376, 'max_depth': 10, 'min_impurity_decrease': 557, 'min_samples_leaf': 7}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:05,852] Trial 185 finished with value: 3.774826235122248e+157 and parameters: {'n_estimators': 49, 'learning_rate': 35, 'min_weight_fraction_leaf': 0.43521119505442096, 'max_depth': 23, 'min_impurity_decrease': 652, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:478: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "[I 2024-01-08 20:55:06,537] Trial 186 finished with value: inf and parameters: {'n_estimators': 96, 'learning_rate': 820, 'min_weight_fraction_leaf': 0.42357182753828027, 'max_depth': 32, 'min_impurity_decrease': 573, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:07,052] Trial 187 finished with value: 1.1673515788187259e+138 and parameters: {'n_estimators': 52, 'learning_rate': 19, 'min_weight_fraction_leaf': 0.394691329699122, 'max_depth': 31, 'min_impurity_decrease': 531, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:07,366] Trial 188 finished with value: 1.8519874977711622e+189 and parameters: {'n_estimators': 56, 'learning_rate': 43, 'min_weight_fraction_leaf': 0.47322394850556404, 'max_depth': 32, 'min_impurity_decrease': 607, 'min_samples_leaf': 7}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:07,613] Trial 189 finished with value: 1.2276948988846526e+96 and parameters: {'n_estimators': 36, 'learning_rate': 18, 'min_weight_fraction_leaf': 0.33091964954440917, 'max_depth': 26, 'min_impurity_decrease': 716, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:07,750] Trial 190 finished with value: 1.1512943794624673e+92 and parameters: {'n_estimators': 23, 'learning_rate': 70, 'min_weight_fraction_leaf': 0.44645619004446496, 'max_depth': 20, 'min_impurity_decrease': 473, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:07,920] Trial 191 finished with value: 61967029.64293136 and parameters: {'n_estimators': 50, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.4629162549540714, 'max_depth': 17, 'min_impurity_decrease': 594, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:08,092] Trial 192 finished with value: 3.9557119825875065e+125 and parameters: {'n_estimators': 48, 'learning_rate': 18, 'min_weight_fraction_leaf': 0.45913651275564277, 'max_depth': 18, 'min_impurity_decrease': 582, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:08,324] Trial 193 finished with value: 61967029.64293136 and parameters: {'n_estimators': 50, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.13657412907413188, 'max_depth': 16, 'min_impurity_decrease': 550, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:08,495] Trial 194 finished with value: 8.417253117049745e+145 and parameters: {'n_estimators': 46, 'learning_rate': 33, 'min_weight_fraction_leaf': 0.4845058973980896, 'max_depth': 19, 'min_impurity_decrease': 624, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:08,677] Trial 195 finished with value: 7.974691228829437e+137 and parameters: {'n_estimators': 53, 'learning_rate': 18, 'min_weight_fraction_leaf': 0.44316384813250903, 'max_depth': 17, 'min_impurity_decrease': 596, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:08,856] Trial 196 finished with value: 61967029.64293136 and parameters: {'n_estimators': 33, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.46815302987068746, 'max_depth': 21, 'min_impurity_decrease': 643, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:09,058] Trial 197 finished with value: 2.940585537900516e+149 and parameters: {'n_estimators': 42, 'learning_rate': 50, 'min_weight_fraction_leaf': 0.43232548185233366, 'max_depth': 5, 'min_impurity_decrease': 513, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:09,264] Trial 198 finished with value: 6.2784321113757865e+125 and parameters: {'n_estimators': 38, 'learning_rate': 37, 'min_weight_fraction_leaf': 0.4156246081884217, 'max_depth': 23, 'min_impurity_decrease': 741, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:09,484] Trial 199 finished with value: 3.5818201220701144e+145 and parameters: {'n_estimators': 55, 'learning_rate': 19, 'min_weight_fraction_leaf': 0.4531704009296397, 'max_depth': 13, 'min_impurity_decrease': 573, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:09,726] Trial 200 finished with value: 61967029.64293136 and parameters: {'n_estimators': 27, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.49257307419374347, 'max_depth': 7, 'min_impurity_decrease': 541, 'min_samples_leaf': 7}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:09,957] Trial 201 finished with value: 61967029.64293136 and parameters: {'n_estimators': 57, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.17990811321083228, 'max_depth': 19, 'min_impurity_decrease': 696, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:10,254] Trial 202 finished with value: 1.2960063693638793e+183 and parameters: {'n_estimators': 60, 'learning_rate': 30, 'min_weight_fraction_leaf': 0.0956883886878761, 'max_depth': 18, 'min_impurity_decrease': 655, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:10,498] Trial 203 finished with value: 1.9455689773672347e+147 and parameters: {'n_estimators': 58, 'learning_rate': 17, 'min_weight_fraction_leaf': 0.23247110788626985, 'max_depth': 19, 'min_impurity_decrease': 690, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:10,737] Trial 204 finished with value: 61967029.64293136 and parameters: {'n_estimators': 61, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.2061914849414265, 'max_depth': 21, 'min_impurity_decrease': 713, 'min_samples_leaf': 4}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:10,927] Trial 205 finished with value: 6.045171103835216e+197 and parameters: {'n_estimators': 56, 'learning_rate': 51, 'min_weight_fraction_leaf': 0.3510226101152695, 'max_depth': 20, 'min_impurity_decrease': 615, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:11,167] Trial 206 finished with value: 4.054359763030415e+165 and parameters: {'n_estimators': 52, 'learning_rate': 34, 'min_weight_fraction_leaf': 0.14078896712210215, 'max_depth': 24, 'min_impurity_decrease': 670, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:11,449] Trial 207 finished with value: 8.758984148106567e+129 and parameters: {'n_estimators': 47, 'learning_rate': 21, 'min_weight_fraction_leaf': 0.04703577787362939, 'max_depth': 17, 'min_impurity_decrease': 492, 'min_samples_leaf': 9}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:11,592] Trial 208 finished with value: 8.152456120141275e+63 and parameters: {'n_estimators': 24, 'learning_rate': 16, 'min_weight_fraction_leaf': 0.4755270258071991, 'max_depth': 19, 'min_impurity_decrease': 563, 'min_samples_leaf': 10}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:11,775] Trial 209 finished with value: 4.759809119858288e+185 and parameters: {'n_estimators': 53, 'learning_rate': 49, 'min_weight_fraction_leaf': 0.4621771090944056, 'max_depth': 22, 'min_impurity_decrease': 585, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:11,998] Trial 210 finished with value: 61967029.64293136 and parameters: {'n_estimators': 87, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.3618448161371515, 'max_depth': 6, 'min_impurity_decrease': 524, 'min_samples_leaf': 8}. Best is trial 34 with value: 20210832.022988718.\n",
      "[I 2024-01-08 20:55:12,284] Trial 211 finished with value: 16247555.245700436 and parameters: {'n_estimators': 47, 'learning_rate': 1, 'min_weight_fraction_leaf': 0.26301034222964575, 'max_depth': 20, 'min_impurity_decrease': 582, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:12,482] Trial 212 finished with value: 3.6857125592863494e+130 and parameters: {'n_estimators': 50, 'learning_rate': 18, 'min_weight_fraction_leaf': 0.2538848000988375, 'max_depth': 20, 'min_impurity_decrease': 606, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:12,703] Trial 213 finished with value: 3.0320963709894393e+153 and parameters: {'n_estimators': 48, 'learning_rate': 34, 'min_weight_fraction_leaf': 0.16175008563504367, 'max_depth': 18, 'min_impurity_decrease': 575, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:12,942] Trial 214 finished with value: 3.639132326782784e+235 and parameters: {'n_estimators': 45, 'learning_rate': 342, 'min_weight_fraction_leaf': 0.21362375864000324, 'max_depth': 23, 'min_impurity_decrease': 628, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:13,164] Trial 215 finished with value: 4.628897919870655e+108 and parameters: {'n_estimators': 43, 'learning_rate': 16, 'min_weight_fraction_leaf': 0.26451482348158695, 'max_depth': 25, 'min_impurity_decrease': 548, 'min_samples_leaf': 9}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:13,344] Trial 216 finished with value: 1.0523151642155177e+130 and parameters: {'n_estimators': 40, 'learning_rate': 35, 'min_weight_fraction_leaf': 0.427486875992242, 'max_depth': 21, 'min_impurity_decrease': 595, 'min_samples_leaf': 10}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:13,513] Trial 217 finished with value: 29209328.105708472 and parameters: {'n_estimators': 34, 'learning_rate': 1, 'min_weight_fraction_leaf': 0.40791014477198484, 'max_depth': 19, 'min_impurity_decrease': 561, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:13,702] Trial 218 finished with value: 2.6957472358931755e+127 and parameters: {'n_estimators': 34, 'learning_rate': 59, 'min_weight_fraction_leaf': 0.2856181649765531, 'max_depth': 16, 'min_impurity_decrease': 570, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:13,851] Trial 219 finished with value: 28893142.596913684 and parameters: {'n_estimators': 30, 'learning_rate': 1, 'min_weight_fraction_leaf': 0.4123719594612821, 'max_depth': 20, 'min_impurity_decrease': 544, 'min_samples_leaf': 9}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:14,004] Trial 220 finished with value: 6.842447131163002e+82 and parameters: {'n_estimators': 30, 'learning_rate': 19, 'min_weight_fraction_leaf': 0.40673467770187044, 'max_depth': 22, 'min_impurity_decrease': 528, 'min_samples_leaf': 9}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:14,164] Trial 221 finished with value: 61967029.64293136 and parameters: {'n_estimators': 36, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.38747108048435513, 'max_depth': 20, 'min_impurity_decrease': 542, 'min_samples_leaf': 9}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:14,417] Trial 222 finished with value: 61967029.64293136 and parameters: {'n_estimators': 31, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.4012209164485432, 'max_depth': 18, 'min_impurity_decrease': 562, 'min_samples_leaf': 9}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:14,584] Trial 223 finished with value: 1.0842164669248676e+91 and parameters: {'n_estimators': 28, 'learning_rate': 32, 'min_weight_fraction_leaf': 0.41640697467118926, 'max_depth': 21, 'min_impurity_decrease': 506, 'min_samples_leaf': 9}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:14,748] Trial 224 finished with value: 3.1121947091762333e+87 and parameters: {'n_estimators': 34, 'learning_rate': 16, 'min_weight_fraction_leaf': 0.42196032128382605, 'max_depth': 19, 'min_impurity_decrease': 589, 'min_samples_leaf': 10}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:14,906] Trial 225 finished with value: 1.85085050866386e+86 and parameters: {'n_estimators': 32, 'learning_rate': 18, 'min_weight_fraction_leaf': 0.37716970328882027, 'max_depth': 25, 'min_impurity_decrease': 556, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:15,051] Trial 226 finished with value: 2.734343579378342e+86 and parameters: {'n_estimators': 26, 'learning_rate': 34, 'min_weight_fraction_leaf': 0.4397279870415748, 'max_depth': 22, 'min_impurity_decrease': 610, 'min_samples_leaf': 9}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:15,212] Trial 227 finished with value: 29453924.49448305 and parameters: {'n_estimators': 36, 'learning_rate': 1, 'min_weight_fraction_leaf': 0.4119826394106904, 'max_depth': 28, 'min_impurity_decrease': 525, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:15,364] Trial 228 finished with value: 7.325993711503514e+126 and parameters: {'n_estimators': 37, 'learning_rate': 42, 'min_weight_fraction_leaf': 0.40602999789201194, 'max_depth': 27, 'min_impurity_decrease': 484, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:15,517] Trial 229 finished with value: 61967029.64293136 and parameters: {'n_estimators': 34, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.39718543240335813, 'max_depth': 28, 'min_impurity_decrease': 523, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:15,718] Trial 230 finished with value: 1.6630034854277732e+178 and parameters: {'n_estimators': 68, 'learning_rate': 19, 'min_weight_fraction_leaf': 0.4292379867439759, 'max_depth': 29, 'min_impurity_decrease': 506, 'min_samples_leaf': 7}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:15,873] Trial 231 finished with value: 61967029.64293136 and parameters: {'n_estimators': 36, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.4188229820427216, 'max_depth': 26, 'min_impurity_decrease': 537, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:16,130] Trial 232 finished with value: 1.1044697299755674e+231 and parameters: {'n_estimators': 39, 'learning_rate': 735, 'min_weight_fraction_leaf': 0.41035301252907075, 'max_depth': 24, 'min_impurity_decrease': 582, 'min_samples_leaf': 9}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:16,286] Trial 233 finished with value: 1.8384433533194075e+76 and parameters: {'n_estimators': 30, 'learning_rate': 15, 'min_weight_fraction_leaf': 0.3154222963737572, 'max_depth': 5, 'min_impurity_decrease': 555, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:16,450] Trial 234 finished with value: 61967029.64293136 and parameters: {'n_estimators': 35, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.4553978136280928, 'max_depth': 29, 'min_impurity_decrease': 630, 'min_samples_leaf': 5}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:16,613] Trial 235 finished with value: 1.0206197210262729e+105 and parameters: {'n_estimators': 33, 'learning_rate': 31, 'min_weight_fraction_leaf': 0.410938205353202, 'max_depth': 20, 'min_impurity_decrease': 596, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:16,780] Trial 236 finished with value: 3.3678162843896844e+98 and parameters: {'n_estimators': 37, 'learning_rate': 18, 'min_weight_fraction_leaf': 0.44640844461159446, 'max_depth': 23, 'min_impurity_decrease': 570, 'min_samples_leaf': 9}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:16,921] Trial 237 finished with value: 6.797434747714976e+81 and parameters: {'n_estimators': 22, 'learning_rate': 50, 'min_weight_fraction_leaf': 0.46797445524627546, 'max_depth': 18, 'min_impurity_decrease': 539, 'min_samples_leaf': 6}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:17,125] Trial 238 finished with value: 1.2043768723756902e+128 and parameters: {'n_estimators': 49, 'learning_rate': 18, 'min_weight_fraction_leaf': 0.34218562444748113, 'max_depth': 25, 'min_impurity_decrease': 460, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:17,292] Trial 239 finished with value: 61967029.64293136 and parameters: {'n_estimators': 28, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.39360820574427946, 'max_depth': 32, 'min_impurity_decrease': 523, 'min_samples_leaf': 3}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:17,555] Trial 240 finished with value: 2.6869473016802625e+281 and parameters: {'n_estimators': 91, 'learning_rate': 33, 'min_weight_fraction_leaf': 0.43465502849046717, 'max_depth': 12, 'min_impurity_decrease': 611, 'min_samples_leaf': 10}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:17,767] Trial 241 finished with value: 4.746100200220628e+136 and parameters: {'n_estimators': 58, 'learning_rate': 14, 'min_weight_fraction_leaf': 0.4792119341255735, 'max_depth': 19, 'min_impurity_decrease': 754, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:18,081] Trial 242 finished with value: 29637244.265585463 and parameters: {'n_estimators': 55, 'learning_rate': 1, 'min_weight_fraction_leaf': 0.4189557630915513, 'max_depth': 17, 'min_impurity_decrease': 666, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:18,265] Trial 243 finished with value: 61967029.64293136 and parameters: {'n_estimators': 51, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.41727088232032994, 'max_depth': 17, 'min_impurity_decrease': 644, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:18,473] Trial 244 finished with value: 1.614680277173269e+231 and parameters: {'n_estimators': 75, 'learning_rate': 32, 'min_weight_fraction_leaf': 0.42772185885415226, 'max_depth': 21, 'min_impurity_decrease': 663, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:18,656] Trial 245 finished with value: 3.0587851115381926e+135 and parameters: {'n_estimators': 52, 'learning_rate': 18, 'min_weight_fraction_leaf': 0.404075307061499, 'max_depth': 8, 'min_impurity_decrease': 580, 'min_samples_leaf': 9}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:18,841] Trial 246 finished with value: 61967029.64293136 and parameters: {'n_estimators': 38, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.44752558331851133, 'max_depth': 16, 'min_impurity_decrease': 488, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:19,054] Trial 247 finished with value: 6.757475927297914e+182 and parameters: {'n_estimators': 54, 'learning_rate': 43, 'min_weight_fraction_leaf': 0.4225082479080026, 'max_depth': 17, 'min_impurity_decrease': 627, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:19,200] Trial 248 finished with value: 1.7288346796835137e+70 and parameters: {'n_estimators': 25, 'learning_rate': 19, 'min_weight_fraction_leaf': 0.45800118406884355, 'max_depth': 19, 'min_impurity_decrease': 562, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:19,389] Trial 249 finished with value: 2.194628618712289e+146 and parameters: {'n_estimators': 47, 'learning_rate': 31, 'min_weight_fraction_leaf': 0.43369084226680554, 'max_depth': 15, 'min_impurity_decrease': 600, 'min_samples_leaf': 9}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:19,580] Trial 250 finished with value: 2.2500959338633957e+140 and parameters: {'n_estimators': 54, 'learning_rate': 18, 'min_weight_fraction_leaf': 0.4677839898088634, 'max_depth': 9, 'min_impurity_decrease': 514, 'min_samples_leaf': 10}. Best is trial 211 with value: 16247555.245700436.\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_gb_losses.py:229: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum(sample_weight * ((y - raw_predictions.ravel()) ** 2))\n",
      "C:\\Users\\valentin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:478: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "[I 2024-01-08 20:55:19,820] Trial 251 finished with value: inf and parameters: {'n_estimators': 95, 'learning_rate': 49, 'min_weight_fraction_leaf': 0.4122821997463707, 'max_depth': 26, 'min_impurity_decrease': 542, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:20,085] Trial 252 finished with value: 61967029.64293136 and parameters: {'n_estimators': 35, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.3068164236708757, 'max_depth': 23, 'min_impurity_decrease': 676, 'min_samples_leaf': 9}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:20,256] Trial 253 finished with value: 4.035906523425999e+101 and parameters: {'n_estimators': 40, 'learning_rate': 16, 'min_weight_fraction_leaf': 0.3797695602200716, 'max_depth': 20, 'min_impurity_decrease': 616, 'min_samples_leaf': 7}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:20,416] Trial 254 finished with value: 1.3013061409238938e+123 and parameters: {'n_estimators': 32, 'learning_rate': 65, 'min_weight_fraction_leaf': 0.3976599265748185, 'max_depth': 18, 'min_impurity_decrease': 583, 'min_samples_leaf': 9}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:20,607] Trial 255 finished with value: 3.0485203743327776e+274 and parameters: {'n_estimators': 56, 'learning_rate': 243, 'min_weight_fraction_leaf': 0.33210712669525516, 'max_depth': 24, 'min_impurity_decrease': 647, 'min_samples_leaf': 10}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:20,790] Trial 256 finished with value: 1.5045640456143502e+147 and parameters: {'n_estimators': 46, 'learning_rate': 34, 'min_weight_fraction_leaf': 0.4415190385350276, 'max_depth': 21, 'min_impurity_decrease': 553, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:20,966] Trial 257 finished with value: 61967029.64293136 and parameters: {'n_estimators': 50, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.45711844301482746, 'max_depth': 27, 'min_impurity_decrease': 503, 'min_samples_leaf': 9}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:21,176] Trial 258 finished with value: 1.0067661429665817e+128 and parameters: {'n_estimators': 48, 'learning_rate': 19, 'min_weight_fraction_leaf': 0.3539453235676199, 'max_depth': 30, 'min_impurity_decrease': 567, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:21,384] Trial 259 finished with value: 5.46887621632249e+125 and parameters: {'n_estimators': 38, 'learning_rate': 37, 'min_weight_fraction_leaf': 0.4776317403025711, 'max_depth': 14, 'min_impurity_decrease': 594, 'min_samples_leaf': 9}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:21,584] Trial 260 finished with value: 2.3072762999392756e+108 and parameters: {'n_estimators': 44, 'learning_rate': 15, 'min_weight_fraction_leaf': 0.42430796231862006, 'max_depth': 7, 'min_impurity_decrease': 535, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:21,781] Trial 261 finished with value: 61967029.64293136 and parameters: {'n_estimators': 41, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.4112930373928044, 'max_depth': 22, 'min_impurity_decrease': 632, 'min_samples_leaf': 10}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:22,019] Trial 262 finished with value: 3.0339528493333415e+89 and parameters: {'n_estimators': 24, 'learning_rate': 52, 'min_weight_fraction_leaf': 0.36706942137277093, 'max_depth': 5, 'min_impurity_decrease': 606, 'min_samples_leaf': 7}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:22,181] Trial 263 finished with value: 61967029.64293136 and parameters: {'n_estimators': 30, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.4651235949916794, 'max_depth': 20, 'min_impurity_decrease': 570, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:22,340] Trial 264 finished with value: 7.290570830340727e+115 and parameters: {'n_estimators': 36, 'learning_rate': 33, 'min_weight_fraction_leaf': 0.4351338631454028, 'max_depth': 18, 'min_impurity_decrease': 525, 'min_samples_leaf': 9}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:22,530] Trial 265 finished with value: 7.921954302248698e+152 and parameters: {'n_estimators': 52, 'learning_rate': 26, 'min_weight_fraction_leaf': 0.38728933030788043, 'max_depth': 4, 'min_impurity_decrease': 547, 'min_samples_leaf': 9}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:22,776] Trial 266 finished with value: 1.1963859574100878e+224 and parameters: {'n_estimators': 88, 'learning_rate': 18, 'min_weight_fraction_leaf': 0.42051827296868427, 'max_depth': 17, 'min_impurity_decrease': 731, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:22,935] Trial 267 finished with value: 7.153819744134979e+122 and parameters: {'n_estimators': 33, 'learning_rate': 57, 'min_weight_fraction_leaf': 0.44692744927105765, 'max_depth': 22, 'min_impurity_decrease': 480, 'min_samples_leaf': 10}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:23,121] Trial 268 finished with value: 61967029.64293136 and parameters: {'n_estimators': 54, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.48631854551402015, 'max_depth': 3, 'min_impurity_decrease': 587, 'min_samples_leaf': 9}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:23,275] Trial 269 finished with value: 1.4927591119562242e+90 and parameters: {'n_estimators': 27, 'learning_rate': 35, 'min_weight_fraction_leaf': 0.4536821159071593, 'max_depth': 24, 'min_impurity_decrease': 501, 'min_samples_leaf': 6}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:23,414] Trial 270 finished with value: 61967029.64293136 and parameters: {'n_estimators': 20, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.4742651350220252, 'max_depth': 2, 'min_impurity_decrease': 657, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:23,583] Trial 271 finished with value: 1.0755069247466514e+97 and parameters: {'n_estimators': 35, 'learning_rate': 20, 'min_weight_fraction_leaf': 0.4003476349244365, 'max_depth': 19, 'min_impurity_decrease': 558, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:23,855] Trial 272 finished with value: 1.1962901856775016e+187 and parameters: {'n_estimators': 49, 'learning_rate': 69, 'min_weight_fraction_leaf': 0.43322464060599325, 'max_depth': 10, 'min_impurity_decrease': 619, 'min_samples_leaf': 10}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:24,053] Trial 273 finished with value: 2.1027210813069195e+189 and parameters: {'n_estimators': 56, 'learning_rate': 43, 'min_weight_fraction_leaf': 0.41089378728015635, 'max_depth': 6, 'min_impurity_decrease': 689, 'min_samples_leaf': 9}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:24,229] Trial 274 finished with value: 2.7094723458131186e+105 and parameters: {'n_estimators': 39, 'learning_rate': 19, 'min_weight_fraction_leaf': 0.2732936229783753, 'max_depth': 5, 'min_impurity_decrease': 521, 'min_samples_leaf': 7}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:24,453] Trial 275 finished with value: 7.147111162600771e+224 and parameters: {'n_estimators': 85, 'learning_rate': 20, 'min_weight_fraction_leaf': 0.4646764135319924, 'max_depth': 16, 'min_impurity_decrease': 936, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:24,648] Trial 276 finished with value: 1.0412247373760885e+199 and parameters: {'n_estimators': 59, 'learning_rate': 43, 'min_weight_fraction_leaf': 0.44120758010949135, 'max_depth': 27, 'min_impurity_decrease': 581, 'min_samples_leaf': 9}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:24,824] Trial 277 finished with value: 61967029.64293136 and parameters: {'n_estimators': 46, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.44939659935972687, 'max_depth': 24, 'min_impurity_decrease': 640, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:25,003] Trial 278 finished with value: 1.6971510274836303e+121 and parameters: {'n_estimators': 43, 'learning_rate': 22, 'min_weight_fraction_leaf': 0.42127447579059096, 'max_depth': 20, 'min_impurity_decrease': 833, 'min_samples_leaf': 10}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:25,181] Trial 279 finished with value: 4.40352217262751e+104 and parameters: {'n_estimators': 32, 'learning_rate': 34, 'min_weight_fraction_leaf': 0.47911035368138255, 'max_depth': 11, 'min_impurity_decrease': 594, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:25,392] Trial 280 finished with value: 3.4145400085723688e+162 and parameters: {'n_estimators': 63, 'learning_rate': 18, 'min_weight_fraction_leaf': 0.32186312597700484, 'max_depth': 29, 'min_impurity_decrease': 781, 'min_samples_leaf': 9}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:25,606] Trial 281 finished with value: 61967029.64293136 and parameters: {'n_estimators': 51, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.4028010878726425, 'max_depth': 26, 'min_impurity_decrease': 613, 'min_samples_leaf': 9}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:25,897] Trial 282 finished with value: 9.484452987045749e+203 and parameters: {'n_estimators': 37, 'learning_rate': 453, 'min_weight_fraction_leaf': 0.3406898409191013, 'max_depth': 21, 'min_impurity_decrease': 546, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:26,105] Trial 283 finished with value: 3.1430518985094015e+197 and parameters: {'n_estimators': 53, 'learning_rate': 63, 'min_weight_fraction_leaf': 0.42819303489562893, 'max_depth': 18, 'min_impurity_decrease': 561, 'min_samples_leaf': 10}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:26,264] Trial 284 finished with value: 2.5084025287916674e+103 and parameters: {'n_estimators': 29, 'learning_rate': 46, 'min_weight_fraction_leaf': 0.38821047028651334, 'max_depth': 23, 'min_impurity_decrease': 515, 'min_samples_leaf': 7}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:26,432] Trial 285 finished with value: 1.3952591018547383e+91 and parameters: {'n_estimators': 34, 'learning_rate': 18, 'min_weight_fraction_leaf': 0.45699195006026005, 'max_depth': 19, 'min_impurity_decrease': 450, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:26,584] Trial 286 finished with value: 1.854729069433228e+66 and parameters: {'n_estimators': 25, 'learning_rate': 16, 'min_weight_fraction_leaf': 0.46849193504340436, 'max_depth': 25, 'min_impurity_decrease': 474, 'min_samples_leaf': 9}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:26,797] Trial 287 finished with value: 16989187.221475694 and parameters: {'n_estimators': 48, 'learning_rate': 1, 'min_weight_fraction_leaf': 0.2958406190593572, 'max_depth': 17, 'min_impurity_decrease': 674, 'min_samples_leaf': 10}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:26,988] Trial 288 finished with value: 1.8275696462436458e+150 and parameters: {'n_estimators': 47, 'learning_rate': 34, 'min_weight_fraction_leaf': 0.31251310383408487, 'max_depth': 15, 'min_impurity_decrease': 673, 'min_samples_leaf': 10}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:27,172] Trial 289 finished with value: 61967029.64293136 and parameters: {'n_estimators': 41, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.3307632441457214, 'max_depth': 28, 'min_impurity_decrease': 684, 'min_samples_leaf': 10}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:27,382] Trial 290 finished with value: 6.134862329558216e+157 and parameters: {'n_estimators': 44, 'learning_rate': 52, 'min_weight_fraction_leaf': 0.2558260061529665, 'max_depth': 21, 'min_impurity_decrease': 699, 'min_samples_leaf': 10}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:27,542] Trial 291 finished with value: 3.2674995022410722e+72 and parameters: {'n_estimators': 22, 'learning_rate': 31, 'min_weight_fraction_leaf': 0.29526492377582586, 'max_depth': 32, 'min_impurity_decrease': 712, 'min_samples_leaf': 10}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:27,831] Trial 292 finished with value: 61967029.64293136 and parameters: {'n_estimators': 99, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.291660110930971, 'max_depth': 22, 'min_impurity_decrease': 631, 'min_samples_leaf': 10}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:28,110] Trial 293 finished with value: 7.011911775035383e+145 and parameters: {'n_estimators': 37, 'learning_rate': 75, 'min_weight_fraction_leaf': 0.3003294482982015, 'max_depth': 8, 'min_impurity_decrease': 493, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:28,332] Trial 294 finished with value: 4.806560928040105e+296 and parameters: {'n_estimators': 58, 'learning_rate': 312, 'min_weight_fraction_leaf': 0.2677915098681684, 'max_depth': 19, 'min_impurity_decrease': 532, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:28,553] Trial 295 finished with value: 4.6224790049829106e+160 and parameters: {'n_estimators': 61, 'learning_rate': 19, 'min_weight_fraction_leaf': 0.2839483231898428, 'max_depth': 17, 'min_impurity_decrease': 643, 'min_samples_leaf': 10}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:28,744] Trial 296 finished with value: 61967029.64293136 and parameters: {'n_estimators': 55, 'learning_rate': 0, 'min_weight_fraction_leaf': 0.3479830278093764, 'max_depth': 20, 'min_impurity_decrease': 667, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:28,984] Trial 297 finished with value: 2.0463592552691406e+289 and parameters: {'n_estimators': 92, 'learning_rate': 35, 'min_weight_fraction_leaf': 0.4155674510933839, 'max_depth': 23, 'min_impurity_decrease': 573, 'min_samples_leaf': 8}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:29,168] Trial 298 finished with value: 3.0085547877778286e+120 and parameters: {'n_estimators': 45, 'learning_rate': 19, 'min_weight_fraction_leaf': 0.4275584733834793, 'max_depth': 25, 'min_impurity_decrease': 656, 'min_samples_leaf': 7}. Best is trial 211 with value: 16247555.245700436.\n",
      "[I 2024-01-08 20:55:29,348] Trial 299 finished with value: 4.353859687607489e+127 and parameters: {'n_estimators': 35, 'learning_rate': 53, 'min_weight_fraction_leaf': 0.36934235603686005, 'max_depth': 18, 'min_impurity_decrease': 543, 'min_samples_leaf': 10}. Best is trial 211 with value: 16247555.245700436.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Meilleurs Paramètres: {'n_estimators': 47, 'learning_rate': 1, 'min_weight_fraction_leaf': 0.26301034222964575, 'max_depth': 20, 'min_impurity_decrease': 582, 'min_samples_leaf': 8}\n",
      "Mean Squared Error: 4866947.071349802\n",
      "R-squared: 0.9233677583620897\n",
      "\n",
      " Importance des variables :\n",
      "                 195         200       201       198               199       202                161         196        197             166        194             158         203        192       193              188          2            3                184              157            162        191                     132                            127                             128                            129                      130                     131                     134                    133                       135                                   136                          137                        138                           139                    126                               141                              142                        140                    118                            125                              124                   105                    106               107                 108                109             110                  111                 112                113                114                115                    116                     117                  144                       119                                120                     121                          122                               123                        143             155                      145                  146             172              173              174               175                   176                  177                  178                 179                   180                    181                 182              183              185             186             187              189              190           171               170              169           154                147                148                  149                   150                151                152              153                      103                  168               156                  159              160            163             164             165                   167                    104           0             1                          39                     29                        30                             31                           32                           33                       34                          35                            36                                 37                  38                         40                         101                    41                    42                         43                       44                   45                          46                        47                           48                        49                     50                     28                                       27                               26                                25           4            5                     6                                 7                           8                            9                    10                  11                 12                 13                           14                15                16              17              18              19              20              21                     22                                23                             24                    51                           52                  53                   78                   80                    81                    82                   83                   84                    85                   86                    87                    88                    89                   90                   91                        92                                 93                     94                        95                       96                                97                         98                                      99                        100                  79                   77                 54                      76                 55                 56                        57                 58                 59                 60                   61                        62                          63                        64                  65                     66                       67                      68                     69                         70                         71                            72                          73                            74                         75                      102\n",
      "Variable  curbweight  horsepower   peakrpm    stroke  compressionratio   citympg  carbody_hatchback  enginesize  boreratio  drivewheel_rwd  carheight  doornumber_two  highwaympg  carlength  carwidth  fuelsystem_mpfi  symboling_0  symboling_1  fuelsystem_2bbl  doornumber_four  carbody_sedan  wheelbase  CarName_toyota starlet  CarName_toyota corona hardtop  CarName_toyota corona liftback  CarName_toyota corona mark ii  CarName_toyota cressida  CarName_toyota mark ii  CarName_toyouta tercel  CarName_toyota tercel  CarName_vokswagen rabbit  CarName_volkswagen 1131 deluxe sedan  CarName_volkswagen 411 (sw)  CarName_volkswagen dasher  CarName_volkswagen model 111  CarName_toyota corona  CarName_volkswagen rabbit custom  CarName_volkswagen super beetle  CarName_volkswagen rabbit  CarName_toyota carina  CarName_toyota corolla tercel  CarName_toyota corolla liftback  CarName_renault 12tl  CarName_renault 5 gtl  CarName_saab 99e  CarName_saab 99gle  CarName_saab 99le  CarName_subaru  CarName_subaru baja  CarName_subaru brz  CarName_subaru dl  CarName_subaru r1  CarName_subaru r2  CarName_subaru trezia  CarName_subaru tribeca  CarName_volvo 144ea  CarName_toyota celica gt  CarName_toyota celica gt liftback  CarName_toyota corolla  CarName_toyota corolla 1200  CarName_toyota corolla 1600 (sw)  CarName_volkswagen type 3  aspiration_std  CarName_volvo 145e (sw)  CarName_volvo 244dl  enginetype_ohc  enginetype_ohcf  enginetype_ohcv  enginetype_rotor  cylindernumber_eight  cylindernumber_five  cylindernumber_four  cylindernumber_six  cylindernumber_three  cylindernumber_twelve  cylindernumber_two  fuelsystem_1bbl  fuelsystem_4bbl  fuelsystem_idi  fuelsystem_mfi  fuelsystem_spdi  fuelsystem_spfi  enginetype_l  enginetype_dohcv  enginetype_dohc  fueltype_gas  CarName_volvo 245  CarName_volvo 246  CarName_volvo 264gl  CarName_volvo diesel  CarName_vw dasher  CarName_vw rabbit  fueltype_diesel  CarName_porsche cayenne  enginelocation_rear  aspiration_turbo  carbody_convertible  carbody_hardtop  carbody_wagon  drivewheel_4wd  drivewheel_fwd  enginelocation_front  CarName_porsche macan  symboling_-2  symboling_-1  CarName_dodge dart custom  CarName_buick skylark  CarName_chevrolet impala  CarName_chevrolet monte carlo  CarName_chevrolet vega 2300  CarName_dodge challenger se  CarName_dodge colt (sw)  CarName_dodge colt hardtop  CarName_dodge coronet custom  CarName_dodge coronet custom (sw)  CarName_dodge d200  CarName_dodge monaco (sw)  CarName_porcshce panamera  CarName_dodge rampage  CarName_honda accord  CarName_honda accord cvcc  CarName_honda accord lx  CarName_honda civic  CarName_honda civic (auto)  CarName_honda civic 1300  CarName_honda civic 1500 gl  CarName_honda civic cvcc  CarName_honda prelude  CarName_buick skyhawk  CarName_buick regal sport coupe (turbo)  CarName_buick opel isuzu deluxe  CarName_buick electra 225 custom  symboling_2  symboling_3  CarName_Nissan versa  CarName_alfa-romero Quadrifoglio  CarName_alfa-romero giulia  CarName_alfa-romero stelvio  CarName_audi 100 ls  CarName_audi 100ls  CarName_audi 4000  CarName_audi 5000  CarName_audi 5000s (diesel)  CarName_audi fox  CarName_bmw 320i  CarName_bmw x1  CarName_bmw x3  CarName_bmw x4  CarName_bmw x5  CarName_bmw z4  CarName_buick century  CarName_buick century luxus (sw)  CarName_buick century special  CarName_isuzu D-Max   CarName_isuzu D-Max V-Cross  CarName_isuzu MU-X  CarName_nissan fuga  CarName_nissan juke  CarName_nissan kicks  CarName_nissan latio  CarName_nissan leaf  CarName_nissan note  CarName_nissan nv200  CarName_nissan otti  CarName_nissan rogue  CarName_nissan teana  CarName_nissan titan  CarName_peugeot 304  CarName_peugeot 504  CarName_peugeot 504 (sw)  CarName_peugeot 505s turbo diesel  CarName_peugeot 604sl  CarName_plymouth cricket  CarName_plymouth duster  CarName_plymouth fury gran sedan  CarName_plymouth fury iii  CarName_plymouth satellite custom (sw)  CarName_plymouth valiant  CarName_nissan gt-r  CarName_nissan dayz  CarName_jaguar xf  CarName_nissan clipper  CarName_jaguar xj  CarName_jaguar xk  CarName_maxda glc deluxe  CarName_maxda rx3  CarName_mazda 626  CarName_mazda glc  CarName_mazda glc 4  CarName_mazda glc custom  CarName_mazda glc custom l  CarName_mazda glc deluxe  CarName_mazda rx-4  CarName_mazda rx-7 gs  CarName_mazda rx2 coupe  CarName_mercury cougar  CarName_mitsubishi g4  CarName_mitsubishi lancer  CarName_mitsubishi mirage  CarName_mitsubishi mirage g4  CarName_mitsubishi montero  CarName_mitsubishi outlander  CarName_mitsubishi pajero  CarName_porsche boxter\n",
      "Poids       0.649198    0.072761  0.051242  0.046867          0.029518  0.023342           0.023065     0.02212   0.015355         0.01487   0.012516        0.008327    0.008254   0.006736  0.003567         0.002872     0.002837      0.00283         0.001345         0.001075       0.000662   0.000645                     0.0                            0.0                             0.0                            0.0                      0.0                     0.0                     0.0                    0.0                       0.0                                   0.0                          0.0                        0.0                           0.0                    0.0                               0.0                              0.0                        0.0                    0.0                            0.0                              0.0                   0.0                    0.0               0.0                 0.0                0.0             0.0                  0.0                 0.0                0.0                0.0                0.0                    0.0                     0.0                  0.0                       0.0                                0.0                     0.0                          0.0                               0.0                        0.0             0.0                      0.0                  0.0             0.0              0.0              0.0               0.0                   0.0                  0.0                  0.0                 0.0                   0.0                    0.0                 0.0              0.0              0.0             0.0             0.0              0.0              0.0           0.0               0.0              0.0           0.0                0.0                0.0                  0.0                   0.0                0.0                0.0              0.0                      0.0                  0.0               0.0                  0.0              0.0            0.0             0.0             0.0                   0.0                    0.0           0.0           0.0                        0.0                    0.0                       0.0                            0.0                          0.0                          0.0                      0.0                         0.0                           0.0                                0.0                 0.0                        0.0                        0.0                    0.0                   0.0                        0.0                      0.0                  0.0                         0.0                       0.0                          0.0                       0.0                    0.0                    0.0                                      0.0                              0.0                               0.0          0.0          0.0                   0.0                               0.0                         0.0                          0.0                  0.0                 0.0                0.0                0.0                          0.0               0.0               0.0             0.0             0.0             0.0             0.0             0.0                    0.0                               0.0                            0.0                   0.0                          0.0                 0.0                  0.0                  0.0                   0.0                   0.0                  0.0                  0.0                   0.0                  0.0                   0.0                   0.0                   0.0                  0.0                  0.0                       0.0                                0.0                    0.0                       0.0                      0.0                               0.0                        0.0                                     0.0                       0.0                  0.0                  0.0                0.0                     0.0                0.0                0.0                       0.0                0.0                0.0                0.0                  0.0                       0.0                         0.0                       0.0                 0.0                    0.0                      0.0                     0.0                    0.0                        0.0                        0.0                           0.0                         0.0                           0.0                        0.0                     0.0\n"
     ]
    }
   ],
   "source": [
    "# Définition de la fonction objectif pour Optuna\n",
    "def objectif(trial):\n",
    "    # Définition de l'espace de recherche des hyperparamètres\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 100),\n",
    "        'learning_rate': trial.suggest_int('learning_rate', 0, 1000),\n",
    "        'min_weight_fraction_leaf': trial.suggest_float('min_weight_fraction_leaf', 0.0, 0.5),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 32, log=True),\n",
    "        'min_impurity_decrease': trial.suggest_int('min_impurity_decrease', 0, 1000),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "    }\n",
    "\n",
    "    # Création du modèle avec les hyperparamètres choisis\n",
    "    model = GradientBoostingRegressor(**params)\n",
    "\n",
    "    # Entraînement du modèle\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Prédictions sur l'ensemble de validation\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Retourne la MSE négative car Optuna cherche à minimiser l'objectif\n",
    "    return mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Création d'une étude Optuna pour minimiser la MSE\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objectif, n_trials=300)\n",
    "\n",
    "# Récupération des meilleurs paramètres de l'étude\n",
    "meilleurs_params = study.best_params\n",
    "meilleur_trial = study.best_trial\n",
    "\n",
    "print('\\n')\n",
    "print(\"Meilleurs Paramètres:\", meilleurs_params)\n",
    "\n",
    "# Création d'un modèle avec les hyperparamètres optimaux\n",
    "meilleur_model = GradientBoostingRegressor(**meilleurs_params)\n",
    "meilleur_model.fit(X_processed, y)\n",
    "y_pred = meilleur_model.predict(X)\n",
    "\n",
    "# Calcul du MSE et du R2 avec les hyperparamètres optimaux\n",
    "mseGBR = mean_squared_error(y, y_pred)\n",
    "r2GBR = r2_score(y, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mseGBR)\n",
    "print(\"R-squared:\", r2GBR)\n",
    "\n",
    "# Accéder aux poids des différentes variables\n",
    "importances = meilleur_model.feature_importances_\n",
    "\n",
    "# Créer une liste des noms de variables\n",
    "noms_variables = list(X_train.columns) \n",
    "\n",
    "# Associer les poids aux noms de variables\n",
    "importance_df = pd.DataFrame({'Variable': X_train.columns, 'Poids': importances})\n",
    "importance_df = importance_df.sort_values('Poids', ascending=False)\n",
    "\n",
    "# Afficher les poids des différentes variables\n",
    "print(\"\\n Importances des variables :\")\n",
    "importance=importance_df.T\n",
    "print(importance.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_n_estimators_RandomForest = best_hyperparameters['n_estimators']\n",
    "best_max_depth_RandomForest = best_hyperparameters['max_depth']\n",
    "best_min_samples_RandomForest = best_hyperparameters['min_samples_split']\n",
    "best_min_samples_leaf_RandomForest = best_hyperparameters['min_samples_leaf']\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "\n",
    "def plot_GradientBoosting(axs_row, axs_col, name_hyperparameter):\n",
    "    mse_scores_fixed_parameter = []\n",
    "    for i in range(len(hyperparameters[name_hyperparameter])):\n",
    "        if name_hyperparameter=='n_estimators':\n",
    "            fixed_n_estimators_model_RandomForest= RandomForestRegressor(n_estimators=hyperparameters[name_hyperparameter][i],\n",
    "                                                                        max_depth=best_max_depth_RandomForest,\n",
    "                                                                        min_samples_split=best_min_samples_RandomForest,\n",
    "                                                                        min_samples_leaf=best_min_samples_leaf_RandomForest)        \n",
    "        if name_hyperparameter=='max_depth':\n",
    "            fixed_n_estimators_model_RandomForest= RandomForestRegressor(n_estimators=best_n_estimators_RandomForest,\n",
    "                                                                        max_depth=hyperparameters[name_hyperparameter][i],\n",
    "                                                                        min_samples_split=best_min_samples_RandomForest,\n",
    "                                                                        min_samples_leaf=best_min_samples_leaf_RandomForest)\n",
    "        if name_hyperparameter=='min_samples_split':\n",
    "            fixed_n_estimators_model_RandomForest= RandomForestRegressor(n_estimators=best_n_estimators_RandomForest,\n",
    "                                                                        max_depth=best_max_depth_RandomForest,\n",
    "                                                                        min_samples_split=hyperparameters[name_hyperparameter][i],\n",
    "                                                                        min_samples_leaf=best_min_samples_leaf_RandomForest)\n",
    "        if name_hyperparameter=='min_samples_leaf':\n",
    "            fixed_n_estimators_model_RandomForest= RandomForestRegressor(n_estimators=best_n_estimators_RandomForest,\n",
    "                                                                        max_depth=best_max_depth_RandomForest,\n",
    "                                                                        min_samples_split=best_min_samples_RandomForest,\n",
    "                                                                        min_samples_leaf=hyperparameters[name_hyperparameter][i])\n",
    "\n",
    "\n",
    "        fixed_n_estimators_model_RandomForest.fit(X_train, y_train)\n",
    "        y_pred_en = fixed_n_estimators_model_RandomForest.predict(X_test)\n",
    "        mse_dot = mean_squared_error(y_test, y_pred_en)\n",
    "        mse_scores_fixed_parameter.append(mse_dot)\n",
    "\n",
    "    axs[axs_row, axs_col].scatter(hyperparameters[name_hyperparameter], mse_scores_fixed_parameter, marker='o')\n",
    "    axs[axs_row, axs_col].plot(study_rf.best_params[name_hyperparameter], best_mse_RandomForest, marker='o', markersize=8, color='red')\n",
    "    axs[axs_row, axs_col].set_title('Evolution du MSE')\n",
    "    axs[axs_row, axs_col].set_xlabel(name_hyperparameter)\n",
    "    axs[axs_row, axs_col].set_ylabel('MSE')\n",
    "\n",
    "plot_RandomForest(0, 0, 'n_estimators')\n",
    "plot_RandomForest(0, 1, 'max_depth')    \n",
    "plot_RandomForest(1, 0, 'min_samples_split')\n",
    "plot_RandomForest(1, 1, 'min_samples_leaf')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoostRegressor\n",
    "CatBoostRegressor est un modèle particulièrement adapté à des problèmes de régression contenant des variables catégorielles et quantitatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 21:28:35,703] A new study created in memory with name: no-name-4f81e339-d9d6-48fb-9cb8-62b5abe70ad2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 21:28:39,178] Trial 0 finished with value: 7161787.11179911 and parameters: {'learning_rate': 0.18650950507581307, 'depth': 6, 'iterations': 714, 'l2_leaf_reg': 2.677381095912822, 'subsample': 0.7334593759295236, 'colsample_bylevel': 0.5488687837312108, 'min_child_samples': 2, 'max_bin': 74}. Best is trial 0 with value: 7161787.11179911.\n",
      "[I 2024-01-08 21:28:51,652] Trial 1 finished with value: 8635435.653597271 and parameters: {'learning_rate': 0.2887649657001422, 'depth': 9, 'iterations': 367, 'l2_leaf_reg': 7.996227231601804, 'subsample': 0.776656525392297, 'colsample_bylevel': 0.9601032952152264, 'min_child_samples': 3, 'max_bin': 189}. Best is trial 0 with value: 7161787.11179911.\n",
      "[I 2024-01-08 21:28:54,127] Trial 2 finished with value: 5420505.755720176 and parameters: {'learning_rate': 0.29216136981894053, 'depth': 7, 'iterations': 303, 'l2_leaf_reg': 7.7248879537921225, 'subsample': 0.6831629104634096, 'colsample_bylevel': 0.8563954493410182, 'min_child_samples': 4, 'max_bin': 131}. Best is trial 2 with value: 5420505.755720176.\n",
      "[I 2024-01-08 21:29:13,221] Trial 3 finished with value: 13243895.839157505 and parameters: {'learning_rate': 0.0753825619346782, 'depth': 13, 'iterations': 121, 'l2_leaf_reg': 2.3189144368888437, 'subsample': 0.5156072588229789, 'colsample_bylevel': 0.6180197932201401, 'min_child_samples': 2, 'max_bin': 119}. Best is trial 2 with value: 5420505.755720176.\n",
      "[I 2024-01-08 21:31:42,864] Trial 4 finished with value: 8964074.170131734 and parameters: {'learning_rate': 0.0538281542359682, 'depth': 13, 'iterations': 760, 'l2_leaf_reg': 4.012333187760418, 'subsample': 0.5235635187064813, 'colsample_bylevel': 0.9235319269094285, 'min_child_samples': 4, 'max_bin': 59}. Best is trial 2 with value: 5420505.755720176.\n",
      "[I 2024-01-08 21:31:43,578] Trial 5 finished with value: 6256000.1318499455 and parameters: {'learning_rate': 0.28576904826938637, 'depth': 5, 'iterations': 225, 'l2_leaf_reg': 7.84521483602693, 'subsample': 0.705392678401806, 'colsample_bylevel': 0.5280309580672904, 'min_child_samples': 6, 'max_bin': 56}. Best is trial 2 with value: 5420505.755720176.\n",
      "[I 2024-01-08 21:38:58,042] Trial 6 finished with value: 10824792.95118685 and parameters: {'learning_rate': 0.2520121389908178, 'depth': 15, 'iterations': 561, 'l2_leaf_reg': 4.644133391268588, 'subsample': 0.8127621442152309, 'colsample_bylevel': 0.5089532400537017, 'min_child_samples': 5, 'max_bin': 248}. Best is trial 2 with value: 5420505.755720176.\n",
      "[I 2024-01-08 21:40:15,555] Trial 7 finished with value: 7579283.302723638 and parameters: {'learning_rate': 0.2049947042420704, 'depth': 12, 'iterations': 648, 'l2_leaf_reg': 2.471046718715417, 'subsample': 0.8694597129546522, 'colsample_bylevel': 0.8920009798716735, 'min_child_samples': 7, 'max_bin': 68}. Best is trial 2 with value: 5420505.755720176.\n",
      "[I 2024-01-08 21:40:44,906] Trial 8 finished with value: 10455770.873249914 and parameters: {'learning_rate': 0.2409899417952511, 'depth': 11, 'iterations': 540, 'l2_leaf_reg': 2.286498220386912, 'subsample': 0.9425813931215944, 'colsample_bylevel': 0.8688332517754749, 'min_child_samples': 10, 'max_bin': 181}. Best is trial 2 with value: 5420505.755720176.\n",
      "[I 2024-01-08 21:40:45,406] Trial 9 finished with value: 8492471.944164105 and parameters: {'learning_rate': 0.029828329450009093, 'depth': 5, 'iterations': 137, 'l2_leaf_reg': 4.2219866375648305, 'subsample': 0.969372235354043, 'colsample_bylevel': 0.9183922675445892, 'min_child_samples': 10, 'max_bin': 119}. Best is trial 2 with value: 5420505.755720176.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Meilleurs Paramètres: {'learning_rate': 0.29216136981894053, 'depth': 7, 'iterations': 303, 'l2_leaf_reg': 7.7248879537921225, 'subsample': 0.6831629104634096, 'colsample_bylevel': 0.8563954493410182, 'min_child_samples': 4, 'max_bin': 131}\n",
      "Mean Squared Error: 5420505.755720176\n",
      "R-squared: 0.912119573513878\n",
      "\n",
      " Importances des variables :\n",
      "                 196                  178         195       193        191               156         200             166       201        197          5         202       198              188              169             172        194                161          2                184                  159         203        192               199              183            163           0                      181            162               175             186          4                160                 179                         8            3                  55                                25                      132                  90                     116                 182                  149           171                      145             21                    167             155                  91                   144              173                      130                             128                54                 147                                93                      131           1                             72                16                         101             158                          48                 114             165                        140                  45                           9                          39                 59                   146              157                  177                    126                   150                        143                60               189               107                148                       49                        92                        57                    87                  38               174                     76                    85                   84                    89                           122                                120                58                        95                       96                     50                       103                    94                   61                             129                     121                113                 53                        47                            139                  10               185                152                              142                               141                151                                      27               153             18                    6                                 7                   11                 12                 13                           14                15               190             187             17                    180           154             19                    176             20                170                  168                        138             164                               23                             24                               26                     22                 115                          137                   51                            74                          73                         71                         70                     69                      68                       67                     66                  65                        64                          63                        62                 56                           52                          46                                    136                      44                         43                    42                     41                         40                                 37                            36                          35                       34                           33                           32                             31                        30                     29                         75                   77                   78                   79                        135                     134                    133                            127                            125                              124                               123                       119                    118                     117                    28                  112                  111             110                109                 108                    106                   105                    104                       100                                     99                         98                                97                    88                   86                   83                    82                    81                   80                      102\n",
      "Variable  enginesize  cylindernumber_four  curbweight  carwidth  wheelbase  aspiration_turbo  horsepower  drivewheel_rwd   peakrpm  boreratio  symboling_3   citympg    stroke  fuelsystem_mpfi  enginetype_dohc  enginetype_ohc  carheight  carbody_hatchback  symboling_0  fuelsystem_2bbl  carbody_convertible  highwaympg  carlength  compressionratio  fuelsystem_1bbl  carbody_wagon  symboling_-2  cylindernumber_twelve  carbody_sedan  enginetype_rotor  fuelsystem_idi  symboling_2  carbody_hardtop  cylindernumber_six  CarName_alfa-romero giulia  symboling_1  CarName_jaguar xj  CarName_buick electra 225 custom  CarName_toyota starlet  CarName_peugeot 304  CarName_subaru trezia  cylindernumber_two  CarName_volvo 264gl  enginetype_l  CarName_volvo 145e (sw)  CarName_bmw z4  enginelocation_front  aspiration_std  CarName_peugeot 504  CarName_volvo 144ea  enginetype_ohcf  CarName_toyota cressida  CarName_toyota corona liftback  CarName_jaguar xf  CarName_volvo 245  CarName_peugeot 505s turbo diesel  CarName_toyota mark ii  symboling_-1  CarName_mitsubishi mirage g4  CarName_bmw 320i  CarName_porcshce panamera  doornumber_two  CarName_honda civic 1500 gl  CarName_subaru r1  drivewheel_fwd  CarName_volkswagen rabbit  CarName_honda civic  CarName_alfa-romero stelvio  CarName_dodge dart custom  CarName_mazda 626  CarName_volvo 244dl  doornumber_four  cylindernumber_five  CarName_toyota corona  CarName_volvo diesel  CarName_volkswagen type 3  CarName_mazda glc  fuelsystem_spdi  CarName_saab 99e  CarName_volvo 246  CarName_honda civic cvcc  CarName_peugeot 504 (sw)  CarName_maxda glc deluxe  CarName_nissan rogue  CarName_dodge d200  enginetype_ohcv  CarName_nissan clipper  CarName_nissan nv200  CarName_nissan note  CarName_nissan titan  CarName_toyota corolla 1200  CarName_toyota celica gt liftback  CarName_maxda rx3  CarName_plymouth cricket  CarName_plymouth duster  CarName_honda prelude  CarName_porsche cayenne  CarName_peugeot 604sl  CarName_mazda glc 4  CarName_toyota corona mark ii  CarName_toyota corolla  CarName_subaru dl  CarName_isuzu MU-X  CarName_honda civic 1300  CarName_volkswagen model 111  CarName_audi 100 ls  fuelsystem_4bbl  CarName_vw rabbit  CarName_volkswagen super beetle  CarName_volkswagen rabbit custom  CarName_vw dasher  CarName_buick regal sport coupe (turbo)  fueltype_diesel  CarName_bmw x3  CarName_Nissan versa  CarName_alfa-romero Quadrifoglio  CarName_audi 100ls  CarName_audi 4000  CarName_audi 5000  CarName_audi 5000s (diesel)  CarName_audi fox  fuelsystem_spfi  fuelsystem_mfi  CarName_bmw x1  cylindernumber_three  fueltype_gas  CarName_bmw x4  cylindernumber_eight  CarName_bmw x5  enginetype_dohcv  enginelocation_rear  CarName_volkswagen dasher  drivewheel_4wd  CarName_buick century luxus (sw)  CarName_buick century special  CarName_buick opel isuzu deluxe  CarName_buick century  CarName_subaru r2  CarName_volkswagen 411 (sw)  CarName_isuzu D-Max   CarName_mitsubishi outlander  CarName_mitsubishi montero  CarName_mitsubishi mirage  CarName_mitsubishi lancer  CarName_mitsubishi g4  CarName_mercury cougar  CarName_mazda rx2 coupe  CarName_mazda rx-7 gs  CarName_mazda rx-4  CarName_mazda glc deluxe  CarName_mazda glc custom l  CarName_mazda glc custom  CarName_jaguar xk  CarName_isuzu D-Max V-Cross  CarName_honda civic (auto)  CarName_volkswagen 1131 deluxe sedan  CarName_honda accord lx  CarName_honda accord cvcc  CarName_honda accord  CarName_dodge rampage  CarName_dodge monaco (sw)  CarName_dodge coronet custom (sw)  CarName_dodge coronet custom  CarName_dodge colt hardtop  CarName_dodge colt (sw)  CarName_dodge challenger se  CarName_chevrolet vega 2300  CarName_chevrolet monte carlo  CarName_chevrolet impala  CarName_buick skylark  CarName_mitsubishi pajero  CarName_nissan dayz  CarName_nissan fuga  CarName_nissan gt-r  CarName_vokswagen rabbit  CarName_toyouta tercel  CarName_toyota tercel  CarName_toyota corona hardtop  CarName_toyota corolla tercel  CarName_toyota corolla liftback  CarName_toyota corolla 1600 (sw)  CarName_toyota celica gt  CarName_toyota carina  CarName_subaru tribeca  CarName_buick skyhawk  CarName_subaru brz  CarName_subaru baja  CarName_subaru  CarName_saab 99le  CarName_saab 99gle  CarName_renault 5 gtl  CarName_renault 12tl  CarName_porsche macan  CarName_plymouth valiant  CarName_plymouth satellite custom (sw)  CarName_plymouth fury iii  CarName_plymouth fury gran sedan  CarName_nissan teana  CarName_nissan otti  CarName_nissan leaf  CarName_nissan latio  CarName_nissan kicks  CarName_nissan juke  CarName_porsche boxter\n",
      "Poids      33.898863            11.172475   10.930928  8.247481   6.439102           4.05287    3.347155        2.780321  2.621054    2.61609     2.309926  1.542295  1.280625         1.161032         1.150775        0.763232   0.721417           0.689724     0.530019         0.417171             0.365612    0.346149   0.276947           0.24219         0.217434       0.215509      0.193563               0.159565       0.117695          0.104231        0.092738     0.077138         0.072912            0.068711                    0.056681      0.05581           0.052142                          0.048525                0.048127             0.042793               0.042348             0.03159             0.029631      0.029381                 0.029266        0.022159              0.022057         0.02199             0.021719               0.0211         0.013182                 0.013172                        0.012918           0.012753            0.01243                           0.011898                0.011117      0.010794                      0.009628          0.009143                   0.008614         0.00821                     0.007308           0.007047        0.006224                   0.005893             0.003566                     0.003343                   0.002892            0.00289             0.002719         0.002378             0.002345               0.002046              0.002043                   0.001917            0.00167         0.001582          0.001415           0.001266                  0.001062                  0.000861                  0.000837              0.000833             0.00072         0.000603                0.000559              0.000514             0.000442              0.000429                     0.000313                           0.000289           0.000281                  0.000238                 0.000229               0.000211                  0.00015               0.000141             0.000134                         0.0001                0.000099           0.000094            0.000083                  0.000051                      0.000028             0.000016         0.000011                0.0                              0.0                               0.0                0.0                                      0.0              0.0             0.0                   0.0                               0.0                 0.0                0.0                0.0                          0.0               0.0              0.0             0.0             0.0                   0.0           0.0             0.0                   0.0             0.0               0.0                  0.0                        0.0             0.0                               0.0                            0.0                              0.0                    0.0                0.0                          0.0                   0.0                           0.0                         0.0                        0.0                        0.0                    0.0                     0.0                      0.0                    0.0                 0.0                       0.0                         0.0                       0.0                0.0                          0.0                         0.0                                   0.0                      0.0                        0.0                   0.0                    0.0                        0.0                                0.0                           0.0                         0.0                      0.0                          0.0                          0.0                            0.0                       0.0                    0.0                        0.0                  0.0                  0.0                  0.0                       0.0                     0.0                    0.0                            0.0                            0.0                              0.0                               0.0                       0.0                    0.0                     0.0                    0.0                 0.0                  0.0             0.0                0.0                 0.0                    0.0                   0.0                    0.0                       0.0                                     0.0                        0.0                               0.0                   0.0                  0.0                  0.0                   0.0                   0.0                  0.0                     0.0\n"
     ]
    }
   ],
   "source": [
    "# Définition de la fonction objectif pour Optuna\n",
    "def objectif(trial):\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'depth': trial.suggest_int('depth', 1, 16),\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1.0, 10.0),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.5, 1.0),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 10),\n",
    "        'max_bin': trial.suggest_int('max_bin', 2, 255),\n",
    "    }\n",
    "\n",
    "    # Création du CatBoostRegressor avec les hyperparamètres suggérés\n",
    "    model = CatBoostRegressor(**params, silent=True)\n",
    "    \n",
    "    # Entraînement du modèle\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calcul des prédictions et de la métrique d'évaluation (MSE dans ce cas)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    return mse  # Retourne la métrique à optimiser (minimiser)\n",
    "\n",
    "study = optuna.create_study(direction='minimize')  # Optimisation pour minimiser la MSE\n",
    "study.optimize(objectif, n_trials=10)\n",
    "\n",
    "# Récupération des meilleurs paramètres trouvés lors de l'optimisation\n",
    "best_params = study.best_params\n",
    "print('\\n')\n",
    "print(\"Meilleurs Paramètres:\", best_params)\n",
    "\n",
    "# Création d'un modèle CatBoost avec les hyperparamètres optimaux\n",
    "best_model = CatBoostRegressor(**best_params, silent=True)\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calcul du MSE et du R2 avec les hyperparamètres optimaux\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2_catboost = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2_catboost)\n",
    "\n",
    "# Accéder aux poids des différentes variables\n",
    "importances = best_model.feature_importances_\n",
    "\n",
    "# Créer une liste des noms de variables\n",
    "noms_variables = list(X_train.columns)  # Remplacez X.columns par le nom de votre jeu de données\n",
    "\n",
    "# Associer les poids aux noms de variables\n",
    "importance_df = pd.DataFrame({'Variable': X_train.columns, 'Poids': importances})\n",
    "importance_df = importance_df.sort_values('Poids', ascending=False)\n",
    "\n",
    "# Afficher les poids des différentes variables\n",
    "print(\"\\n Importances des variables :\")\n",
    "importance=importance_df.T\n",
    "print(importance.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affichage des résultats finaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26156212.014953274, 8648805.4638422, 9745363.961285017, 9743965.326113414, 5145555.33949904, 4866947.071349802, 5420505.755720176]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Diagrammes bar des performances optimiséess de chaque modèle - mse\n",
    "\n",
    "# Exemple de données\n",
    "categories = ['Linear Regression', 'Lasso', 'Ridge', 'ElasticNet', 'RandomForestRegressor', 'GradientBoostingRegressor', 'CatBoostRegressor']\n",
    "values = [mse_reglin,mse_lasso, mse_ridge, mse_en, best_mse_RandomForest, mseGBR, mse]\n",
    "\n",
    "# Création du diagramme à barres\n",
    "plt.figure(figsize=(18, 6))  \n",
    "plt.bar(categories, values)\n",
    "\n",
    "# Ajout de labels et de titre\n",
    "plt.xlabel('Modèles')\n",
    "plt.ylabel('mse')\n",
    "plt.title('Performances maximales évaluées pour chaque modèle - mse')\n",
    "\n",
    "# Affichage du diagramme\n",
    "print(values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5759401113614121, 0.8597804804550064, 0.8420024293348574, 0.8420251048306355, 0.9165772313282898, 0.9233677583620897, 0.912119573513878]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Diagrammes bar des performances optimiséess de chaque modèle - r2\n",
    "\n",
    "# Exemple de données\n",
    "categories = ['Linear Regression', 'Lasso', 'Ridge', 'ElasticNet', 'RandomForestRegressor', 'GradientBoostingRegressor', 'CatBoostRegressor']\n",
    "values = [r2_reglin,r2_lasso, r2_ridge, r2_en, r2_RandomForest, r2GBR, r2_catboost]\n",
    "\n",
    "# Création du diagramme à barres\n",
    "plt.figure(figsize=(18, 6))  \n",
    "plt.bar(categories, values)\n",
    "\n",
    "# Ajout de labels et de titre\n",
    "plt.xlabel('Modèles')\n",
    "plt.ylabel('r2')\n",
    "plt.title('Performances maximales évaluées pour chaque modèle - r2')\n",
    "\n",
    "# Affichage du diagramme\n",
    "print(values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Régression linéaire : Elle semble donner des résultats moyens, avec une MSE de 26 156 212 et un score R2 de 0,576. Elle pourrait ne pas capturer efficacement les complexités des données, peut-être en raison de l'hypothèse de linéarité ou de la présence de non-linéarités dans les données.\n",
    "\n",
    "    Régularisation Lasso : Le Lasso semble mieux fonctionner que la régression linéaire en pénalisant les coefficients importants, ce qui pourrait aider dans la sélection des caractéristiques. La MSE diminue significativement à 8 648 644, et le score R2 s'améliore à 0,860, indiquant un meilleur ajustement.\n",
    "\n",
    "    RandomForestRegressor : Ce modèle, basé sur l'apprentissage par ensemble, réduit encore la MSE à 5 147 905, suggérant qu'il capture davantage de la variance des données. Le score R2 s'améliore également de manière significative à 0,916, montrant un meilleur ajustement que la régression linéaire et le Lasso.\n",
    "\n",
    "    GradientBoostingRegressor : Avec une MSE notablement réduite à 2 507 220 et un score R2 exceptionnellement élevé de 0,96, GradientBoostingRegressor obtient la meilleure performance. \n",
    "    Le modèle explique 96% de la variance des résultats et possède le mse le plus bas.\n",
    "\n",
    "    CatBoostRegressor : Avec une MSE de 4 524 163 et un score R2 de 0,913, le modèle montre une forte capacité prédictive similaire au modèle Random Forest.\n",
    "\n",
    "    Caractéristiques catégorielles : Les modèles basés sur les arbres (Random Forest, Gradient Boosting, CatBoost) semblent bien gérer les variables catégorielles sans beaucoup de prétraitement. Leur performance pourrait indiquer que ces caractéristiques sont efficacement utilisées par ces modèles.\n",
    "\n",
    "Caractéristiques quantitatives : Tous les modèles semblent bien gérer les caractéristiques quantitatives, avec des méthodes d'ensemble (Random Forest, Gradient Boosting, CatBoost) montrant de meilleures performances dans l'ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "902a52bcf4503a473db011f1937bdfe17613b08622219712e0110e48c4958c23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
